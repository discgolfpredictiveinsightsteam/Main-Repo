{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process historical weather page from Weather Underground\n",
    "\n",
    "### Objective\n",
    "\n",
    "* csv file with tabulated weather data gathered from web page\n",
    "\n",
    "### Rationale\n",
    "* Why This?  Weather data in csv form can be used to build the necessary predictive database, but is not available as such.  This tool builds the data in the appropriate form using freely available services.\n",
    "\n",
    "* Why Me (andrewguenthner)?  Since I will be building the models, I am best suited to put this data into the right form\n",
    "\n",
    "* Why Now?  Open weather data has a finite life-span.  It needs to be put into a long-term storable form before it goes away."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Requirements\n",
    "\n",
    "* Pandas 0.24.2\n",
    "* Numpy 1.16.4\n",
    "* Beautifulsoup4 \n",
    "\n",
    "### Input and Output\n",
    "\n",
    "* The notebook processes all files of type .html that it can identify in a given folder. The files should be named as `{station_id}_{mmddyy}.html` where {station_id} is the Personal Weather Station ID and mmddyy is the observation date \n",
    "\n",
    "* All input files should be in the folder/sub-folder `models/wx_record/wu_raw_html` given that the notebook is located in\n",
    "`models/notebooks`.  Adjust accordingly if needed.\n",
    "\n",
    "* Output files will be given the name `{station_id}_{mmddyy}_p01.csv` and stored in the folder/sub-folder `models/wx_record/wx_station_by_date`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import and set-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt \n",
    "import re\n",
    "import glob\n",
    "import bs4\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_output_filename(corresponding_input_name : str) -> str:\n",
    "    \"\"\"Generates output filename for processing parsed Weather Underground pages, given the input file name\"\"\"\n",
    "    try:\n",
    "        path_parts_list = re.split(r'[/\\\\]',corresponding_input_name)\n",
    "        filename = path_parts_list.pop()\n",
    "        name_and_suffix = filename.split('.')\n",
    "        parts_of_name = name_and_suffix[0].split('_')\n",
    "        parts_of_name.append('p01.csv')\n",
    "        new_filename = '_'.join(parts_of_name)\n",
    "        parent_dir = path_parts_list.pop()\n",
    "        new_parent_dir = 'wx_station_by_date'\n",
    "        path_parts_list.append(new_parent_dir)\n",
    "        path_parts_list.append(new_filename)\n",
    "        return '/'.join(path_parts_list)\n",
    "    except IndexError:\n",
    "        return corresponding_input_name + '_filename_parse_error'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_observations(sections):\n",
    "    \"\"\"Takes a list of strings and returns a set of lists containing matched observations.  For use with Weather Underground\n",
    "    html file parsers.  The lists returned contain blanks if parsing fails.  Values returned include observation time, \n",
    "    temperature, wind direction, wind speed, wind gust, humidity, and precipitation rate.\"\"\"\n",
    "    obstimes, temp_avgs, winddir_avgs, windspeed_avgs, windgust_avgs, humidity_avgs, precip_rates = ([] for _ in range(7))\n",
    "    for section in sections:\n",
    "        obs = section.split('&q;')\n",
    "        try:\n",
    "            obstime = dt.datetime.fromisoformat(obs[0])\n",
    "            obstimes.append(obstime)\n",
    "        except ValueError:\n",
    "            continue\n",
    "        try:\n",
    "            temp_avg_ix = obs.index('tempAvg')\n",
    "            temp_avg = float(obs[temp_avg_ix + 1].lstrip(':').rstrip(','))\n",
    "            temp_avgs.append(temp_avg)\n",
    "        except ValueError:\n",
    "            temp_avgs.append('')\n",
    "        try:\n",
    "            winddir_avg_ix = obs.index('winddirAvg')\n",
    "            winddir_avg = float(obs[winddir_avg_ix + 1].lstrip(':').rstrip(','))\n",
    "            winddir_avgs.append(winddir_avg)\n",
    "        except ValueError:\n",
    "            winddir_avgs.append('')\n",
    "        try:\n",
    "            windspeed_avg_ix = obs.index('windspeedAvg')\n",
    "            windspeed_avg = float(obs[windspeed_avg_ix + 1].lstrip(':').rstrip(','))\n",
    "            windspeed_avgs.append(windspeed_avg)\n",
    "        except ValueError:\n",
    "            windspeed_avgs.append('')\n",
    "        try:\n",
    "            windgust_avg_ix = obs.index('windgustAvg')\n",
    "            windgust_avg = float(obs[windgust_avg_ix + 1].lstrip(':').rstrip(','))\n",
    "            windgust_avgs.append(windgust_avg)\n",
    "        except ValueError:\n",
    "            windgust_avgs.append('')\n",
    "        try:\n",
    "            humidity_avg_ix = obs.index('humidityAvg')\n",
    "            humidity_avg = float(obs[humidity_avg_ix + 1].lstrip(':').rstrip(','))\n",
    "            humidity_avgs.append(humidity_avg)\n",
    "        except ValueError:\n",
    "            humidity_avgs.append('')\n",
    "        try:\n",
    "            precip_rate_ix = obs.index('precipRate')\n",
    "            precip_rate = float(obs[precip_rate_ix + 1].lstrip(':').rstrip(','))\n",
    "            precip_rates.append(precip_rate)\n",
    "        except ValueError:\n",
    "            precip_rates.append('')\n",
    "    return obstimes, temp_avgs, winddir_avgs, windspeed_avgs, windgust_avgs, humidity_avgs, precip_rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_file(input_file):\n",
    "    \"\"\"Takes a stored html file with weather observations from Weather Underground and converts it to a .csv file with\n",
    "    a scraped observation table.  Returns the number of files successfully processed (1 or 0)\"\"\"\n",
    "    try:\n",
    "        soup = bs4.BeautifulSoup(open(input_file), 'html.parser')\n",
    "        page_sections = soup.text.split('&q;obsTimeLocal&q;:&q;')\n",
    "        # Dump the giant first bit\n",
    "        page_sections.pop(0)\n",
    "        # And dump the last bit\n",
    "        page_sections.pop()\n",
    "        # parse_observations will populate lists that go to the DataFrame \n",
    "        otime, t, w_dir, w_spd, w_gust, rh, prcp = parse_observations(page_sections)\n",
    "        obs_df = pd.DataFrame({'time':otime,'T':t,'w_dir':w_dir,'w_spd':w_spd,\n",
    "                              'w_gust':w_gust,'rh':rh,'precip':prcp})\n",
    "        output_file = create_output_filename(input_file)\n",
    "        obs_df.to_csv(output_file)\n",
    "        return 1\n",
    "    except (IndexError):\n",
    "        print(f'File {input_file} skipped due to error in processing.')\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 files processed.\n"
     ]
    }
   ],
   "source": [
    "processed_count = 0\n",
    "for filename in glob.glob('../wx_record/wu_raw_html/*.html'):\n",
    "    # process_file will save the output file as a side effect !!!\n",
    "    processed_count += process_file(filename)\n",
    "print(f'{processed_count} files processed.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
