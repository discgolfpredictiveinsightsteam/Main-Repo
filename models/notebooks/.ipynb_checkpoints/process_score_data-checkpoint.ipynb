{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process Player Scores\n",
    "\n",
    "### Objective\n",
    "\n",
    "* Build single file for player scores, merge-compatible with weather model\n",
    "\n",
    "### Rationale\n",
    "\n",
    "* Why This?  A nicely formatted set of player scores can be merged into the weather model for predictive analytics.\n",
    "\n",
    "* Why Me?  I will be building the predictive scoring model, so it makes sense to build all the pipelines\n",
    "\n",
    "* Why Now?  This step needs to be reproducible before creating the prediction system"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Requirements\n",
    "\n",
    "* numpy 1.16.4\n",
    "* pandas 0.24.2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input / Output\n",
    "\n",
    "* Input files are in the `'csv_files` directory of the project root directory (same level as `models`).  The notebook is expected to be in `models/noetbooks`.  Output files will be stored in `models/score_model_data`\n",
    "\n",
    "* The input files are named via data index as follows: `Chabot_{mm}-{dd}-{yyyy}.csv` \n",
    "\n",
    "* The output file will be named `scores.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import glob\n",
    "import csv\n",
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_datetime_from_Chabot_filename (filename: str):\n",
    "    \"\"\"Given a filename that is expected to refer to a csv file with Lake Chabot Golf Course disc golf scores, \n",
    "    return a datetime object with the estimated starting date & time.  Uses hard coded knowledge of Chabot disc golf practices\n",
    "    for start time.  Returns Jan 1, 1900 for date if date parsing fails.\"\"\"\n",
    "    \n",
    "    # Lake Chabot uses a rolling start from 8AM - 2PM year-round\n",
    "    start_time = dt.time(8,0,0)\n",
    "    # Filename format \"[parent_dirs][/\\]Chabot_mm-dd-yyyy.csv\"\n",
    "    # Remove any parent directories first\n",
    "    filename = re.split(r'[/\\\\]',filename)[-1]\n",
    "    date_portion_of_name = filename.split('.')[0].split('_')[1]\n",
    "    nums_in_date = date_portion_of_name.split('-')\n",
    "    try:\n",
    "        month_num = int(nums_in_date[0])\n",
    "        day_num = int(nums_in_date[1])\n",
    "        year_num = int(nums_in_date[2])\n",
    "    except ValueError:\n",
    "        month_num = 1\n",
    "        day_num = 1\n",
    "        year_num = 1900\n",
    "    \n",
    "    extracted_date = dt.date(year_num, month_num, day_num)\n",
    "    \n",
    "    return dt.datetime.combine(extracted_date, start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_Chabot_input_to_df (filename : str):\n",
    "    \"\"\"Given an input filename that is expected to refer to a csv file with Lake Chabot Golf Course disc golf scores,\n",
    "    return a Pandas dataframe with starting time, player name, raw score, handicap, and adjusted score\"\"\"\n",
    "    \n",
    "    try:\n",
    "        input_df = pd.read_csv(filename, header=1, index_col=None, usecols=['Name','Raw','Handicap','Adjusted'],\n",
    "                         skip_blank_lines=True)\n",
    "    except ValueError as e:\n",
    "        print(f'\\nError parsing data from {filename}')\n",
    "        print(e)\n",
    "        return None \n",
    "    # Remove any lines without a number in 'Raw' by first coercing conversion of non-numbers to NaN\n",
    "    input_df.Raw = pd.to_numeric(input_df.Raw, errors='coerce')\n",
    "    input_df = input_df.dropna(subset=['Raw'])\n",
    "    # Drop any scores of zero or below\n",
    "    input_df = input_df[input_df['Raw'] > 0]\n",
    "    if len(input_df) == 0:\n",
    "        print(f'\\nNo useable data found in {filename}')\n",
    "        return None\n",
    "    datetime_obj = extract_datetime_from_Chabot_filename(filename)\n",
    "    input_df['time'] = datetime_obj\n",
    "    input_df['course_id'] = 1\n",
    "    return input_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_datetime_from_Golden_Gate_filename (filename: str):\n",
    "    \"\"\"Given a filename that is expected to refer to a csv file with Golden Gate Park disc golf scores, return a datetime\n",
    "    object with the estimated starting date & time.  Uses hard coded knowledge of Golden Gate disc golf practices\n",
    "    for start time.  Returns Jan 1, 1900 for date if date parsing fails.\"\"\"\n",
    "    \n",
    "    # Golden Gate uses a rolling start time from 7:30 AM onward \n",
    "    start_time = dt.time(7,30,0)\n",
    "    # Filename format \"[parent_dirs][/\\][m]m-[d]d-yy.csv\"\n",
    "    # Remove any parent directories first\n",
    "    filename = re.split(r'[/\\\\]',filename)[-1]\n",
    "    date_portion_of_name = filename.split('.')[0]\n",
    "    nums_in_date = date_portion_of_name.split('-')\n",
    "    try:\n",
    "        month_num = int(nums_in_date[0])\n",
    "        day_num = int(nums_in_date[1])\n",
    "        year_num = int(nums_in_date[2]) + 2000\n",
    "    except ValueError:\n",
    "        month_num = 1\n",
    "        day_num = 1\n",
    "        year_num = 1900\n",
    "    \n",
    "    extracted_date = dt.date(year_num, month_num, day_num)\n",
    "    \n",
    "    return dt.datetime.combine(extracted_date, start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_Golden_Gate_input_to_df (filename : str):\n",
    "    \"\"\"Given an input filename that is expected to refer to a csv file with Golden Gate Park disc golf scores,\n",
    "    return a Pandas dataframe with starting time, player name, raw score, handicap, adjusted score and course_id (0)\"\"\"\n",
    "    \n",
    "    try:\n",
    "        input_df = pd.read_csv(filename, index_col=None, usecols=['Full Name','Adjust', 'Score'],\n",
    "                         skip_blank_lines=True)\n",
    "    except ValueError as e:\n",
    "        print(f'\\nError parsing data from {filename}')\n",
    "        print(e)\n",
    "        return None \n",
    "    # Synchronize column names with other course data\n",
    "    input_df = input_df.rename(columns = {'Full Name':'Name','Score':'Raw','Adjust':'Handicap'})\n",
    "    # Remove any lines without a number in 'Raw' by first coercing conversion of non-numbers to NaN\n",
    "    input_df.Raw = pd.to_numeric(input_df.Raw, errors='coerce')\n",
    "    input_df = input_df.dropna(subset=['Raw'])\n",
    "    # Also remove any scores of zero or below\n",
    "    input_df = input_df[input_df['Raw'] > 0]\n",
    "    if len(input_df) == 0:\n",
    "        print(f'\\nNo useable data found in {filename}')\n",
    "        return None\n",
    "    # Compute adjusted score\n",
    "    # Strip parentheses from Handicap and convert to a '-'\n",
    "    input_df['Handicap'] = input_df['Handicap'].astype('str')\n",
    "    input_df['Handicap'] = input_df['Handicap'].str.replace('(','-').str.rstrip(')')\n",
    "    # Replace anything that isn't numeric with NaN\n",
    "    input_df['Handicap'] = pd.to_numeric(input_df['Handicap'], errors='coerce')\n",
    "    # Compute adjusted score\n",
    "    input_df['Adjusted'] = input_df['Raw'] + input_df['Handicap']\n",
    "    datetime_obj = extract_datetime_from_Golden_Gate_filename(filename)\n",
    "    input_df['time'] = datetime_obj\n",
    "    input_df['course_id'] = 0\n",
    "    return input_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_row_with_dates_in_AP_file(data):\n",
    "    \"\"\"Given a two-dimensional list of data from an Aquatic Park yearly csv file, find which row in the file contains\n",
    "    the dates in m/d/y format.  This row is the last row in the header and is useful in multiple contexts.\"\"\"\n",
    "    #Look in column with index '2'\n",
    "    row_with_dates = 0\n",
    "    for ix, row in enumerate(data):\n",
    "        content = row[2]\n",
    "        if '/' in content:\n",
    "            row_with_dates = ix\n",
    "            break  #Once the dates are found, no need to keep looking\n",
    "    if (row_with_dates == 0):\n",
    "        print('Unable to find expected date info in file.')\n",
    "    return row_with_dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_info_locs_from_AP_file(data, row_with_dates):\n",
    "    \"\"\"Given a two-dimensional list of data from an Aquatic Park yearly csv file, and an integer index for the row that \n",
    "    contains the dates,return a dictionary mapping dates to olumn index numbers.  The dictionary will have two levels,\n",
    "    the outer level will hold dates as keys, the inner level will have three keys for each date: 'raw', 'handicap',\n",
    "    and 'adjusted' for info about the raw score, handicap, and adjusted score that date, respectively.  The info \n",
    "    is in the form of the spreadsheet column (or list index #2) that contains this value. The function expects the \n",
    "    info type to be in the row above the date.\"\"\"\n",
    "    \n",
    "    result_dict = {}  #Default to empty dict \n",
    "    #Now search through the row with dates to find raw score (labeled 'SCORE'),\n",
    "    #handicap (labeled 'HANDICAP'), and adjusted score (labeled 'ADJUSTED SCORE') in\n",
    "    #the row with types\n",
    "    for ix, cell in enumerate(data[row_with_dates]):\n",
    "        if ix < 2:\n",
    "            continue    #Skip first two columns\n",
    "        date_key = cell\n",
    "        type_label = data[row_with_dates - 1][ix]\n",
    "        if type_label in ['SCORE','HANDICAP','ADJUSTED SCORE']:\n",
    "            if date_key not in result_dict:\n",
    "                result_dict[date_key] = {}\n",
    "            result_dict[date_key][type_label] = ix\n",
    "    \n",
    "    return result_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_AP_game_dates(date_string : str):\n",
    "    \"\"\"Given a string of the form [m]m/[d]d/yyyy, return a valid Python date object with the given date.\"\"\"\n",
    "    \n",
    "    date_nums = date_string.split('/')\n",
    "    try:\n",
    "        month = int(date_nums[0])\n",
    "        day = int(date_nums[1])\n",
    "        year = int(date_nums[2]) + 2000\n",
    "    except ValueError:\n",
    "        month, day, year = 1, 1, 1900\n",
    "        \n",
    "    return dt.date(year, month, day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_Aquatic_Park_input_to_df(filename: str):\n",
    "    \"\"\"Given an input file with a year (or year-to-date)s worth of score data for Berkeley Aquatic Park disc golf course\n",
    "    in its standard format, return a DataFrame in the standard name, raw score, handicap, adjusted, course_id (2) format.\n",
    "    This function differs from the other parsers because the file format is substantially different.\"\"\"\n",
    "    with open(filename) as csvfile:\n",
    "        reader = csv.reader(csvfile)\n",
    "        file_data = [row for row in reader]\n",
    "    #Create a dictionary with datestrings as keys, each value being a dictionary with \n",
    "    #keys 'raw','handicap', and 'adjusted', with values corresponding to column numbers where \n",
    "    #this info can be found on the sheet for each date\n",
    "    last_header_row = find_row_with_dates_in_AP_file(file_data)\n",
    "    dates_dict = parse_info_locs_from_AP_file(file_data, last_header_row)\n",
    "    time_list, name_list, raw_list, handicap_list, adjusted_list = ([] for _ in range(5))\n",
    "    input_df = pd.DataFrame()\n",
    "    for row_ix, row in enumerate(file_data):\n",
    "        if row_ix <= last_header_row:\n",
    "            continue   #Skip row if in header\n",
    "        player_name = row[1]\n",
    "        if (len(player_name) > 0) & (player_name != 'Paid Participants:'):\n",
    "            for col_ix, cell in enumerate(row):\n",
    "                if file_data[last_header_row - 1][col_ix] == 'SCORE':\n",
    "                    try:\n",
    "                        entry = int(cell)\n",
    "                    except ValueError:\n",
    "                        continue   #Skip non-numeric entries\n",
    "                    date_played = file_data[last_header_row][col_ix]\n",
    "                    score_data = dates_dict.get(date_played,None)\n",
    "                    if score_data:  #Should always be true, but parsing could be corrupted\n",
    "                        try:\n",
    "                            raw_score = int(row[score_data['SCORE']])\n",
    "                        except ValueError:\n",
    "                            continue   #ValueError here would mean corrupted parsing, so skip entirely if true\n",
    "                        try:\n",
    "                            handicap = int(row[score_data['HANDICAP']])\n",
    "                            adjusted_score = int(row[score_data['ADJUSTED SCORE']])\n",
    "                        except ValueError:\n",
    "                            handicap = 'not established'\n",
    "                            adjusted_score = 'not established'\n",
    "                        #Append to the lists for DataFrame\n",
    "                        time_list.append(dt.datetime.combine(parse_AP_game_dates(date_played),dt.time.fromisoformat('09:00:00')))\n",
    "                        name_list.append(player_name)\n",
    "                        raw_list.append(raw_score)\n",
    "                        handicap_list.append(handicap)\n",
    "                        adjusted_list.append(adjusted_score)\n",
    "                    #End of if (score_data)\n",
    "                elif file_data[last_header_row - 1][col_ix] == 'AVERAGE':  #this signals the end of score data\n",
    "                    break #Once we hit the end of score data, no need to examine any more columns\n",
    "            #End of for loop for columns\n",
    "            print('.',end='')\n",
    "        #End of check for non-empty player name\n",
    "    #End of for loop to add rows\n",
    "    if len(time_list) > 0:\n",
    "        input_df = pd.DataFrame({'Name':name_list,'Raw':raw_list,'Handicap':handicap_list,\n",
    "                               'Adjusted':adjusted_list,'time':time_list})\n",
    "        input_df['course_id'] = 2\n",
    "    #Remove raw scores of 0 or less\n",
    "    input_df = input_df[input_df['Raw'] > 0]\n",
    "    return input_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting files...+++++++++++++++++++++++++oooooooooooooooooooooooooooo\n",
      "No useable data found in ../../csv_files\\3-31-19.csv\n",
      "o\n",
      "No useable data found in ../../csv_files\\8-11-13.csv\n",
      "o.......................................................................................................................................................................................................................................................................x..............................................................................................................................................................................................................................................................................................x............................................................................................................................................................................................................................................................................................................x\n",
      "3796 rows created.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Raw</th>\n",
       "      <th>Handicap</th>\n",
       "      <th>Adjusted</th>\n",
       "      <th>time</th>\n",
       "      <th>course_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mark Shannon</td>\n",
       "      <td>61.0</td>\n",
       "      <td>-12.4</td>\n",
       "      <td>48.6</td>\n",
       "      <td>2019-01-19 08:00:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jacob Kermish-Wells</td>\n",
       "      <td>60.0</td>\n",
       "      <td>-10.72</td>\n",
       "      <td>49.28</td>\n",
       "      <td>2019-01-19 08:00:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Luiz Celeste</td>\n",
       "      <td>55.0</td>\n",
       "      <td>-5.23</td>\n",
       "      <td>49.77</td>\n",
       "      <td>2019-01-19 08:00:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tu Tran</td>\n",
       "      <td>59.0</td>\n",
       "      <td>-9.07</td>\n",
       "      <td>49.93</td>\n",
       "      <td>2019-01-19 08:00:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Matty Angell</td>\n",
       "      <td>53.0</td>\n",
       "      <td>-1.5</td>\n",
       "      <td>51.5</td>\n",
       "      <td>2019-01-19 08:00:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Name   Raw Handicap Adjusted                time  course_id\n",
       "1         Mark Shannon  61.0    -12.4     48.6 2019-01-19 08:00:00          1\n",
       "2  Jacob Kermish-Wells  60.0   -10.72    49.28 2019-01-19 08:00:00          1\n",
       "3         Luiz Celeste  55.0    -5.23    49.77 2019-01-19 08:00:00          1\n",
       "4              Tu Tran  59.0    -9.07    49.93 2019-01-19 08:00:00          1\n",
       "5         Matty Angell  53.0     -1.5     51.5 2019-01-19 08:00:00          1"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build a master DataFrame by combining all data from input files\n",
    "master_df = pd.DataFrame()\n",
    "print('Extracting files...',end='')\n",
    "# Chabot data files\n",
    "for file_to_read in glob.glob('../../csv_files/Chabot_*.csv'):\n",
    "    master_df = master_df.append(parse_Chabot_input_to_df(file_to_read), sort=False)\n",
    "    print('+',end='')\n",
    "# Golden Gate Park data files \n",
    "for file_to_read in glob.glob('../../csv_files/[0-9]*.csv'):\n",
    "    master_df = master_df.append(parse_Golden_Gate_input_to_df(file_to_read), sort=False)\n",
    "    print ('o',end='')\n",
    "# Berkeley Aquatic Park files\n",
    "for file_to_read in glob.glob('../../csv_files/AP*final_week.csv'):\n",
    "    master_df = master_df.append(parse_Aquatic_Park_input_to_df(file_to_read), sort=False)\n",
    "    print('x',end='')\n",
    "print(f'\\n{len(master_df)} rows created.')\n",
    "master_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Raw</th>\n",
       "      <th>Handicap</th>\n",
       "      <th>Adjusted</th>\n",
       "      <th>time</th>\n",
       "      <th>course_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mark Shannon</td>\n",
       "      <td>61.0</td>\n",
       "      <td>-12.40</td>\n",
       "      <td>48.60</td>\n",
       "      <td>2019-01-19 08:00:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jacob Kermish-Wells</td>\n",
       "      <td>60.0</td>\n",
       "      <td>-10.72</td>\n",
       "      <td>49.28</td>\n",
       "      <td>2019-01-19 08:00:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Luiz Celeste</td>\n",
       "      <td>55.0</td>\n",
       "      <td>-5.23</td>\n",
       "      <td>49.77</td>\n",
       "      <td>2019-01-19 08:00:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tu Tran</td>\n",
       "      <td>59.0</td>\n",
       "      <td>-9.07</td>\n",
       "      <td>49.93</td>\n",
       "      <td>2019-01-19 08:00:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Matty Angell</td>\n",
       "      <td>53.0</td>\n",
       "      <td>-1.50</td>\n",
       "      <td>51.50</td>\n",
       "      <td>2019-01-19 08:00:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Name   Raw  Handicap  Adjusted                time  \\\n",
       "0         Mark Shannon  61.0    -12.40     48.60 2019-01-19 08:00:00   \n",
       "1  Jacob Kermish-Wells  60.0    -10.72     49.28 2019-01-19 08:00:00   \n",
       "2         Luiz Celeste  55.0     -5.23     49.77 2019-01-19 08:00:00   \n",
       "3              Tu Tran  59.0     -9.07     49.93 2019-01-19 08:00:00   \n",
       "4         Matty Angell  53.0     -1.50     51.50 2019-01-19 08:00:00   \n",
       "\n",
       "   course_id  \n",
       "0          1  \n",
       "1          1  \n",
       "2          1  \n",
       "3          1  \n",
       "4          1  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Clean up DataFrame\n",
    "# 1) Drop anything with NaN in the name\n",
    "master_df = master_df.dropna(subset = ['Name'])\n",
    "# 1) Get rid of anything including and after a '(' in the name\n",
    "master_df['Name'] = master_df['Name'].apply(lambda x : x.split('(')[0])\n",
    "# 2) Coerce all non-numeric handicap and adjusted to 'NaN' \n",
    "master_df['Handicap'] = pd.to_numeric(master_df['Handicap'], errors='coerce')\n",
    "master_df['Adjusted'] = pd.to_numeric(master_df['Adjusted'], errors='coerce')\n",
    "# 3) Reset index and get rid of old index\n",
    "master_df = master_df.reset_index()\n",
    "master_df = master_df.drop(columns = 'index')\n",
    "master_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df.to_csv('../score_model_data/scores.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
