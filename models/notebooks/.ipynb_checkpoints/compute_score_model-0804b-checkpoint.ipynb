{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Score Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objective\n",
    "\n",
    "* Creates the comprehensive set of scoring models for all players and courses in the database, using an ElasticNetCV linear regression for weather parameters when a player has sufficient games on the same course, an ARIMA(0,1,0) model when a player has 4 or more game on the same course but not enough for a weather-based model, a same-course average if the player has one or more games on the same course, and an off-course average when a player has no games on the same course.  Also computes an estimated error from (in order of preference), same-course mse, all-course mse, or, when there is only one game available, an imputed first-vs-second game sme on either the same course or all-course, as the situation requires.  \n",
    "\n",
    "### Rationale\n",
    "\n",
    "*  Why This?  The models are a key component of the service offered by the system, and need a production-ready ETL method\n",
    "\n",
    "*  Why Me?  As the main model architect, I am the logical choice\n",
    "\n",
    "*  Why Now?  Successful trial runs with earlier models have accomplished preliminary optimization and established usefulness with user feedback.  Having a production-level model-building system now will enable us to receive maximum benefit from early deployments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Requirements\n",
    "\n",
    "*  Pandas 0.24.2\n",
    "*  Scikit-learn 0.21.2\n",
    "*  Numpy 1.16.4\n",
    "*  Matplotlib 3.1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input / Output\n",
    "\n",
    "*  This notebook is expected to be in `models/notebooks`\n",
    "\n",
    "*  The input weather data is in a file `models/wx_model_data/wx_model.csv`\n",
    "\n",
    "*  The input score data is in a file `models/score_model_data/scores.csv`\n",
    "\n",
    "*  The output models are stored in a file `models/score_model_data/score_model.csv` with a second copy as `models/scoer_model_data/score_model_{YYYYMMDD}{[a-z]}` where YYYYMMDD is the year, month, and day the model was generated, and a lower-case letter auto-increments for tracking.  `score_model.csv` is moved to `scoreCalculator/data` for deployed use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import / Set-Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "import numpy as np\n",
    "from sklearn.linear_model import ElasticNetCV\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import datetime as dt\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get weather data\n",
    "wx_df = pd.read_csv('../wx_model_data/wx_model.csv', parse_dates = ['date'])\n",
    "# Get scores data\n",
    "scores_df = pd.read_csv('../score_model_data/scores.csv', parse_dates = ['time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>date</th>\n",
       "      <th>weighted_T</th>\n",
       "      <th>weighted_w_dir</th>\n",
       "      <th>weighted_w_spd</th>\n",
       "      <th>weighted_w_gust</th>\n",
       "      <th>weighted_rh</th>\n",
       "      <th>weighted_precip</th>\n",
       "      <th>weighted_w_u</th>\n",
       "      <th>weighted_w_v</th>\n",
       "      <th>w_gust_var</th>\n",
       "      <th>w_dir_var</th>\n",
       "      <th>w_uv_var</th>\n",
       "      <th>course_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2018-11-11</td>\n",
       "      <td>62.987163</td>\n",
       "      <td>59.560057</td>\n",
       "      <td>5.091894</td>\n",
       "      <td>15.866667</td>\n",
       "      <td>26.821613</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.632290</td>\n",
       "      <td>3.792724</td>\n",
       "      <td>2.382222</td>\n",
       "      <td>115.436274</td>\n",
       "      <td>111.370212</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2018-12-09</td>\n",
       "      <td>49.491667</td>\n",
       "      <td>68.116667</td>\n",
       "      <td>3.919444</td>\n",
       "      <td>13.133333</td>\n",
       "      <td>90.988889</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.100778</td>\n",
       "      <td>2.822686</td>\n",
       "      <td>2.915556</td>\n",
       "      <td>490.203981</td>\n",
       "      <td>41.108702</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2018-12-17</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>135.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>93.000000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2019-01-06</td>\n",
       "      <td>51.505556</td>\n",
       "      <td>153.133333</td>\n",
       "      <td>4.384722</td>\n",
       "      <td>20.933333</td>\n",
       "      <td>89.798611</td>\n",
       "      <td>0.105625</td>\n",
       "      <td>0.829178</td>\n",
       "      <td>-3.227827</td>\n",
       "      <td>6.995556</td>\n",
       "      <td>214.376551</td>\n",
       "      <td>906.500313</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2019-08-03</td>\n",
       "      <td>56.631841</td>\n",
       "      <td>226.426190</td>\n",
       "      <td>3.021159</td>\n",
       "      <td>12.866667</td>\n",
       "      <td>96.149492</td>\n",
       "      <td>0.000203</td>\n",
       "      <td>-2.264058</td>\n",
       "      <td>-1.859965</td>\n",
       "      <td>1.448889</td>\n",
       "      <td>15.888444</td>\n",
       "      <td>17.074903</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0       date  weighted_T  weighted_w_dir  weighted_w_spd  \\\n",
       "0           0 2018-11-11   62.987163       59.560057        5.091894   \n",
       "1           1 2018-12-09   49.491667       68.116667        3.919444   \n",
       "2           2 2018-12-17   52.000000      135.000000        0.000000   \n",
       "3           3 2019-01-06   51.505556      153.133333        4.384722   \n",
       "4           4 2019-08-03   56.631841      226.426190        3.021159   \n",
       "\n",
       "   weighted_w_gust  weighted_rh  weighted_precip  weighted_w_u  weighted_w_v  \\\n",
       "0        15.866667    26.821613         0.000000      2.632290      3.792724   \n",
       "1        13.133333    90.988889         0.000000      2.100778      2.822686   \n",
       "2         9.000000    93.000000         0.010000      0.000000      0.000000   \n",
       "3        20.933333    89.798611         0.105625      0.829178     -3.227827   \n",
       "4        12.866667    96.149492         0.000203     -2.264058     -1.859965   \n",
       "\n",
       "   w_gust_var   w_dir_var    w_uv_var  course_id  \n",
       "0    2.382222  115.436274  111.370212          0  \n",
       "1    2.915556  490.203981   41.108702          0  \n",
       "2    0.000000    0.000000    0.000000          0  \n",
       "3    6.995556  214.376551  906.500313          0  \n",
       "4    1.448889   15.888444   17.074903          0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wx_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Name</th>\n",
       "      <th>Raw</th>\n",
       "      <th>Handicap</th>\n",
       "      <th>Adjusted</th>\n",
       "      <th>time</th>\n",
       "      <th>course_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Mark Shannon</td>\n",
       "      <td>61</td>\n",
       "      <td>-12.40</td>\n",
       "      <td>48.60</td>\n",
       "      <td>2019-01-19 08:00:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Jacob Kermish-Wells</td>\n",
       "      <td>60</td>\n",
       "      <td>-10.72</td>\n",
       "      <td>49.28</td>\n",
       "      <td>2019-01-19 08:00:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Luiz Celeste</td>\n",
       "      <td>55</td>\n",
       "      <td>-5.23</td>\n",
       "      <td>49.77</td>\n",
       "      <td>2019-01-19 08:00:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Tu Tran</td>\n",
       "      <td>59</td>\n",
       "      <td>-9.07</td>\n",
       "      <td>49.93</td>\n",
       "      <td>2019-01-19 08:00:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Matty Angell</td>\n",
       "      <td>53</td>\n",
       "      <td>-1.50</td>\n",
       "      <td>51.50</td>\n",
       "      <td>2019-01-19 08:00:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                 Name  Raw  Handicap  Adjusted                time  \\\n",
       "0   0         Mark Shannon   61    -12.40     48.60 2019-01-19 08:00:00   \n",
       "1   1  Jacob Kermish-Wells   60    -10.72     49.28 2019-01-19 08:00:00   \n",
       "2   2         Luiz Celeste   55     -5.23     49.77 2019-01-19 08:00:00   \n",
       "3   3              Tu Tran   59     -9.07     49.93 2019-01-19 08:00:00   \n",
       "4   4         Matty Angell   53     -1.50     51.50 2019-01-19 08:00:00   \n",
       "\n",
       "   course_id  \n",
       "0          1  \n",
       "1          1  \n",
       "2          1  \n",
       "3          1  \n",
       "4          1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean out duplicated indexes\n",
    "wx_df = wx_df.drop(columns = 'Unnamed: 0')\n",
    "scores_df = scores_df.drop(columns = 'id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort prior to merge\n",
    "wx_df = wx_df.sort_values(by = ['date','course_id'])\n",
    "scores_df = scores_df.sort_values(by= ['time','course_id','Name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Raw</th>\n",
       "      <th>Handicap</th>\n",
       "      <th>Adjusted</th>\n",
       "      <th>time</th>\n",
       "      <th>course_id</th>\n",
       "      <th>date</th>\n",
       "      <th>weighted_T</th>\n",
       "      <th>weighted_w_dir</th>\n",
       "      <th>weighted_w_spd</th>\n",
       "      <th>weighted_w_gust</th>\n",
       "      <th>weighted_rh</th>\n",
       "      <th>weighted_precip</th>\n",
       "      <th>weighted_w_u</th>\n",
       "      <th>weighted_w_v</th>\n",
       "      <th>w_gust_var</th>\n",
       "      <th>w_dir_var</th>\n",
       "      <th>w_uv_var</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alex Torres</td>\n",
       "      <td>68</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2012-11-18 07:30:00</td>\n",
       "      <td>0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Andy Leaf</td>\n",
       "      <td>53</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2012-11-18 07:30:00</td>\n",
       "      <td>0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Anthony McGinnis</td>\n",
       "      <td>78</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2012-11-18 07:30:00</td>\n",
       "      <td>0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Aurelius Lewicki</td>\n",
       "      <td>57</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2012-11-18 07:30:00</td>\n",
       "      <td>0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Billy Manger</td>\n",
       "      <td>58</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2012-11-18 07:30:00</td>\n",
       "      <td>0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Name  Raw  Handicap  Adjusted                time  course_id  \\\n",
       "0       Alex Torres   68       NaN       NaN 2012-11-18 07:30:00          0   \n",
       "1         Andy Leaf   53       NaN       NaN 2012-11-18 07:30:00          0   \n",
       "2  Anthony McGinnis   78       NaN       NaN 2012-11-18 07:30:00          0   \n",
       "3  Aurelius Lewicki   57       NaN       NaN 2012-11-18 07:30:00          0   \n",
       "4      Billy Manger   58       NaN       NaN 2012-11-18 07:30:00          0   \n",
       "\n",
       "  date  weighted_T  weighted_w_dir  weighted_w_spd  weighted_w_gust  \\\n",
       "0  NaT         NaN             NaN             NaN              NaN   \n",
       "1  NaT         NaN             NaN             NaN              NaN   \n",
       "2  NaT         NaN             NaN             NaN              NaN   \n",
       "3  NaT         NaN             NaN             NaN              NaN   \n",
       "4  NaT         NaN             NaN             NaN              NaN   \n",
       "\n",
       "   weighted_rh  weighted_precip  weighted_w_u  weighted_w_v  w_gust_var  \\\n",
       "0          NaN              NaN           NaN           NaN         NaN   \n",
       "1          NaN              NaN           NaN           NaN         NaN   \n",
       "2          NaN              NaN           NaN           NaN         NaN   \n",
       "3          NaN              NaN           NaN           NaN         NaN   \n",
       "4          NaN              NaN           NaN           NaN         NaN   \n",
       "\n",
       "   w_dir_var  w_uv_var  \n",
       "0        NaN       NaN  \n",
       "1        NaN       NaN  \n",
       "2        NaN       NaN  \n",
       "3        NaN       NaN  \n",
       "4        NaN       NaN  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge\n",
    "all_df = pd.merge_asof(scores_df, wx_df, by = 'course_id', left_on= 'time', right_on = 'date',\n",
    "                       direction = 'backward', tolerance = pd.Timedelta('1d') )\n",
    "all_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare imputation estimates \n",
    "\n",
    "* Use as needed for when players have only ever played once or got an unrealistically low variation in scores:\n",
    "    * Single game on current course only -- use 1st game mean and historical 1st/2nd game average mse for all players on course\n",
    "    * Single game on a different course -- use existing game mean and historical 1st/2nd game (different course) average mse for all players\n",
    "    * Low standard deviation cut-off -- use the 5th percentile of all observed standard deviations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37.30478395061729"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate different course 1st to 2nd game estimate\n",
    "player_names = all_df['Name'].unique()\n",
    "diffs = []\n",
    "for player in player_names:\n",
    "    player_df = all_df[all_df['Name'] == player].sort_values(by = 'time')\n",
    "    if len(player_df) > 1:\n",
    "        scores = player_df[['course_id','Raw']].groupby('course_id')['Raw'].first().values\n",
    "        if len(scores) > 1:\n",
    "            diffs.append(scores[1] - scores[0])\n",
    "if len(diffs) > 1:\n",
    "    mse1to2_different_course = np.std(diffs) * np.std(diffs)\n",
    "else:\n",
    "    mse1to2_different_course = 6 * 6\n",
    "mse1to2_different_course"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[28.547822339223522, 32.90227440828402, 33.77324263038549]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate same course 1st to 2nd game estimate\n",
    "mse1to2_same_course = []\n",
    "for course_num in range(all_df['course_id'].max() + 1):\n",
    "    same_course_df = all_df[all_df['course_id'] == course_num]\n",
    "    player_names = same_course_df['Name'].unique()\n",
    "    diffs = []\n",
    "    for player in player_names:\n",
    "        player_df = same_course_df[same_course_df['Name'] == player].sort_values(by = 'time')\n",
    "        if len(player_df) > 1:\n",
    "            scores = player_df['Raw'].tolist()\n",
    "            if len(scores) > 1:\n",
    "                diffs.append(scores[1] - scores[0])\n",
    "    if len(diffs) > 1:\n",
    "        mse1to2_same_course.append(np.std(diffs) * np.std(diffs))\n",
    "    else:\n",
    "        mse1to2_same_course.append(6 * 6)\n",
    "mse1to2_same_course"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.1112220782958926"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate low standard deviation cut-off at 5th percentile \n",
    "player_stdev = all_df[['Name','Raw']].groupby('Name').std()\n",
    "low_std_cutoff = player_stdev['Raw'].quantile(q=0.05)\n",
    "low_var_cutoff = low_std_cutoff * low_std_cutoff\n",
    "low_var_cutoff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Raw</th>\n",
       "      <th>Handicap</th>\n",
       "      <th>Adjusted</th>\n",
       "      <th>time</th>\n",
       "      <th>course_id</th>\n",
       "      <th>date</th>\n",
       "      <th>weighted_T</th>\n",
       "      <th>weighted_w_dir</th>\n",
       "      <th>weighted_w_spd</th>\n",
       "      <th>weighted_w_gust</th>\n",
       "      <th>weighted_rh</th>\n",
       "      <th>weighted_precip</th>\n",
       "      <th>weighted_w_u</th>\n",
       "      <th>weighted_w_v</th>\n",
       "      <th>w_gust_var</th>\n",
       "      <th>w_dir_var</th>\n",
       "      <th>w_uv_var</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>478</th>\n",
       "      <td>Ben Horst</td>\n",
       "      <td>65</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-01-28 09:00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>2017-01-28</td>\n",
       "      <td>53.835946</td>\n",
       "      <td>251.602328</td>\n",
       "      <td>1.120795</td>\n",
       "      <td>7.688889</td>\n",
       "      <td>63.954106</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.963792</td>\n",
       "      <td>-0.419697</td>\n",
       "      <td>0.134321</td>\n",
       "      <td>28.786247</td>\n",
       "      <td>2.475685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479</th>\n",
       "      <td>Bob Montes</td>\n",
       "      <td>54</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-01-28 09:00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>2017-01-28</td>\n",
       "      <td>53.835946</td>\n",
       "      <td>251.602328</td>\n",
       "      <td>1.120795</td>\n",
       "      <td>7.688889</td>\n",
       "      <td>63.954106</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.963792</td>\n",
       "      <td>-0.419697</td>\n",
       "      <td>0.134321</td>\n",
       "      <td>28.786247</td>\n",
       "      <td>2.475685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480</th>\n",
       "      <td>Dennis Warsen</td>\n",
       "      <td>52</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-01-28 09:00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>2017-01-28</td>\n",
       "      <td>53.835946</td>\n",
       "      <td>251.602328</td>\n",
       "      <td>1.120795</td>\n",
       "      <td>7.688889</td>\n",
       "      <td>63.954106</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.963792</td>\n",
       "      <td>-0.419697</td>\n",
       "      <td>0.134321</td>\n",
       "      <td>28.786247</td>\n",
       "      <td>2.475685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>481</th>\n",
       "      <td>Gonzalo Arestizabal</td>\n",
       "      <td>63</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-01-28 09:00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>2017-01-28</td>\n",
       "      <td>53.835946</td>\n",
       "      <td>251.602328</td>\n",
       "      <td>1.120795</td>\n",
       "      <td>7.688889</td>\n",
       "      <td>63.954106</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.963792</td>\n",
       "      <td>-0.419697</td>\n",
       "      <td>0.134321</td>\n",
       "      <td>28.786247</td>\n",
       "      <td>2.475685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>482</th>\n",
       "      <td>Greg Mann</td>\n",
       "      <td>58</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-01-28 09:00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>2017-01-28</td>\n",
       "      <td>53.835946</td>\n",
       "      <td>251.602328</td>\n",
       "      <td>1.120795</td>\n",
       "      <td>7.688889</td>\n",
       "      <td>63.954106</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.963792</td>\n",
       "      <td>-0.419697</td>\n",
       "      <td>0.134321</td>\n",
       "      <td>28.786247</td>\n",
       "      <td>2.475685</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Name  Raw  Handicap  Adjusted                time  \\\n",
       "478            Ben Horst   65       NaN       NaN 2017-01-28 09:00:00   \n",
       "479           Bob Montes   54       NaN       NaN 2017-01-28 09:00:00   \n",
       "480        Dennis Warsen   52       NaN       NaN 2017-01-28 09:00:00   \n",
       "481  Gonzalo Arestizabal   63       NaN       NaN 2017-01-28 09:00:00   \n",
       "482            Greg Mann   58       NaN       NaN 2017-01-28 09:00:00   \n",
       "\n",
       "     course_id       date  weighted_T  weighted_w_dir  weighted_w_spd  \\\n",
       "478          2 2017-01-28   53.835946      251.602328        1.120795   \n",
       "479          2 2017-01-28   53.835946      251.602328        1.120795   \n",
       "480          2 2017-01-28   53.835946      251.602328        1.120795   \n",
       "481          2 2017-01-28   53.835946      251.602328        1.120795   \n",
       "482          2 2017-01-28   53.835946      251.602328        1.120795   \n",
       "\n",
       "     weighted_w_gust  weighted_rh  weighted_precip  weighted_w_u  \\\n",
       "478         7.688889    63.954106              0.0     -0.963792   \n",
       "479         7.688889    63.954106              0.0     -0.963792   \n",
       "480         7.688889    63.954106              0.0     -0.963792   \n",
       "481         7.688889    63.954106              0.0     -0.963792   \n",
       "482         7.688889    63.954106              0.0     -0.963792   \n",
       "\n",
       "     weighted_w_v  w_gust_var  w_dir_var  w_uv_var  \n",
       "478     -0.419697    0.134321  28.786247  2.475685  \n",
       "479     -0.419697    0.134321  28.786247  2.475685  \n",
       "480     -0.419697    0.134321  28.786247  2.475685  \n",
       "481     -0.419697    0.134321  28.786247  2.475685  \n",
       "482     -0.419697    0.134321  28.786247  2.475685  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop any rows from all_df that do not have weather data\n",
    "all_df = all_df.dropna(subset = ['weighted_T'])\n",
    "all_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_wx_impact(model_info):\n",
    "    \"\"\"Given a dictionary with coefficients of a weather model on disc golf scores, compute the maximum potential impact\n",
    "    of weather on score, using standards for 'extreme' weather in the San Francisco Bay Area.  Model coefficient keys\n",
    "    checked include 'T_coeff' for temperature, 'wsp_coeff' for wind speed, 'wgust_coeff' for wind gust, 'precip_coeff' \n",
    "    for precipitation intensity, and 'dirvar_coeff' for wind direction variance.  Units are Imperial, with in/5 min\n",
    "    for precipitation intensity\"\"\"\n",
    "    \n",
    "    ranges_dict = {'T_coeff':40,'wspd_coeff':20,'wgust_coeff':40,'precip_coeff':0.15,'dirvar_coeff':10000}\n",
    "    impact_sum = 0\n",
    "    for coeff_name, impact_value in ranges_dict.items():\n",
    "        try:\n",
    "            impact_sum += abs(model_info[coeff_name]) * impact_value\n",
    "        except (KeyError, ValueError):\n",
    "            pass\n",
    "    return impact_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def model_player_performance(player : str, course : int):\n",
    "    \"\"\"Given a player name and course id, return model parameters indicating the effects of weather on expected score.\n",
    "    The model will return a dictionary with coefficients for easy identification.  This funciton uses global values\n",
    "    that must be previously computed and available.\"\"\"\n",
    "    \n",
    "    model_dict = {}\n",
    "    model_dict['player'] = player\n",
    "    model_dict['course_id'] = course\n",
    "    player_df = all_df[(all_df['Name'] == player) & (all_df['course_id'] == course)]\n",
    "    # If zero or one games are found, impute by avg and std from all courses\n",
    "    # Because player list comes from all_df, there must be at leat one game \n",
    "    model_dict['n_values'] = len(player_df)\n",
    "    if len(player_df) < 2:\n",
    "        player_atall_df = all_df[all_df['Name'] == player]\n",
    "        model_dict['intercept'] = player_atall_df['Raw'].mean()\n",
    "        if len(player_atall_df) > 1:\n",
    "            model_dict['mse'] = player_atall_df['Raw'].std() * player_atall_df['Raw'].std()\n",
    "        elif len(player_df == 1):  # This is the case with only one game ever played, on the current course\n",
    "            model_dict['mse'] = mse1to2_same_course[course]\n",
    "        else:  # This is the case with only one game ever played, and on a different course \n",
    "            model_dict['mse'] = mse1to2_different_course\n",
    "        if model_dict['mse'] < low_var_cutoff:\n",
    "            model_dict['mse'] = low_var_cutoff\n",
    "        return model_dict\n",
    "    elif len(player_df) < 4:   #This case is 2 or 3 games on the current course, not enough for ARIMA\n",
    "        model_dict['intercept'] = player_df['Raw'].mean()\n",
    "        model_dict['mse'] = player_df['Raw'].std() * player_df['Raw'].std()\n",
    "        if model_dict['mse'] < low_var_cutoff:\n",
    "            model_dict['mse'] = low_var_cutoff\n",
    "        return model_dict\n",
    "    # else... if 4 or more games are found, try to do weather-based or ARIMA model \n",
    "    # Replace index with the cumulative number of games played, and make that into a column\n",
    "    player_df = player_df.reset_index()\n",
    "    player_df = player_df.drop(columns = ['index'])\n",
    "    player_df = player_df.reset_index()\n",
    "    # Set list to hold model items and coefficient names\n",
    "    model_factors = ['index','weighted_T','weighted_w_spd','weighted_w_gust','weighted_precip','w_dir_var']\n",
    "    coeff_names = ['cumgame_coeff','T_coeff','wspd_coeff','wgust_coeff','precip_coeff','dirvar_coeff']\n",
    "    # Assumes first factor will be time-dependent and the rest weather-dependent\n",
    "    # Check for any weather variable that is highly correlated with time (i.e. model_factor[0]) and remove it\n",
    "    removed_corr = 0\n",
    "    new_model_factors, new_coeff_names = ([] for _ in range(2))\n",
    "    for ix, factor in enumerate(model_factors):\n",
    "        if ix == 0:\n",
    "            continue\n",
    "        corr = player_df.corr()[model_factors[0]][factor]\n",
    "        if corr < 0.8:\n",
    "            new_model_factors.append(factor)\n",
    "            new_coeff_names.append(coeff_names[ix])\n",
    "        else:\n",
    "            removed_corr += 1\n",
    "    model_dict['removed_corr'] = removed_corr\n",
    "    # If the number of data points is too small or no weather factors are left, go with ARIMA\n",
    "    if (len(new_model_factors) == 0) or (len(new_model_factors) > len(player_df) - 2):\n",
    "        x = player_df['index'].values.reshape(-1,1)\n",
    "        y = player_df['Raw'].values\n",
    "        lr = LinearRegression()\n",
    "        lr.fit(x,y)\n",
    "        ypred = lr.predict(x)\n",
    "        next_game_x = np.array(len(player_df),ndmin=2)\n",
    "        next_game_score = lr.predict(next_game_x)\n",
    "        # If ARIMA predicts a score outside of a player's known range, then revert to average... \n",
    "        if (next_game_score < player_df['Raw'].min()) or (next_game_score > player_df['Raw'].max()):\n",
    "            model_dict['prediction_score'] = 0\n",
    "            model_dict['intercept'] = np.mean(y)\n",
    "            model_dict['mse'] = np.std(y) * np.std(y)\n",
    "        else:\n",
    "            model_dict['prediction_score'] = lr.score(x,y)\n",
    "            model_dict['intercept'] = lr.intercept_\n",
    "            model_dict['cumgame_coeff'] = lr.coef_[0]\n",
    "            model_dict['mse'] = mean_squared_error(y, ypred)\n",
    "        if model_dict['mse'] < low_var_cutoff:\n",
    "            model_dict['mse'] = low_var_cutoff\n",
    "        return model_dict\n",
    "    else:   # Enough values for weather-based model\n",
    "        X = player_df[new_model_factors].values\n",
    "        y = player_df['Raw'].values\n",
    "        scaler = StandardScaler()\n",
    "        max_acceptable_wx_impact = 0.4 * np.mean(y)\n",
    "        test_alphas = np.linspace(0.01,10,num=50)\n",
    "        wx_impact_not_acceptable = True\n",
    "        attempts = 0\n",
    "        while( (attempts < 11) and (wx_impact_not_acceptable) ):\n",
    "            lr = ElasticNetCV(l1_ratio = [0.05, 0.2, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 0.95, 0.99], cv = 3, \n",
    "                            alphas = test_alphas, max_iter = 500, random_state=42)\n",
    "            pipeline = make_pipeline(scaler, lr)\n",
    "            pipeline.fit(X,y)\n",
    "            scaled_coeff = pipeline['elasticnetcv'].coef_ \n",
    "            coeff_tuple = np.true_divide(scaled_coeff, pipeline['standardscaler'].scale_)\n",
    "            for ix, coeff in enumerate(coeff_tuple):\n",
    "                model_dict[new_coeff_names[ix]] = coeff_tuple[ix]\n",
    "            chosen_alpha = pipeline['elasticnetcv'].alpha_\n",
    "            test_alphas = np.linspace(chosen_alpha * 2, chosen_alpha * 2 + 10, 100)\n",
    "            wx_impact_not_acceptable = (compute_wx_impact(model_dict) > max_acceptable_wx_impact)\n",
    "            attempts += 1\n",
    "        scaled_intercept = pipeline['elasticnetcv'].intercept_\n",
    "        model_dict['intercept'] = scaled_intercept - np.dot(coeff_tuple, pipeline['standardscaler'].mean_)\n",
    "        ypred = pipeline.predict(X)\n",
    "        model_dict['prediction_score'] = pipeline.score(X,y)\n",
    "        model_dict['mse'] = mean_squared_error(y, ypred)\n",
    "        model_dict['l1'] = pipeline['elasticnetcv'].l1_ratio_\n",
    "        model_dict['alpha'] = pipeline['elasticnetcv'].alpha_\n",
    "        model_dict['n_iter'] = pipeline['elasticnetcv'].n_iter_\n",
    "        if model_dict['mse'] < low_var_cutoff:\n",
    "            model_dict['mse'] = low_var_cutoff\n",
    "    return model_dict    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.003791144653748302, tolerance: 0.002475\n",
      "  positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.009724633082956069, tolerance: 0.002475\n",
      "  positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.00917052175236199, tolerance: 0.0025\n",
      "  positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.007736203625309412, tolerance: 0.002475\n",
      "  positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.023043395340229953, tolerance: 0.0025\n",
      "  positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.0070798735824501025, tolerance: 0.002475\n",
      "  positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.04455289279178391, tolerance: 0.0025\n",
      "  positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.01660818066979919, tolerance: 0.013480000000000002\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.03552981129082233, tolerance: 0.013480000000000002\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.012629988831625916, tolerance: 0.005350000000000001\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.03473709392544411, tolerance: 0.005350000000000001\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.020253850779992533, tolerance: 0.004933333333333334\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.09661246200008211, tolerance: 0.005350000000000001\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.10916711849809424, tolerance: 0.004933333333333334\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.2566711489893514, tolerance: 0.005350000000000001\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.5592992392568998, tolerance: 0.004933333333333334\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.6154781354054601, tolerance: 0.005350000000000001\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.105853953030154, tolerance: 0.004933333333333334\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.8580216754483898, tolerance: 0.005350000000000001\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.6936243453833546, tolerance: 0.004933333333333334\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.0306249628540187, tolerance: 0.005350000000000001\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.012826342331125673, tolerance: 0.01192\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.03965920761966757, tolerance: 0.01192\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.12735302422152905, tolerance: 0.01192\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.11400473582014925, tolerance: 0.01192\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.6283522516079572, tolerance: 0.01192\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.597836845175486, tolerance: 0.01192\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2.0956004929247163, tolerance: 0.01192\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2.3132671448012547, tolerance: 0.01192\n",
      "  tol, rng, random, positive)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.006769847291773878, tolerance: 0.003275\n",
      "  positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.031197814374606114, tolerance: 0.003275\n",
      "  positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.05865126418996436, tolerance: 0.003275\n",
      "  positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.10118081761788211, tolerance: 0.003275\n",
      "  positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.17303176712290336, tolerance: 0.003275\n",
      "  positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.26290565668241794, tolerance: 0.003275\n",
      "  positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.2606928436690171, tolerance: 0.003275\n",
      "  positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.14579239063492266, tolerance: 0.003275\n",
      "  positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.005411909937089343, tolerance: 0.003275\n",
      "  positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.015834740842796513, tolerance: 0.012933333333333335\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.038695629838434, tolerance: 0.0074\n",
      "  positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.08728473765507205, tolerance: 0.0074\n",
      "  positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.18504436630331655, tolerance: 0.0074\n",
      "  positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.35193537698272914, tolerance: 0.0074\n",
      "  positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.5705961035766214, tolerance: 0.0074\n",
      "  positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.7550370908798533, tolerance: 0.0074\n",
      "  positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.7930510808226086, tolerance: 0.0074\n",
      "  positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.7790217413351672, tolerance: 0.0074\n",
      "  positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.02291657011389847, tolerance: 0.017480000000000002\n",
      "  positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.10975309791821597, tolerance: 0.017480000000000002\n",
      "  positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.11578297263714887, tolerance: 0.017283333333333335\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.03390917233499141, tolerance: 0.017480000000000002\n",
      "  positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2.7644755381503217, tolerance: 0.017283333333333335\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.2806657275991508, tolerance: 0.017480000000000002\n",
      "  positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 11.099643004096066, tolerance: 0.017283333333333335\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.023591284865119633, tolerance: 0.017933333333333336\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.15993425458917443, tolerance: 0.017933333333333336\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.0272268403253193, tolerance: 0.017933333333333336\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4.854794340290546, tolerance: 0.017933333333333336\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 12.269758286227905, tolerance: 0.017933333333333336\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 14.098444620504846, tolerance: 0.017933333333333336\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 12.32541014822147, tolerance: 0.017933333333333336\n",
      "  tol, rng, random, positive)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.008785979855538528, tolerance: 0.007883333333333334\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.03803243669771206, tolerance: 0.007883333333333334\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.1775376425870192, tolerance: 0.007883333333333334\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.34906040329235566, tolerance: 0.007883333333333334\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2.2386521120085376, tolerance: 0.007883333333333334\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 6.342051864218421, tolerance: 0.007883333333333334\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 8.299869996010598, tolerance: 0.007883333333333334\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 8.901410853091477, tolerance: 0.007883333333333334\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.011738281920658178, tolerance: 0.01032\n",
      "  positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.034867218356590346, tolerance: 0.01032\n",
      "  positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.10009778820200821, tolerance: 0.01032\n",
      "  positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.2418912388133012, tolerance: 0.01032\n",
      "  positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.30746578382539047, tolerance: 0.01032\n",
      "  positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.10268141218511609, tolerance: 0.01032\n",
      "  positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.008474621779927374, tolerance: 0.0036000000000000003\n",
      "  positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.016201395497704156, tolerance: 0.0036000000000000003\n",
      "  positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.025416360058538284, tolerance: 0.0036000000000000003\n",
      "  positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.045226715035212806, tolerance: 0.010733333333333334\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.2062787408166713, tolerance: 0.010733333333333334\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.44126812864962517, tolerance: 0.010733333333333334\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.7997125252797019, tolerance: 0.010733333333333334\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.009034074486974575, tolerance: 0.005880000000000001\n",
      "  positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.029311758108190533, tolerance: 0.005880000000000001\n",
      "  positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.040599432658320334, tolerance: 0.005880000000000001\n",
      "  positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.02980865511375297, tolerance: 0.0092\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.12163235522561988, tolerance: 0.005880000000000001\n",
      "  positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.06294610667549033, tolerance: 0.0092\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.18346672232934436, tolerance: 0.005880000000000001\n",
      "  positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.10823360792703846, tolerance: 0.0092\n",
      "  tol, rng, random, positive)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.004372853452059233, tolerance: 0.004333333333333334\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.012474109361232166, tolerance: 0.003\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.0051099043316860104, tolerance: 0.0015333333333333334\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.01403753411956199, tolerance: 0.0015333333333333334\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.03978592013173987, tolerance: 0.0015333333333333334\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.11217519790837915, tolerance: 0.0015333333333333334\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.2968170240739241, tolerance: 0.0015333333333333334\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.6657776742647847, tolerance: 0.0015333333333333334\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.8912406739313838, tolerance: 0.0015333333333333334\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.035018149170242, tolerance: 0.0015333333333333334\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.016043657883590967, tolerance: 0.008483333333333334\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.00535346906870382, tolerance: 0.005083333333333333\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.043830299782325, tolerance: 0.008483333333333334\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.024276827867606432, tolerance: 0.005083333333333333\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.12051414673002458, tolerance: 0.008483333333333334\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.08864503941658519, tolerance: 0.005083333333333333\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.007061638562186445, tolerance: 0.003933333333333333\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.31544586883158354, tolerance: 0.008483333333333334\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.1613232666385831, tolerance: 0.005083333333333333\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.019208412792377505, tolerance: 0.003933333333333333\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.47672177205021904, tolerance: 0.008483333333333334\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.24663010101694205, tolerance: 0.005083333333333333\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.044477612500337216, tolerance: 0.003933333333333333\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.6162149973980506, tolerance: 0.008483333333333334\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.0038726406504138618, tolerance: 0.003280000000000001\n",
      "  positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.005755309327976581, tolerance: 0.003280000000000001\n",
      "  positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.004701698941379909, tolerance: 0.003280000000000001\n",
      "  positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.004476346731298922, tolerance: 0.003280000000000001\n",
      "  positive)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.006326519354726834, tolerance: 0.0041\n",
      "  positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.029389958163636543, tolerance: 0.0041\n",
      "  positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.12133596976106809, tolerance: 0.0041\n",
      "  positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.38476467599184616, tolerance: 0.0041\n",
      "  positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.7543439861452772, tolerance: 0.0041\n",
      "  positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.767680857656541, tolerance: 0.0041\n",
      "  positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.46416091415106364, tolerance: 0.0041\n",
      "  positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.01612467134015283, tolerance: 0.0041\n",
      "  positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.2169916811695849, tolerance: 0.0041\n",
      "  positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.5492057949084179, tolerance: 0.0041\n",
      "  positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.7505010726308605, tolerance: 0.0041\n",
      "  positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.019174134862963044, tolerance: 0.0041\n",
      "  positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.003928894427531304, tolerance: 0.0035200000000000006\n",
      "  positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.0066784977098670595, tolerance: 0.0035200000000000006\n",
      "  positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.048274095063105094, tolerance: 0.0035200000000000006\n",
      "  positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.13441267755252362, tolerance: 0.0035200000000000006\n",
      "  positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.2991080823176109, tolerance: 0.0035200000000000006\n",
      "  positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.5083569244230999, tolerance: 0.0035200000000000006\n",
      "  positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.5424363136548642, tolerance: 0.0035200000000000006\n",
      "  positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.3514257951939972, tolerance: 0.0035200000000000006\n",
      "  positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.3722520697432714, tolerance: 0.0035200000000000006\n",
      "  positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.9967919801392501, tolerance: 0.0035200000000000006\n",
      "  positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.0077729424468957475, tolerance: 0.007733333333333334\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.018271010992201298, tolerance: 0.007733333333333334\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.042470835493084946, tolerance: 0.007733333333333334\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.06436835724142131, tolerance: 0.007733333333333334\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.08920871501421762, tolerance: 0.007733333333333334\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.002297078395868485, tolerance: 0.00108\n",
      "  positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.004113720505969712, tolerance: 0.00108\n",
      "  positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.006695882667214215, tolerance: 0.005483333333333335\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.009910491328634391, tolerance: 0.005483333333333335\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.014093653047598964, tolerance: 0.005483333333333335\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.026887109229001005, tolerance: 0.005483333333333335\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.013587066723445673, tolerance: 0.00575\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.011865419573403813, tolerance: 0.00575\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.06519190763869886, tolerance: 0.00575\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.17562762549160738, tolerance: 0.00575\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.47544539837127786, tolerance: 0.00575\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.2131597615835048, tolerance: 0.00575\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2.670825019706321, tolerance: 0.00575\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4.5813649813172965, tolerance: 0.00575\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 5.125532731833523, tolerance: 0.00575\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4.783626359156283, tolerance: 0.00575\n",
      "  tol, rng, random, positive)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.01322653583684863, tolerance: 0.013085714285714287\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.018309420472404803, tolerance: 0.013085714285714287\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.00608602327809038, tolerance: 0.004683333333333334\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.014604919721337595, tolerance: 0.004683333333333334\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.03726803319630667, tolerance: 0.004683333333333334\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.0027379408224280644, tolerance: 0.0016799999999999999\n",
      "  positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.004693512458028515, tolerance: 0.0016799999999999999\n",
      "  positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.002340248470643902, tolerance: 0.0016799999999999999\n",
      "  positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.008343868324778458, tolerance: 0.0016799999999999999\n",
      "  positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.014358390528538822, tolerance: 0.0016799999999999999\n",
      "  positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.04795157429016278, tolerance: 0.01052\n",
      "  positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.015126720922239656, tolerance: 0.008\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.061122001753808775, tolerance: 0.008\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.21220208211565872, tolerance: 0.008\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.35688826348376157, tolerance: 0.008\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.48948557003532356, tolerance: 0.008\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.009765066041445891, tolerance: 0.005733333333333334\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.05238879442439859, tolerance: 0.005733333333333334\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.1174291299479806, tolerance: 0.005733333333333334\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.21195482971395163, tolerance: 0.005733333333333334\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.0180824467513597, tolerance: 0.01732\n",
      "  positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.013125901963670028, tolerance: 0.007733333333333333\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.047579147640010255, tolerance: 0.007733333333333333\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.08837220933732182, tolerance: 0.007733333333333333\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.1403039483485352, tolerance: 0.007733333333333333\n",
      "  tol, rng, random, positive)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>T_coeff</th>\n",
       "      <th>alpha</th>\n",
       "      <th>course_id</th>\n",
       "      <th>cumgame_coeff</th>\n",
       "      <th>dirvar_coeff</th>\n",
       "      <th>intercept</th>\n",
       "      <th>l1</th>\n",
       "      <th>mse</th>\n",
       "      <th>n_iter</th>\n",
       "      <th>n_values</th>\n",
       "      <th>player</th>\n",
       "      <th>precip_coeff</th>\n",
       "      <th>prediction_score</th>\n",
       "      <th>removed_corr</th>\n",
       "      <th>wgust_coeff</th>\n",
       "      <th>wspd_coeff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>68.111111</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.361111</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Ben Horst</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>68.111111</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.361111</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Ben Horst</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>68.111111</td>\n",
       "      <td>0.4</td>\n",
       "      <td>16.320988</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9</td>\n",
       "      <td>Ben Horst</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>54.607143</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.025132</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Bob Montes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>52.400000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.620000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>Bob Montes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.003012</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   T_coeff  alpha  course_id  cumgame_coeff  dirvar_coeff  intercept   l1  \\\n",
       "0      NaN    NaN          0            NaN           NaN  68.111111  NaN   \n",
       "1      NaN    NaN          1            NaN           NaN  68.111111  NaN   \n",
       "2      NaN   10.0          2            NaN          -0.0  68.111111  0.4   \n",
       "3      NaN    NaN          0            NaN           NaN  54.607143  NaN   \n",
       "4      NaN    NaN          1            0.1           NaN  52.400000  NaN   \n",
       "\n",
       "         mse  n_iter  n_values      player  precip_coeff  prediction_score  \\\n",
       "0  18.361111     NaN         0   Ben Horst           NaN               NaN   \n",
       "1  18.361111     NaN         0   Ben Horst           NaN               NaN   \n",
       "2  16.320988     1.0         9   Ben Horst           NaN          0.000000   \n",
       "3  14.025132     NaN         0  Bob Montes           NaN               NaN   \n",
       "4   6.620000     NaN         5  Bob Montes           NaN          0.003012   \n",
       "\n",
       "   removed_corr  wgust_coeff  wspd_coeff  \n",
       "0           NaN          NaN         NaN  \n",
       "1           NaN          NaN         NaN  \n",
       "2           2.0          0.0         0.0  \n",
       "3           NaN          NaN         NaN  \n",
       "4           1.0          NaN         NaN  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Make list of player names\n",
    "player_names = all_df['Name'].unique()\n",
    "perf_dicts = []\n",
    "for player_name in player_names:\n",
    "    for course_id in range(all_df['course_id'].max() + 1):\n",
    "        perf_dict = model_player_performance(player_name, course_id)\n",
    "        perf_dicts.append(perf_dict)\n",
    "            \n",
    "perf_model_df = pd.DataFrame(perf_dicts)\n",
    "perf_model_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    159\n",
       "1.0     58\n",
       "2.0      7\n",
       "Name: removed_corr, dtype: int64"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perf_model_df.removed_corr.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>T_coeff</th>\n",
       "      <th>alpha</th>\n",
       "      <th>course_id</th>\n",
       "      <th>cumgame_coeff</th>\n",
       "      <th>dirvar_coeff</th>\n",
       "      <th>intercept</th>\n",
       "      <th>l1</th>\n",
       "      <th>mse</th>\n",
       "      <th>n_iter</th>\n",
       "      <th>n_values</th>\n",
       "      <th>player</th>\n",
       "      <th>precip_coeff</th>\n",
       "      <th>prediction_score</th>\n",
       "      <th>removed_corr</th>\n",
       "      <th>wgust_coeff</th>\n",
       "      <th>wspd_coeff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.059120</td>\n",
       "      <td>1.711020</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>56.679093</td>\n",
       "      <td>0.05</td>\n",
       "      <td>10.659072</td>\n",
       "      <td>6.0</td>\n",
       "      <td>23</td>\n",
       "      <td>Bob Montes</td>\n",
       "      <td>56.543837</td>\n",
       "      <td>0.236162</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.137270</td>\n",
       "      <td>0.195796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.049826</td>\n",
       "      <td>1.029388</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000081</td>\n",
       "      <td>52.243656</td>\n",
       "      <td>0.05</td>\n",
       "      <td>2.208735</td>\n",
       "      <td>7.0</td>\n",
       "      <td>11</td>\n",
       "      <td>Dennis Warsen</td>\n",
       "      <td>4.289653</td>\n",
       "      <td>0.325109</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.081629</td>\n",
       "      <td>0.132396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.147365</td>\n",
       "      <td>1.711020</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.000623</td>\n",
       "      <td>66.224316</td>\n",
       "      <td>0.05</td>\n",
       "      <td>8.682143</td>\n",
       "      <td>5.0</td>\n",
       "      <td>14</td>\n",
       "      <td>Dennis Warsen</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.461487</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.119753</td>\n",
       "      <td>0.168692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.825510</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>52.208302</td>\n",
       "      <td>0.50</td>\n",
       "      <td>13.921088</td>\n",
       "      <td>12.0</td>\n",
       "      <td>53</td>\n",
       "      <td>Dennis Warsen</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.126004</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.167198</td>\n",
       "      <td>0.092093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-0.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>0.20</td>\n",
       "      <td>12.500000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8</td>\n",
       "      <td>Gonzalo Arestizabal</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     T_coeff      alpha  course_id  cumgame_coeff  dirvar_coeff  intercept  \\\n",
       "5  -0.059120   1.711020          2            NaN      0.000038  56.679093   \n",
       "6  -0.049826   1.029388          0            NaN      0.000081  52.243656   \n",
       "7  -0.147365   1.711020          1            NaN     -0.000623  66.224316   \n",
       "8  -0.000000   0.825510          2            NaN     -0.000000  52.208302   \n",
       "10 -0.000000  10.000000          1            NaN     -0.000000  65.000000   \n",
       "\n",
       "      l1        mse  n_iter  n_values               player  precip_coeff  \\\n",
       "5   0.05  10.659072     6.0        23           Bob Montes     56.543837   \n",
       "6   0.05   2.208735     7.0        11        Dennis Warsen      4.289653   \n",
       "7   0.05   8.682143     5.0        14        Dennis Warsen           NaN   \n",
       "8   0.50  13.921088    12.0        53        Dennis Warsen      0.000000   \n",
       "10  0.20  12.500000     1.0         8  Gonzalo Arestizabal           NaN   \n",
       "\n",
       "    prediction_score  removed_corr  wgust_coeff  wspd_coeff  \n",
       "5           0.236162           0.0     0.137270    0.195796  \n",
       "6           0.325109           0.0     0.081629    0.132396  \n",
       "7           0.461487           1.0     0.119753    0.168692  \n",
       "8           0.126004           0.0     0.167198    0.092093  \n",
       "10          0.000000           1.0    -0.000000    0.000000  "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perf_model_small = perf_model_df.dropna(subset=['T_coeff'])\n",
    "print(len(perf_model_small))\n",
    "perf_model_small.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([106.,  15.,  36.]),\n",
       " array([0.        , 0.66666667, 1.33333333, 2.        ]),\n",
       " <a list of 3 Patch objects>)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(perf_model_small['course_id'],bins=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 1.,  0.,  1.,  0.,  2.,  1.,  0.,  3.,  4.,  2.,  4.,  6.,  6.,\n",
       "        10., 10.,  6.,  2.,  1.,  2.,  1.,  2.,  1.,  1.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  1.]),\n",
       " array([-0.31216142, -0.29083567, -0.26950992, -0.24818418, -0.22685843,\n",
       "        -0.20553269, -0.18420694, -0.16288119, -0.14155545, -0.1202297 ,\n",
       "        -0.09890396, -0.07757821, -0.05625247, -0.03492672, -0.01360097,\n",
       "         0.00772477,  0.02905052,  0.05037626,  0.07170201,  0.09302776,\n",
       "         0.1143535 ,  0.13567925,  0.15700499,  0.17833074,  0.19965649,\n",
       "         0.22098223,  0.24230798,  0.26363372,  0.28495947,  0.30628521,\n",
       "         0.32761096]),\n",
       " <a list of 30 Patch objects>)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(perf_model_small[perf_model_small['T_coeff'] !=0]['T_coeff'], bins = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([21., 46., 47., 24., 10.,  3.,  3.,  0.,  2.,  1.]),\n",
       " array([ 1.38721535,  5.74849382, 10.10977228, 14.47105075, 18.83232921,\n",
       "        23.19360768, 27.55488614, 31.91616461, 36.27744307, 40.63872154,\n",
       "        45.        ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(perf_model_small['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1., 0., 0., 0., 1., 0., 1., 1., 1., 2., 3., 0., 4., 4., 2., 8., 3.,\n",
       "        3., 2., 5., 5., 2., 0., 0., 2., 0., 1., 0., 0., 2.]),\n",
       " array([-84.89305583, -77.9030638 , -70.91307177, -63.92307974,\n",
       "        -56.93308771, -49.94309568, -42.95310365, -35.96311162,\n",
       "        -28.97311959, -21.98312757, -14.99313554,  -8.00314351,\n",
       "         -1.01315148,   5.97684055,  12.96683258,  19.95682461,\n",
       "         26.94681664,  33.93680867,  40.9268007 ,  47.91679273,\n",
       "         54.90678476,  61.89677679,  68.88676882,  75.87676085,\n",
       "         82.86675288,  89.85674491,  96.84673694, 103.83672897,\n",
       "        110.826721  , 117.81671303, 124.80670506]),\n",
       " <a list of 30 Patch objects>)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(perf_model_small[perf_model_small['precip_coeff'] != 0]['precip_coeff'], bins = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 2.,  0.,  0.,  0.,  1.,  2.,  0.,  3.,  2.,  1.,  4.,  7.,  6.,\n",
       "        12., 11.,  3.,  4.,  2.,  3.,  3.,  1.,  1.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  1.]),\n",
       " array([-0.61169779, -0.5573407 , -0.5029836 , -0.44862651, -0.39426942,\n",
       "        -0.33991233, -0.28555523, -0.23119814, -0.17684105, -0.12248395,\n",
       "        -0.06812686, -0.01376977,  0.04058732,  0.09494442,  0.14930151,\n",
       "         0.2036586 ,  0.2580157 ,  0.31237279,  0.36672988,  0.42108697,\n",
       "         0.47544407,  0.52980116,  0.58415825,  0.63851535,  0.69287244,\n",
       "         0.74722953,  0.80158662,  0.85594372,  0.91030081,  0.9646579 ,\n",
       "         1.01901499]),\n",
       " <a list of 30 Patch objects>)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(perf_model_small[perf_model_small['wspd_coeff'] != 0]['wspd_coeff'], bins = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 2., 4., 8., 3.,\n",
       "        8., 9., 8., 7., 5., 5., 2., 2., 1., 1., 0., 0., 1.]),\n",
       " array([-0.47689332, -0.44850002, -0.42010673, -0.39171343, -0.36332014,\n",
       "        -0.33492684, -0.30653355, -0.27814025, -0.24974696, -0.22135366,\n",
       "        -0.19296037, -0.16456707, -0.13617377, -0.10778048, -0.07938718,\n",
       "        -0.05099389, -0.02260059,  0.0057927 ,  0.034186  ,  0.06257929,\n",
       "         0.09097259,  0.11936588,  0.14775918,  0.17615247,  0.20454577,\n",
       "         0.23293906,  0.26133236,  0.28972566,  0.31811895,  0.34651225,\n",
       "         0.37490554]),\n",
       " <a list of 30 Patch objects>)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(perf_model_small[perf_model_small['wgust_coeff'] != 0]['wgust_coeff'], bins = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 1.,  0.,  1.,  0.,  0.,  0.,  1.,  0.,  2.,  2.,  4.,  5.,  4.,\n",
       "         2.,  6., 10.,  6.,  5.,  4.,  5.,  1.,  0.,  1.,  1.,  0.,  1.,\n",
       "         0.,  1.,  3.,  1.]),\n",
       " array([-1.78135911e-03, -1.66696597e-03, -1.55257283e-03, -1.43817970e-03,\n",
       "        -1.32378656e-03, -1.20939342e-03, -1.09500028e-03, -9.80607145e-04,\n",
       "        -8.66214007e-04, -7.51820870e-04, -6.37427732e-04, -5.23034594e-04,\n",
       "        -4.08641457e-04, -2.94248319e-04, -1.79855181e-04, -6.54620439e-05,\n",
       "         4.89310937e-05,  1.63324231e-04,  2.77717369e-04,  3.92110507e-04,\n",
       "         5.06503644e-04,  6.20896782e-04,  7.35289919e-04,  8.49683057e-04,\n",
       "         9.64076195e-04,  1.07846933e-03,  1.19286247e-03,  1.30725561e-03,\n",
       "         1.42164875e-03,  1.53604188e-03,  1.65043502e-03]),\n",
       " <a list of 30 Patch objects>)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(perf_model_small[perf_model_small['dirvar_coeff'] !=0]['dirvar_coeff'], bins = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([78., 16., 22., 18., 10.,  3.,  3.,  2.,  4.,  1.]),\n",
       " array([0.        , 0.07879916, 0.15759832, 0.23639748, 0.31519665,\n",
       "        0.39399581, 0.47279497, 0.55159413, 0.63039329, 0.70919245,\n",
       "        0.78799162]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(perf_model_small['prediction_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>T_coeff</th>\n",
       "      <th>alpha</th>\n",
       "      <th>course_id</th>\n",
       "      <th>cumgame_coeff</th>\n",
       "      <th>dirvar_coeff</th>\n",
       "      <th>intercept</th>\n",
       "      <th>l1</th>\n",
       "      <th>mse</th>\n",
       "      <th>n_iter</th>\n",
       "      <th>n_values</th>\n",
       "      <th>player</th>\n",
       "      <th>precip_coeff</th>\n",
       "      <th>prediction_score</th>\n",
       "      <th>removed_corr</th>\n",
       "      <th>wgust_coeff</th>\n",
       "      <th>wspd_coeff</th>\n",
       "      <th>coeff_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.059120</td>\n",
       "      <td>1.711020</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>56.679093</td>\n",
       "      <td>0.05</td>\n",
       "      <td>10.659072</td>\n",
       "      <td>6.0</td>\n",
       "      <td>23</td>\n",
       "      <td>Bob Montes</td>\n",
       "      <td>56.543837</td>\n",
       "      <td>0.236162</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.137270</td>\n",
       "      <td>0.195796</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.049826</td>\n",
       "      <td>1.029388</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000081</td>\n",
       "      <td>52.243656</td>\n",
       "      <td>0.05</td>\n",
       "      <td>2.208735</td>\n",
       "      <td>7.0</td>\n",
       "      <td>11</td>\n",
       "      <td>Dennis Warsen</td>\n",
       "      <td>4.289653</td>\n",
       "      <td>0.325109</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.081629</td>\n",
       "      <td>0.132396</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.147365</td>\n",
       "      <td>1.711020</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.000623</td>\n",
       "      <td>66.224316</td>\n",
       "      <td>0.05</td>\n",
       "      <td>8.682143</td>\n",
       "      <td>5.0</td>\n",
       "      <td>14</td>\n",
       "      <td>Dennis Warsen</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.461487</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.119753</td>\n",
       "      <td>0.168692</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.825510</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>52.208302</td>\n",
       "      <td>0.50</td>\n",
       "      <td>13.921088</td>\n",
       "      <td>12.0</td>\n",
       "      <td>53</td>\n",
       "      <td>Dennis Warsen</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.126004</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.167198</td>\n",
       "      <td>0.092093</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-0.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>0.20</td>\n",
       "      <td>12.500000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8</td>\n",
       "      <td>Gonzalo Arestizabal</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     T_coeff      alpha  course_id  cumgame_coeff  dirvar_coeff  intercept  \\\n",
       "5  -0.059120   1.711020          2            NaN      0.000038  56.679093   \n",
       "6  -0.049826   1.029388          0            NaN      0.000081  52.243656   \n",
       "7  -0.147365   1.711020          1            NaN     -0.000623  66.224316   \n",
       "8  -0.000000   0.825510          2            NaN     -0.000000  52.208302   \n",
       "10 -0.000000  10.000000          1            NaN     -0.000000  65.000000   \n",
       "\n",
       "      l1        mse  n_iter  n_values               player  precip_coeff  \\\n",
       "5   0.05  10.659072     6.0        23           Bob Montes     56.543837   \n",
       "6   0.05   2.208735     7.0        11        Dennis Warsen      4.289653   \n",
       "7   0.05   8.682143     5.0        14        Dennis Warsen           NaN   \n",
       "8   0.50  13.921088    12.0        53        Dennis Warsen      0.000000   \n",
       "10  0.20  12.500000     1.0         8  Gonzalo Arestizabal           NaN   \n",
       "\n",
       "    prediction_score  removed_corr  wgust_coeff  wspd_coeff  coeff_count  \n",
       "5           0.236162           0.0     0.137270    0.195796            5  \n",
       "6           0.325109           0.0     0.081629    0.132396            5  \n",
       "7           0.461487           1.0     0.119753    0.168692            4  \n",
       "8           0.126004           0.0     0.167198    0.092093            2  \n",
       "10          0.000000           1.0    -0.000000    0.000000            0  "
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coeff_count = []\n",
    "for row in perf_model_small.iterrows():\n",
    "    tmp_count = 0\n",
    "    if row[1]['cumgame_coeff'] and (abs(row[1]['cumgame_coeff']) > 0.000001):\n",
    "        tmp_count += 1\n",
    "    if row[1]['T_coeff'] and (abs(row[1]['T_coeff']) > 0.000001):\n",
    "        tmp_count += 1\n",
    "    if row[1]['precip_coeff'] and (abs(row[1]['precip_coeff']) > 0.000001):\n",
    "        tmp_count += 1\n",
    "    if row[1]['wgust_coeff'] and (abs(row[1]['wgust_coeff']) > 0.000001):\n",
    "        tmp_count += 1\n",
    "    if row[1]['wspd_coeff'] and (abs(row[1]['wspd_coeff']) > 0.000001):\n",
    "        tmp_count += 1\n",
    "    if row[1]['dirvar_coeff'] and (abs(row[1]['dirvar_coeff']) > 0.000001):\n",
    "        tmp_count += 1\n",
    "    coeff_count.append(tmp_count)\n",
    "perf_model_small['coeff_count'] = coeff_count\n",
    "perf_model_small.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    60\n",
       "5    30\n",
       "4    25\n",
       "1    20\n",
       "3    11\n",
       "2    11\n",
       "Name: coeff_count, dtype: int64"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perf_model_small.coeff_count.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.21387755102040817"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perf_model_small.alpha.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x1942d988e10>"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(x=perf_model_small.prediction_score,y=perf_model_small.alpha, alpha = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x1942efc7518>"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(x=perf_model_small.n_values, y=perf_model_small.coeff_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x1942f022ac8>"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(x=perf_model_small.prediction_score, y=perf_model_small.coeff_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x1942f089b70>"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(x=perf_model_small.coeff_count, y=perf_model_small.mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['T_coeff',\n",
       " 'alpha',\n",
       " 'course_id',\n",
       " 'cumgame_coeff',\n",
       " 'dirvar_coeff',\n",
       " 'intercept',\n",
       " 'l1',\n",
       " 'mse',\n",
       " 'n_iter',\n",
       " 'n_values',\n",
       " 'player',\n",
       " 'precip_coeff',\n",
       " 'prediction_score',\n",
       " 'removed_corr',\n",
       " 'wgust_coeff',\n",
       " 'wspd_coeff',\n",
       " 'coeff_count']"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(perf_model_small.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('T_coeff', -0.03414428961664803, 0.10120460538031932),\n",
       " ('alpha', 5.684919728941567, 4.75070680162162),\n",
       " ('course_id', 1.7058823529411764, 0.46017899330842227),\n",
       " ('cumgame_coeff', nan, nan),\n",
       " ('dirvar_coeff', 2.4551892687941338e-05, 0.0006469434346615954),\n",
       " ('intercept', 58.29021306601422, 6.083157784594636),\n",
       " ('l1', 0.33433121019108275, 0.3193247560916836),\n",
       " ('mse', 12.118328472760245, 6.889088681221772),\n",
       " ('n_iter', 3.738853503184713, 4.162017657916814),\n",
       " ('n_values', 13.961783439490446, 10.239995336486363),\n",
       " ('precip_coeff', 27.59904206443039, 40.813515618642036),\n",
       " ('prediction_score', 0.2332486115263072, 0.16736036031687768),\n",
       " ('removed_corr', 1.0769230769230769, 0.2699527623995085),\n",
       " ('wgust_coeff', 0.05157973024445388, 0.11820302142679943),\n",
       " ('wspd_coeff', 0.11192519575742012, 0.2513748179595838),\n",
       " ('coeff_count', 3.350515463917526, 1.527806414393703)]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(col, perf_model_small[perf_model_small[col] != 0][col].mean(), \n",
    " perf_model_small[perf_model_small[col] != 0][col].std()) for col in list(perf_model_small.columns) if col != 'player']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "T_coeff             -0.014571\n",
       "alpha                5.684920\n",
       "course_id            0.554140\n",
       "cumgame_coeff             NaN\n",
       "dirvar_coeff         0.000011\n",
       "intercept           58.290213\n",
       "l1                   0.334331\n",
       "mse                 12.118328\n",
       "n_iter               3.738854\n",
       "n_values            13.961783\n",
       "precip_coeff        12.396180\n",
       "prediction_score     0.144109\n",
       "removed_corr         0.267516\n",
       "wgust_coeff          0.022814\n",
       "wspd_coeff           0.049190\n",
       "coeff_count          2.070064\n",
       "dtype: float64"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perf_model_small.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "T_coeff              0.067973\n",
       "alpha                4.750707\n",
       "course_id            0.842728\n",
       "cumgame_coeff             NaN\n",
       "dirvar_coeff         0.000424\n",
       "intercept            6.083158\n",
       "l1                   0.319325\n",
       "mse                  6.889089\n",
       "n_iter               4.162018\n",
       "n_values            10.239995\n",
       "precip_coeff        30.502433\n",
       "prediction_score     0.173680\n",
       "removed_corr         0.485457\n",
       "wgust_coeff          0.082402\n",
       "wspd_coeff           0.175071\n",
       "coeff_count          2.025842\n",
       "dtype: float64"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perf_model_small.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>player</th>\n",
       "      <th>course_id</th>\n",
       "      <th>mse</th>\n",
       "      <th>coeff_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>969</th>\n",
       "      <td>Jake Ward</td>\n",
       "      <td>0</td>\n",
       "      <td>1.387215</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>Matty Angell</td>\n",
       "      <td>1</td>\n",
       "      <td>1.685748</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1023</th>\n",
       "      <td>Marquis Mallen</td>\n",
       "      <td>0</td>\n",
       "      <td>1.709850</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Juan Fielding</td>\n",
       "      <td>2</td>\n",
       "      <td>2.185550</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Dennis Warsen</td>\n",
       "      <td>0</td>\n",
       "      <td>2.208735</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>798</th>\n",
       "      <td>Dan Santini</td>\n",
       "      <td>0</td>\n",
       "      <td>2.437075</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>705</th>\n",
       "      <td>Mike Sale</td>\n",
       "      <td>0</td>\n",
       "      <td>2.981308</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>873</th>\n",
       "      <td>Trevor Duckworth</td>\n",
       "      <td>0</td>\n",
       "      <td>2.984650</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1074</th>\n",
       "      <td>Randy Waters</td>\n",
       "      <td>0</td>\n",
       "      <td>3.316928</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1077</th>\n",
       "      <td>Ryan Santos</td>\n",
       "      <td>0</td>\n",
       "      <td>3.341589</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>Joe Kestler</td>\n",
       "      <td>0</td>\n",
       "      <td>3.667146</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Jon Braidman</td>\n",
       "      <td>1</td>\n",
       "      <td>3.853628</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>963</th>\n",
       "      <td>Erica Norton</td>\n",
       "      <td>0</td>\n",
       "      <td>3.908192</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>Beau Griffin</td>\n",
       "      <td>2</td>\n",
       "      <td>4.208245</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>Mike Degnan</td>\n",
       "      <td>0</td>\n",
       "      <td>4.260489</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>444</th>\n",
       "      <td>Joe Dannels</td>\n",
       "      <td>0</td>\n",
       "      <td>4.611489</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>Matt Hansen</td>\n",
       "      <td>1</td>\n",
       "      <td>4.681820</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>927</th>\n",
       "      <td>Kevin Smeds</td>\n",
       "      <td>0</td>\n",
       "      <td>4.732644</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>720</th>\n",
       "      <td>Niel Jones</td>\n",
       "      <td>0</td>\n",
       "      <td>4.774943</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>843</th>\n",
       "      <td>Life Gibson</td>\n",
       "      <td>0</td>\n",
       "      <td>5.135802</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>813</th>\n",
       "      <td>Eric Leaf</td>\n",
       "      <td>0</td>\n",
       "      <td>5.405955</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>David Falzone</td>\n",
       "      <td>2</td>\n",
       "      <td>5.950617</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1056</th>\n",
       "      <td>Brett Allen</td>\n",
       "      <td>0</td>\n",
       "      <td>6.130084</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>660</th>\n",
       "      <td>Kevin Eckert</td>\n",
       "      <td>0</td>\n",
       "      <td>6.218965</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Gonzalo Arestizabal</td>\n",
       "      <td>2</td>\n",
       "      <td>6.253195</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>Luiz Celeste</td>\n",
       "      <td>2</td>\n",
       "      <td>6.287787</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>Ben Fox</td>\n",
       "      <td>0</td>\n",
       "      <td>6.330579</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356</th>\n",
       "      <td>Soki Hagiwara</td>\n",
       "      <td>2</td>\n",
       "      <td>6.399261</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>783</th>\n",
       "      <td>Bryan Schmitz</td>\n",
       "      <td>0</td>\n",
       "      <td>6.420629</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>942</th>\n",
       "      <td>Mick Coronel</td>\n",
       "      <td>0</td>\n",
       "      <td>6.437500</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>Arthur Coddington</td>\n",
       "      <td>1</td>\n",
       "      <td>16.910341</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>Marc Atkinson</td>\n",
       "      <td>1</td>\n",
       "      <td>16.916667</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>Bob McGarity</td>\n",
       "      <td>2</td>\n",
       "      <td>17.100210</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>648</th>\n",
       "      <td>Joe Donahue</td>\n",
       "      <td>0</td>\n",
       "      <td>17.240000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>657</th>\n",
       "      <td>Josh Schmidt</td>\n",
       "      <td>0</td>\n",
       "      <td>17.248741</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>Daniel Charlip-Blumlein</td>\n",
       "      <td>0</td>\n",
       "      <td>17.265306</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>Shawn Mercy</td>\n",
       "      <td>0</td>\n",
       "      <td>17.500000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>753</th>\n",
       "      <td>Steven P.</td>\n",
       "      <td>0</td>\n",
       "      <td>17.621302</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>792</th>\n",
       "      <td>Chris Tirrell</td>\n",
       "      <td>0</td>\n",
       "      <td>17.677315</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>804</th>\n",
       "      <td>Dave Van Dollen</td>\n",
       "      <td>0</td>\n",
       "      <td>17.833645</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>Zac Pape</td>\n",
       "      <td>2</td>\n",
       "      <td>18.456747</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>630</th>\n",
       "      <td>Eldridge Manchester</td>\n",
       "      <td>0</td>\n",
       "      <td>19.166667</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>915</th>\n",
       "      <td>Joe Canose</td>\n",
       "      <td>0</td>\n",
       "      <td>19.434555</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>831</th>\n",
       "      <td>Josh Babiak</td>\n",
       "      <td>0</td>\n",
       "      <td>19.636344</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>801</th>\n",
       "      <td>Daniel Johengen</td>\n",
       "      <td>0</td>\n",
       "      <td>19.995006</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1035</th>\n",
       "      <td>Thor Scordelis</td>\n",
       "      <td>0</td>\n",
       "      <td>20.395062</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>561</th>\n",
       "      <td>Andy Rothschild</td>\n",
       "      <td>0</td>\n",
       "      <td>20.875346</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>588</th>\n",
       "      <td>Chris Vanleemput</td>\n",
       "      <td>0</td>\n",
       "      <td>21.107438</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>744</th>\n",
       "      <td>Sean Pierson</td>\n",
       "      <td>0</td>\n",
       "      <td>21.192810</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>747</th>\n",
       "      <td>Sean Saxton</td>\n",
       "      <td>0</td>\n",
       "      <td>21.360000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>Roger Cansler</td>\n",
       "      <td>2</td>\n",
       "      <td>21.754256</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>609</th>\n",
       "      <td>Daniel Humphreys</td>\n",
       "      <td>0</td>\n",
       "      <td>23.283951</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489</th>\n",
       "      <td>John Drago</td>\n",
       "      <td>0</td>\n",
       "      <td>26.859375</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339</th>\n",
       "      <td>Andy Nguyen</td>\n",
       "      <td>0</td>\n",
       "      <td>27.428571</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>579</th>\n",
       "      <td>Candace Romaine</td>\n",
       "      <td>0</td>\n",
       "      <td>27.597633</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>Matt Neiman</td>\n",
       "      <td>0</td>\n",
       "      <td>28.710059</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Aaron Kirby</td>\n",
       "      <td>2</td>\n",
       "      <td>30.953719</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1068</th>\n",
       "      <td>Nick Klein</td>\n",
       "      <td>0</td>\n",
       "      <td>36.359375</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1254</th>\n",
       "      <td>Sylvain Pelletier</td>\n",
       "      <td>0</td>\n",
       "      <td>37.102041</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>Nate Tilman</td>\n",
       "      <td>2</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>157 rows  4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       player  course_id        mse  coeff_count\n",
       "969                 Jake Ward          0   1.387215            5\n",
       "133              Matty Angell          1   1.685748            3\n",
       "1023           Marquis Mallen          0   1.709850            5\n",
       "23              Juan Fielding          2   2.185550            3\n",
       "6               Dennis Warsen          0   2.208735            5\n",
       "798               Dan Santini          0   2.437075            2\n",
       "705                 Mike Sale          0   2.981308            2\n",
       "873          Trevor Duckworth          0   2.984650            5\n",
       "1074             Randy Waters          0   3.316928            5\n",
       "1077              Ryan Santos          0   3.341589            1\n",
       "126               Joe Kestler          0   3.667146            1\n",
       "19               Jon Braidman          1   3.853628            3\n",
       "963              Erica Norton          0   3.908192            1\n",
       "260              Beau Griffin          2   4.208245            4\n",
       "135               Mike Degnan          0   4.260489            5\n",
       "444               Joe Dannels          0   4.611489            2\n",
       "226               Matt Hansen          1   4.681820            1\n",
       "927               Kevin Smeds          0   4.732644            2\n",
       "720                Niel Jones          0   4.774943            4\n",
       "843               Life Gibson          0   5.135802            0\n",
       "813                 Eric Leaf          0   5.405955            4\n",
       "74              David Falzone          2   5.950617            0\n",
       "1056              Brett Allen          0   6.130084            5\n",
       "660              Kevin Eckert          0   6.218965            1\n",
       "11        Gonzalo Arestizabal          2   6.253195            4\n",
       "182              Luiz Celeste          2   6.287787            5\n",
       "567                   Ben Fox          0   6.330579            0\n",
       "356             Soki Hagiwara          2   6.399261            3\n",
       "783             Bryan Schmitz          0   6.420629            4\n",
       "942              Mick Coronel          0   6.437500            0\n",
       "...                       ...        ...        ...          ...\n",
       "196         Arthur Coddington          1  16.910341            4\n",
       "286             Marc Atkinson          1  16.916667            0\n",
       "101              Bob McGarity          2  17.100210            4\n",
       "648               Joe Donahue          0  17.240000            0\n",
       "657              Josh Schmidt          0  17.248741            2\n",
       "252   Daniel Charlip-Blumlein          0  17.265306            0\n",
       "240               Shawn Mercy          0  17.500000            0\n",
       "753                 Steven P.          0  17.621302            0\n",
       "792             Chris Tirrell          0  17.677315            4\n",
       "804           Dave Van Dollen          0  17.833645            5\n",
       "314                  Zac Pape          2  18.456747            0\n",
       "630       Eldridge Manchester          0  19.166667            0\n",
       "915                Joe Canose          0  19.434555            1\n",
       "831               Josh Babiak          0  19.636344            1\n",
       "801           Daniel Johengen          0  19.995006            1\n",
       "1035           Thor Scordelis          0  20.395062            0\n",
       "561           Andy Rothschild          0  20.875346            0\n",
       "588          Chris Vanleemput          0  21.107438            0\n",
       "744              Sean Pierson          0  21.192810            1\n",
       "747               Sean Saxton          0  21.360000            0\n",
       "338             Roger Cansler          2  21.754256            1\n",
       "609          Daniel Humphreys          0  23.283951            0\n",
       "489                John Drago          0  26.859375            0\n",
       "339               Andy Nguyen          0  27.428571            0\n",
       "579           Candace Romaine          0  27.597633            0\n",
       "129               Matt Neiman          0  28.710059            0\n",
       "95                Aaron Kirby          2  30.953719            1\n",
       "1068               Nick Klein          0  36.359375            0\n",
       "1254        Sylvain Pelletier          0  37.102041            0\n",
       "308               Nate Tilman          2  45.000000            0\n",
       "\n",
       "[157 rows x 4 columns]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perf_model_small[['player','course_id','mse','coeff_count']].sort_values(by='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>T_coeff</th>\n",
       "      <th>alpha</th>\n",
       "      <th>course_id</th>\n",
       "      <th>cumgame_coeff</th>\n",
       "      <th>dirvar_coeff</th>\n",
       "      <th>intercept</th>\n",
       "      <th>l1</th>\n",
       "      <th>mse</th>\n",
       "      <th>n_iter</th>\n",
       "      <th>n_values</th>\n",
       "      <th>player</th>\n",
       "      <th>precip_coeff</th>\n",
       "      <th>prediction_score</th>\n",
       "      <th>removed_corr</th>\n",
       "      <th>wgust_coeff</th>\n",
       "      <th>wspd_coeff</th>\n",
       "      <th>coeff_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>969</th>\n",
       "      <td>-0.214726</td>\n",
       "      <td>0.621633</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000250</td>\n",
       "      <td>69.899195</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1.387215</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9</td>\n",
       "      <td>Jake Ward</td>\n",
       "      <td>24.376450</td>\n",
       "      <td>0.787992</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.105301</td>\n",
       "      <td>0.204910</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>-0.264028</td>\n",
       "      <td>0.427755</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.000392</td>\n",
       "      <td>73.722457</td>\n",
       "      <td>0.99</td>\n",
       "      <td>3.853628</td>\n",
       "      <td>14.0</td>\n",
       "      <td>11</td>\n",
       "      <td>Jon Braidman</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.673009</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.057198</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1074</th>\n",
       "      <td>-0.209207</td>\n",
       "      <td>0.855510</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.001061</td>\n",
       "      <td>76.997068</td>\n",
       "      <td>0.05</td>\n",
       "      <td>3.316928</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9</td>\n",
       "      <td>Randy Waters</td>\n",
       "      <td>7.193448</td>\n",
       "      <td>0.660769</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.016341</td>\n",
       "      <td>0.184927</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>444</th>\n",
       "      <td>-0.312161</td>\n",
       "      <td>0.855510</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>69.816125</td>\n",
       "      <td>0.40</td>\n",
       "      <td>4.611489</td>\n",
       "      <td>4.0</td>\n",
       "      <td>12</td>\n",
       "      <td>Joe Dannels</td>\n",
       "      <td>45.608696</td>\n",
       "      <td>0.647342</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>0.000303</td>\n",
       "      <td>2.560000</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>54.884803</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1.685748</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5</td>\n",
       "      <td>Matty Angell</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.636692</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.161420</td>\n",
       "      <td>0.498873</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       T_coeff     alpha  course_id  cumgame_coeff  dirvar_coeff  intercept  \\\n",
       "969  -0.214726  0.621633          0            NaN      0.000250  69.899195   \n",
       "19   -0.264028  0.427755          1            NaN     -0.000392  73.722457   \n",
       "1074 -0.209207  0.855510          0            NaN     -0.001061  76.997068   \n",
       "444  -0.312161  0.855510          0            NaN      0.000000  69.816125   \n",
       "133   0.000303  2.560000          1            NaN           NaN  54.884803   \n",
       "\n",
       "        l1       mse  n_iter  n_values        player  precip_coeff  \\\n",
       "969   0.05  1.387215     9.0         9     Jake Ward     24.376450   \n",
       "19    0.99  3.853628    14.0        11  Jon Braidman           NaN   \n",
       "1074  0.05  3.316928     8.0         9  Randy Waters      7.193448   \n",
       "444   0.40  4.611489     4.0        12   Joe Dannels     45.608696   \n",
       "133   0.05  1.685748     5.0         5  Matty Angell           NaN   \n",
       "\n",
       "      prediction_score  removed_corr  wgust_coeff  wspd_coeff  coeff_count  \n",
       "969           0.787992           0.0     0.105301    0.204910            5  \n",
       "19            0.673009           1.0     0.057198   -0.000000            3  \n",
       "1074          0.660769           0.0     0.016341    0.184927            5  \n",
       "444           0.647342           0.0     0.000000    0.000000            2  \n",
       "133           0.636692           2.0     0.161420    0.498873            3  "
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perf_model_small.sort_values(by='prediction_score',ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "T_coeff             -0.014571\n",
       "alpha                5.712230\n",
       "course_id            1.000000\n",
       "cumgame_coeff        0.002083\n",
       "dirvar_coeff         0.000011\n",
       "intercept           61.717697\n",
       "l1                   0.334747\n",
       "mse                 23.001302\n",
       "n_iter               3.721519\n",
       "n_values             2.109731\n",
       "precip_coeff        12.396180\n",
       "prediction_score     0.138183\n",
       "removed_corr         0.321429\n",
       "wgust_coeff          0.022669\n",
       "wspd_coeff           0.048879\n",
       "dtype: float64"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perf_model_df.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "T_coeff              0.067973\n",
       "alpha                4.747980\n",
       "course_id            0.816778\n",
       "cumgame_coeff        1.006876\n",
       "dirvar_coeff         0.000422\n",
       "intercept            8.824437\n",
       "l1                   0.318349\n",
       "mse                 15.126925\n",
       "n_iter               4.154460\n",
       "n_values             5.458251\n",
       "precip_coeff        30.502433\n",
       "prediction_score     0.172571\n",
       "removed_corr         0.530915\n",
       "wgust_coeff          0.082158\n",
       "wspd_coeff           0.174556\n",
       "dtype: float64"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perf_model_df.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>T_coeff</th>\n",
       "      <th>alpha</th>\n",
       "      <th>course_id</th>\n",
       "      <th>cumgame_coeff</th>\n",
       "      <th>dirvar_coeff</th>\n",
       "      <th>intercept</th>\n",
       "      <th>l1</th>\n",
       "      <th>mse</th>\n",
       "      <th>n_iter</th>\n",
       "      <th>n_values</th>\n",
       "      <th>player</th>\n",
       "      <th>precip_coeff</th>\n",
       "      <th>prediction_score</th>\n",
       "      <th>removed_corr</th>\n",
       "      <th>wgust_coeff</th>\n",
       "      <th>wspd_coeff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>68.111111</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.361111</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Ben Horst</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>68.111111</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.361111</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Ben Horst</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>68.111111</td>\n",
       "      <td>0.4</td>\n",
       "      <td>16.320988</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9</td>\n",
       "      <td>Ben Horst</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>54.607143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.025132</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Bob Montes</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>52.400000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.620000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>Bob Montes</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003012</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   T_coeff  alpha  course_id  cumgame_coeff  dirvar_coeff  intercept   l1  \\\n",
       "0      0.0    0.0          0            0.0           0.0  68.111111  0.0   \n",
       "1      0.0    0.0          1            0.0           0.0  68.111111  0.0   \n",
       "2      0.0   10.0          2            0.0          -0.0  68.111111  0.4   \n",
       "3      0.0    0.0          0            0.0           0.0  54.607143  0.0   \n",
       "4      0.0    0.0          1            0.1           0.0  52.400000  0.0   \n",
       "\n",
       "         mse  n_iter  n_values      player  precip_coeff  prediction_score  \\\n",
       "0  18.361111     0.0         0   Ben Horst           0.0          0.000000   \n",
       "1  18.361111     0.0         0   Ben Horst           0.0          0.000000   \n",
       "2  16.320988     1.0         9   Ben Horst           0.0          0.000000   \n",
       "3  14.025132     0.0         0  Bob Montes           0.0          0.000000   \n",
       "4   6.620000     0.0         5  Bob Montes           0.0          0.003012   \n",
       "\n",
       "   removed_corr  wgust_coeff  wspd_coeff  \n",
       "0           0.0          0.0         0.0  \n",
       "1           0.0          0.0         0.0  \n",
       "2           2.0          0.0         0.0  \n",
       "3           0.0          0.0         0.0  \n",
       "4           1.0          0.0         0.0  "
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perf_model_with_zeros = perf_model_df.fillna(0)\n",
    "perf_model_with_zeros.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.111222    59\n",
       "1.260000     1\n",
       "1.333333     2\n",
       "1.333333     1\n",
       "1.387215     1\n",
       "Name: mse, dtype: int64"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perf_model_df['mse'].value_counts().sort_index().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1449"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perf_model_with_zeros.to_csv('../score_model_data/score_model.csv')\n",
    "perf_model_with_zeros.to_csv('../score_model_data/score_model_20190804b.csv')\n",
    "len(perf_model_with_zeros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x28d934dc470>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "scores_df.Raw.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
