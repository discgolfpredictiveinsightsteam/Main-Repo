{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Score Model w/ Weather EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objective\n",
    "\n",
    "* Evaluation of basic linear model using weather factors and previous scores\n",
    "\n",
    "### Rationale\n",
    "\n",
    "*  Why This?  Before establishing a baseline model, the performance implications of various model choices need to be explored.\n",
    "\n",
    "*  Why Me?  Because I will be building the baseline model, I am the logical choice\n",
    "\n",
    "*  Why Now?  Data from a reproducible pipeline is now available; understanding model choices is necessary before continuing on the project critical path of model implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Requirements\n",
    "\n",
    "*  Pandas 0.24.2\n",
    "*  Scikit-learn 0.21.2\n",
    "*  Matplotlib 3.1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input / Output\n",
    "\n",
    "*  This notebook is expected to be in `models/notebooks/eda`\n",
    "\n",
    "*  The input weather data is in a file `models/wx_model_data/wx_model.csv`\n",
    "\n",
    "*  The input score data is in a file `models/score_model_data/scores.csv`\n",
    "\n",
    "*  The output models are stored in a file `models/score_model_data/linear_model_fits.csv`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import / Set-Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "import numpy as np\n",
    "from sklearn.linear_model import ElasticNetCV\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import datetime as dt\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get weather data\n",
    "wx_df = pd.read_csv('../../wx_model_data/wx_model.csv', parse_dates = ['date'])\n",
    "# Get scores data\n",
    "scores_df = pd.read_csv('../../score_model_data/scores.csv', parse_dates = ['time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>date</th>\n",
       "      <th>weighted_T</th>\n",
       "      <th>weighted_w_dir</th>\n",
       "      <th>weighted_w_spd</th>\n",
       "      <th>weighted_w_gust</th>\n",
       "      <th>weighted_rh</th>\n",
       "      <th>weighted_precip</th>\n",
       "      <th>weighted_w_u</th>\n",
       "      <th>weighted_w_v</th>\n",
       "      <th>w_gust_var</th>\n",
       "      <th>w_dir_var</th>\n",
       "      <th>w_uv_var</th>\n",
       "      <th>course_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2018-11-25</td>\n",
       "      <td>57.023188</td>\n",
       "      <td>80.344928</td>\n",
       "      <td>1.289855</td>\n",
       "      <td>6.800000</td>\n",
       "      <td>88.214493</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.807230</td>\n",
       "      <td>0.670447</td>\n",
       "      <td>0.560000</td>\n",
       "      <td>266.490351</td>\n",
       "      <td>154.904818</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2019-02-24</td>\n",
       "      <td>52.839273</td>\n",
       "      <td>179.611525</td>\n",
       "      <td>1.979019</td>\n",
       "      <td>11.066667</td>\n",
       "      <td>75.883806</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.276422</td>\n",
       "      <td>-1.255324</td>\n",
       "      <td>0.062222</td>\n",
       "      <td>1907.347412</td>\n",
       "      <td>27.922180</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2019-01-27</td>\n",
       "      <td>56.642593</td>\n",
       "      <td>66.362963</td>\n",
       "      <td>3.916667</td>\n",
       "      <td>12.466667</td>\n",
       "      <td>73.714815</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.674324</td>\n",
       "      <td>2.326601</td>\n",
       "      <td>1.582222</td>\n",
       "      <td>301.056529</td>\n",
       "      <td>227.954035</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2019-02-17</td>\n",
       "      <td>49.299471</td>\n",
       "      <td>267.369841</td>\n",
       "      <td>5.489524</td>\n",
       "      <td>14.066667</td>\n",
       "      <td>67.711164</td>\n",
       "      <td>0.000778</td>\n",
       "      <td>-4.882030</td>\n",
       "      <td>-0.070813</td>\n",
       "      <td>1.528889</td>\n",
       "      <td>14.666560</td>\n",
       "      <td>13.316158</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2019-01-06</td>\n",
       "      <td>51.505556</td>\n",
       "      <td>153.133333</td>\n",
       "      <td>4.384722</td>\n",
       "      <td>20.933333</td>\n",
       "      <td>89.798611</td>\n",
       "      <td>0.105625</td>\n",
       "      <td>0.829178</td>\n",
       "      <td>-3.227827</td>\n",
       "      <td>6.995556</td>\n",
       "      <td>214.376551</td>\n",
       "      <td>906.500313</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0       date  weighted_T  weighted_w_dir  weighted_w_spd  \\\n",
       "0           0 2018-11-25   57.023188       80.344928        1.289855   \n",
       "1           1 2019-02-24   52.839273      179.611525        1.979019   \n",
       "2           2 2019-01-27   56.642593       66.362963        3.916667   \n",
       "3           3 2019-02-17   49.299471      267.369841        5.489524   \n",
       "4           4 2019-01-06   51.505556      153.133333        4.384722   \n",
       "\n",
       "   weighted_w_gust  weighted_rh  weighted_precip  weighted_w_u  weighted_w_v  \\\n",
       "0         6.800000    88.214493         0.000000      0.807230      0.670447   \n",
       "1        11.066667    75.883806         0.000000     -0.276422     -1.255324   \n",
       "2        12.466667    73.714815         0.000000      2.674324      2.326601   \n",
       "3        14.066667    67.711164         0.000778     -4.882030     -0.070813   \n",
       "4        20.933333    89.798611         0.105625      0.829178     -3.227827   \n",
       "\n",
       "   w_gust_var    w_dir_var    w_uv_var  course_id  \n",
       "0    0.560000   266.490351  154.904818          0  \n",
       "1    0.062222  1907.347412   27.922180          0  \n",
       "2    1.582222   301.056529  227.954035          0  \n",
       "3    1.528889    14.666560   13.316158          0  \n",
       "4    6.995556   214.376551  906.500313          0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wx_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Name</th>\n",
       "      <th>Raw</th>\n",
       "      <th>Handicap</th>\n",
       "      <th>Adjusted</th>\n",
       "      <th>time</th>\n",
       "      <th>course_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Mark Shannon</td>\n",
       "      <td>61.0</td>\n",
       "      <td>-12.40</td>\n",
       "      <td>48.60</td>\n",
       "      <td>2019-01-19 08:00:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Jacob Kermish-Wells</td>\n",
       "      <td>60.0</td>\n",
       "      <td>-10.72</td>\n",
       "      <td>49.28</td>\n",
       "      <td>2019-01-19 08:00:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Luiz Celeste</td>\n",
       "      <td>55.0</td>\n",
       "      <td>-5.23</td>\n",
       "      <td>49.77</td>\n",
       "      <td>2019-01-19 08:00:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Tu Tran</td>\n",
       "      <td>59.0</td>\n",
       "      <td>-9.07</td>\n",
       "      <td>49.93</td>\n",
       "      <td>2019-01-19 08:00:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Matty Angell</td>\n",
       "      <td>53.0</td>\n",
       "      <td>-1.50</td>\n",
       "      <td>51.50</td>\n",
       "      <td>2019-01-19 08:00:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                 Name   Raw  Handicap  Adjusted  \\\n",
       "0           0         Mark Shannon  61.0    -12.40     48.60   \n",
       "1           1  Jacob Kermish-Wells  60.0    -10.72     49.28   \n",
       "2           2         Luiz Celeste  55.0     -5.23     49.77   \n",
       "3           3              Tu Tran  59.0     -9.07     49.93   \n",
       "4           4         Matty Angell  53.0     -1.50     51.50   \n",
       "\n",
       "                 time  course_id  \n",
       "0 2019-01-19 08:00:00          1  \n",
       "1 2019-01-19 08:00:00          1  \n",
       "2 2019-01-19 08:00:00          1  \n",
       "3 2019-01-19 08:00:00          1  \n",
       "4 2019-01-19 08:00:00          1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean out duplicated indexes\n",
    "wx_df = wx_df.drop(columns = 'Unnamed: 0')\n",
    "scores_df = scores_df.drop(columns = 'Unnamed: 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort prior to merge\n",
    "wx_df = wx_df.sort_values(by = ['date','course_id'])\n",
    "scores_df = scores_df.sort_values(by= ['time','course_id','Name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Raw</th>\n",
       "      <th>Handicap</th>\n",
       "      <th>Adjusted</th>\n",
       "      <th>time</th>\n",
       "      <th>course_id</th>\n",
       "      <th>date</th>\n",
       "      <th>weighted_T</th>\n",
       "      <th>weighted_w_dir</th>\n",
       "      <th>weighted_w_spd</th>\n",
       "      <th>weighted_w_gust</th>\n",
       "      <th>weighted_rh</th>\n",
       "      <th>weighted_precip</th>\n",
       "      <th>weighted_w_u</th>\n",
       "      <th>weighted_w_v</th>\n",
       "      <th>w_gust_var</th>\n",
       "      <th>w_dir_var</th>\n",
       "      <th>w_uv_var</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alex Torres</td>\n",
       "      <td>68.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2012-11-18 07:30:00</td>\n",
       "      <td>0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Andy Leaf</td>\n",
       "      <td>53.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2012-11-18 07:30:00</td>\n",
       "      <td>0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Anthony McGinnis</td>\n",
       "      <td>78.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2012-11-18 07:30:00</td>\n",
       "      <td>0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Aurelius Lewicki</td>\n",
       "      <td>57.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2012-11-18 07:30:00</td>\n",
       "      <td>0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Billy Manger</td>\n",
       "      <td>58.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2012-11-18 07:30:00</td>\n",
       "      <td>0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Name   Raw  Handicap  Adjusted                time  course_id  \\\n",
       "0       Alex Torres  68.0       NaN       NaN 2012-11-18 07:30:00          0   \n",
       "1         Andy Leaf  53.0       NaN       NaN 2012-11-18 07:30:00          0   \n",
       "2  Anthony McGinnis  78.0       NaN       NaN 2012-11-18 07:30:00          0   \n",
       "3  Aurelius Lewicki  57.0       NaN       NaN 2012-11-18 07:30:00          0   \n",
       "4      Billy Manger  58.0       NaN       NaN 2012-11-18 07:30:00          0   \n",
       "\n",
       "  date  weighted_T  weighted_w_dir  weighted_w_spd  weighted_w_gust  \\\n",
       "0  NaT         NaN             NaN             NaN              NaN   \n",
       "1  NaT         NaN             NaN             NaN              NaN   \n",
       "2  NaT         NaN             NaN             NaN              NaN   \n",
       "3  NaT         NaN             NaN             NaN              NaN   \n",
       "4  NaT         NaN             NaN             NaN              NaN   \n",
       "\n",
       "   weighted_rh  weighted_precip  weighted_w_u  weighted_w_v  w_gust_var  \\\n",
       "0          NaN              NaN           NaN           NaN         NaN   \n",
       "1          NaN              NaN           NaN           NaN         NaN   \n",
       "2          NaN              NaN           NaN           NaN         NaN   \n",
       "3          NaN              NaN           NaN           NaN         NaN   \n",
       "4          NaN              NaN           NaN           NaN         NaN   \n",
       "\n",
       "   w_dir_var  w_uv_var  \n",
       "0        NaN       NaN  \n",
       "1        NaN       NaN  \n",
       "2        NaN       NaN  \n",
       "3        NaN       NaN  \n",
       "4        NaN       NaN  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_df = pd.merge_asof(scores_df, wx_df, by = 'course_id', left_on= 'time', right_on = 'date',\n",
    "                       direction = 'backward', tolerance = pd.Timedelta('1d') )\n",
    "all_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Raw</th>\n",
       "      <th>Handicap</th>\n",
       "      <th>Adjusted</th>\n",
       "      <th>time</th>\n",
       "      <th>course_id</th>\n",
       "      <th>date</th>\n",
       "      <th>weighted_T</th>\n",
       "      <th>weighted_w_dir</th>\n",
       "      <th>weighted_w_spd</th>\n",
       "      <th>weighted_w_gust</th>\n",
       "      <th>weighted_rh</th>\n",
       "      <th>weighted_precip</th>\n",
       "      <th>weighted_w_u</th>\n",
       "      <th>weighted_w_v</th>\n",
       "      <th>w_gust_var</th>\n",
       "      <th>w_dir_var</th>\n",
       "      <th>w_uv_var</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>478</th>\n",
       "      <td>Ben Horst</td>\n",
       "      <td>65.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-01-28 09:00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>2017-01-28</td>\n",
       "      <td>53.789346</td>\n",
       "      <td>251.602328</td>\n",
       "      <td>1.089775</td>\n",
       "      <td>7.688889</td>\n",
       "      <td>64.358531</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.963792</td>\n",
       "      <td>-0.419697</td>\n",
       "      <td>0.134321</td>\n",
       "      <td>28.786247</td>\n",
       "      <td>2.475685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479</th>\n",
       "      <td>Bob Montes</td>\n",
       "      <td>54.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-01-28 09:00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>2017-01-28</td>\n",
       "      <td>53.789346</td>\n",
       "      <td>251.602328</td>\n",
       "      <td>1.089775</td>\n",
       "      <td>7.688889</td>\n",
       "      <td>64.358531</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.963792</td>\n",
       "      <td>-0.419697</td>\n",
       "      <td>0.134321</td>\n",
       "      <td>28.786247</td>\n",
       "      <td>2.475685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480</th>\n",
       "      <td>Dennis Warsen</td>\n",
       "      <td>52.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-01-28 09:00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>2017-01-28</td>\n",
       "      <td>53.789346</td>\n",
       "      <td>251.602328</td>\n",
       "      <td>1.089775</td>\n",
       "      <td>7.688889</td>\n",
       "      <td>64.358531</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.963792</td>\n",
       "      <td>-0.419697</td>\n",
       "      <td>0.134321</td>\n",
       "      <td>28.786247</td>\n",
       "      <td>2.475685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>481</th>\n",
       "      <td>Gonzalo Arestizabal</td>\n",
       "      <td>63.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-01-28 09:00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>2017-01-28</td>\n",
       "      <td>53.789346</td>\n",
       "      <td>251.602328</td>\n",
       "      <td>1.089775</td>\n",
       "      <td>7.688889</td>\n",
       "      <td>64.358531</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.963792</td>\n",
       "      <td>-0.419697</td>\n",
       "      <td>0.134321</td>\n",
       "      <td>28.786247</td>\n",
       "      <td>2.475685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>482</th>\n",
       "      <td>Greg Mann</td>\n",
       "      <td>58.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-01-28 09:00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>2017-01-28</td>\n",
       "      <td>53.789346</td>\n",
       "      <td>251.602328</td>\n",
       "      <td>1.089775</td>\n",
       "      <td>7.688889</td>\n",
       "      <td>64.358531</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.963792</td>\n",
       "      <td>-0.419697</td>\n",
       "      <td>0.134321</td>\n",
       "      <td>28.786247</td>\n",
       "      <td>2.475685</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Name   Raw  Handicap  Adjusted                time  \\\n",
       "478            Ben Horst  65.0       NaN       NaN 2017-01-28 09:00:00   \n",
       "479           Bob Montes  54.0       NaN       NaN 2017-01-28 09:00:00   \n",
       "480        Dennis Warsen  52.0       NaN       NaN 2017-01-28 09:00:00   \n",
       "481  Gonzalo Arestizabal  63.0       NaN       NaN 2017-01-28 09:00:00   \n",
       "482            Greg Mann  58.0       NaN       NaN 2017-01-28 09:00:00   \n",
       "\n",
       "     course_id       date  weighted_T  weighted_w_dir  weighted_w_spd  \\\n",
       "478          2 2017-01-28   53.789346      251.602328        1.089775   \n",
       "479          2 2017-01-28   53.789346      251.602328        1.089775   \n",
       "480          2 2017-01-28   53.789346      251.602328        1.089775   \n",
       "481          2 2017-01-28   53.789346      251.602328        1.089775   \n",
       "482          2 2017-01-28   53.789346      251.602328        1.089775   \n",
       "\n",
       "     weighted_w_gust  weighted_rh  weighted_precip  weighted_w_u  \\\n",
       "478         7.688889    64.358531              0.0     -0.963792   \n",
       "479         7.688889    64.358531              0.0     -0.963792   \n",
       "480         7.688889    64.358531              0.0     -0.963792   \n",
       "481         7.688889    64.358531              0.0     -0.963792   \n",
       "482         7.688889    64.358531              0.0     -0.963792   \n",
       "\n",
       "     weighted_w_v  w_gust_var  w_dir_var  w_uv_var  \n",
       "478     -0.419697    0.134321  28.786247  2.475685  \n",
       "479     -0.419697    0.134321  28.786247  2.475685  \n",
       "480     -0.419697    0.134321  28.786247  2.475685  \n",
       "481     -0.419697    0.134321  28.786247  2.475685  \n",
       "482     -0.419697    0.134321  28.786247  2.475685  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop any rows that do not have weather data\n",
    "all_df = all_df.dropna(subset = ['weighted_T'])\n",
    "all_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2960"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Name', 'Raw', 'Handicap', 'Adjusted', 'time', 'course_id', 'date',\n",
       "       'weighted_T', 'weighted_w_dir', 'weighted_w_spd', 'weighted_w_gust',\n",
       "       'weighted_rh', 'weighted_precip', 'weighted_w_u', 'weighted_w_v',\n",
       "       'w_gust_var', 'w_dir_var', 'w_uv_var'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def model_player_performance(player : str, course : int):\n",
    "    \"\"\"Given a player name and course id, return model parameters indicating the effects of weather on expected score.\n",
    "    The model will return a dictionary with coefficients for easy identification\"\"\"\n",
    "    \n",
    "    model_dict = {}\n",
    "    model_dict['player'] = player\n",
    "    model_dict['course_id'] = course\n",
    "    player_df = all_df[(all_df['Name'] == player) & (all_df['course_id'] == course)]\n",
    "    # Replace index with the cumulative number of games played, and make that into a column\n",
    "    player_df = player_df.reset_index()\n",
    "    player_df = player_df.drop(columns = ['index'])\n",
    "    player_df = player_df.reset_index()\n",
    "    \n",
    "    #Build weather model\n",
    "    X = player_df[['index','weighted_T', 'weighted_w_dir', 'weighted_w_spd', 'weighted_w_gust',\n",
    "        'weighted_precip', 'weighted_w_u', 'weighted_w_v',\n",
    "       'w_gust_var', 'w_dir_var', 'w_uv_var']].values\n",
    "    y = player_df['Raw'].values\n",
    "    \n",
    "    if len(player_df) > 13:\n",
    "        scaler = StandardScaler()\n",
    "        lr = ElasticNetCV(l1_ratio = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 0.95, 0.99], cv = 3, \n",
    "                          max_iter = 5000, random_state=42)\n",
    "        pipeline = make_pipeline(scaler, lr)\n",
    "        pipeline.fit(X,y)\n",
    "        ypred = pipeline.predict(X)\n",
    "        cumgame_coeff, T_coeff, wdir_coeff, wspd_coeff, wgust_coeff,\\\n",
    "        precip_coeff, u_coeff, v_coeff, gustvar_coeff, dirvar_coeff, uv_var_coeff = pipeline['elasticnetcv'].coef_\n",
    "        model_dict['prediction_score'] = pipeline.score(X,y)\n",
    "        model_dict['cumgame_coeff'] = cumgame_coeff\n",
    "        model_dict['T_coeff'] = T_coeff\n",
    "        model_dict['wdir_coeff'] = wdir_coeff\n",
    "        model_dict['wspd_coeff'] = wspd_coeff\n",
    "        model_dict['wgust_coeff'] = wgust_coeff\n",
    "        model_dict['precip_coeff'] = precip_coeff\n",
    "        model_dict['u_coeff'] = u_coeff\n",
    "        model_dict['v_coeff'] = v_coeff\n",
    "        model_dict['gustvar_coeff'] = gustvar_coeff\n",
    "        model_dict['dirvar_coeff'] = dirvar_coeff\n",
    "        model_dict['uv_var_coeff'] = uv_var_coeff\n",
    "        model_dict['intercept'] = pipeline['elasticnetcv'].intercept_\n",
    "        model_dict['mse'] = mean_squared_error(y, ypred)\n",
    "        model_dict['n_value'] = len(player_df)\n",
    "    elif len(player_df) > 0:\n",
    "        model_dict['nomatch'] = 1\n",
    "    else:\n",
    "        model_dict['nomatch'] = 1\n",
    "        \n",
    "    return model_dict    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.01121810991049621, tolerance: 0.009222222222222224\n",
      "  positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.01707703687829465, tolerance: 0.009222222222222224\n",
      "  positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.023136391763770803, tolerance: 0.009222222222222224\n",
      "  positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.03057416347238373, tolerance: 0.009222222222222224\n",
      "  positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.03971605540649392, tolerance: 0.009222222222222224\n",
      "  positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.050827461017314945, tolerance: 0.009222222222222224\n",
      "  positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.06417514516239109, tolerance: 0.009222222222222224\n",
      "  positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.010142074498549647, tolerance: 0.009222222222222224\n",
      "  positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.012279212679624507, tolerance: 0.009222222222222224\n",
      "  positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.015076940897470692, tolerance: 0.009222222222222224\n",
      "  positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.018390100237446916, tolerance: 0.009222222222222224\n",
      "  positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.023766885825681427, tolerance: 0.009222222222222224\n",
      "  positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.053337006257894615, tolerance: 0.009222222222222224\n",
      "  positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.07369958019327782, tolerance: 0.009222222222222224\n",
      "  positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.09410734027326839, tolerance: 0.009222222222222224\n",
      "  positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.10632884291818812, tolerance: 0.009222222222222224\n",
      "  positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.12471504722576832, tolerance: 0.009222222222222224\n",
      "  positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.14779576806419747, tolerance: 0.009222222222222224\n",
      "  positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.17403748484290382, tolerance: 0.009222222222222224\n",
      "  positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.20271249945530379, tolerance: 0.009222222222222224\n",
      "  positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.2333667718497363, tolerance: 0.009222222222222224\n",
      "  positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.014424438434232911, tolerance: 0.009222222222222224\n",
      "  positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.05421044862434776, tolerance: 0.009222222222222224\n",
      "  positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.10292084708014393, tolerance: 0.009222222222222224\n",
      "  positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.06230782940098045, tolerance: 0.009222222222222224\n",
      "  positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.19092033837394062, tolerance: 0.009222222222222224\n",
      "  positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.3030858851808862, tolerance: 0.009222222222222224\n",
      "  positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.38995907628540394, tolerance: 0.009222222222222224\n",
      "  positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.5007767758698609, tolerance: 0.009222222222222224\n",
      "  positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.5334451914003893, tolerance: 0.009222222222222224\n",
      "  positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.5703145949279369, tolerance: 0.009222222222222224\n",
      "  positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.6054681403482292, tolerance: 0.009222222222222224\n",
      "  positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.6372220900685095, tolerance: 0.009222222222222224\n",
      "  positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.6648042034508972, tolerance: 0.009222222222222224\n",
      "  positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.6878358293091917, tolerance: 0.009222222222222224\n",
      "  positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.7061790946197206, tolerance: 0.009222222222222224\n",
      "  positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.7198595270807817, tolerance: 0.009222222222222224\n",
      "  positive)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.03244667182098837, tolerance: 0.012854545454545457\n",
      "  positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.01195325066121633, tolerance: 0.01101\n",
      "  positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.013858231792234221, tolerance: 0.01101\n",
      "  positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.016655019927709347, tolerance: 0.01101\n",
      "  positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.01825194668737673, tolerance: 0.01101\n",
      "  positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.02224096781183782, tolerance: 0.01101\n",
      "  positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.013037729014051536, tolerance: 0.01101\n",
      "  positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.043576026342392105, tolerance: 0.01101\n",
      "  positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.06724856255698697, tolerance: 0.01101\n",
      "  positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.07898508971916973, tolerance: 0.01101\n",
      "  positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.041524392536676835, tolerance: 0.01101\n",
      "  positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.019891946179619868, tolerance: 0.01101\n",
      "  positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.0317071818013126, tolerance: 0.028225\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.039954397467514724, tolerance: 0.028225\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.04985634812785378, tolerance: 0.028225\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.061454859062497036, tolerance: 0.028225\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.07488021522601684, tolerance: 0.028225\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.035593057434518016, tolerance: 0.028225\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.0877042812353892, tolerance: 0.028225\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.16757799259968564, tolerance: 0.028225\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.21004586374787237, tolerance: 0.028225\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.24563112208398863, tolerance: 0.028225\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.27969652182106586, tolerance: 0.028225\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.312866655096272, tolerance: 0.028225\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.34490513799863365, tolerance: 0.028225\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.37544037163035426, tolerance: 0.028225\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.4041101959319562, tolerance: 0.028225\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.4305953407562306, tolerance: 0.028225\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.22331315911081617, tolerance: 0.028225\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.30863107437193626, tolerance: 0.028225\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.4555528986805726, tolerance: 0.028225\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.5067974847116901, tolerance: 0.028225\n",
      "  tol, rng, random, positive)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.016304184825858048, tolerance: 0.016\n",
      "  positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.016214257638042184, tolerance: 0.016\n",
      "  positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.018631588874429728, tolerance: 0.016\n",
      "  positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.027263011905270584, tolerance: 0.016\n",
      "  positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.04735492325052393, tolerance: 0.016\n",
      "  positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.02127777478289694, tolerance: 0.016\n",
      "  positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.03464287593338522, tolerance: 0.016\n",
      "  positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.054262928639847274, tolerance: 0.016\n",
      "  positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.06493384379277067, tolerance: 0.016\n",
      "  positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.028394681195945903, tolerance: 0.016\n",
      "  positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.04686115548172687, tolerance: 0.016\n",
      "  positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.09185906461746018, tolerance: 0.016\n",
      "  positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.10935838105428042, tolerance: 0.016\n",
      "  positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.10588624244662559, tolerance: 0.016\n",
      "  positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.09949264419786052, tolerance: 0.016\n",
      "  positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.09349631504712486, tolerance: 0.016\n",
      "  positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.026338507750118367, tolerance: 0.023323076923076922\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.03127351348554441, tolerance: 0.023323076923076922\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.03666082516555491, tolerance: 0.023323076923076922\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.04244060914458103, tolerance: 0.023323076923076922\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.04855548944125232, tolerance: 0.023323076923076922\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.05493810124109544, tolerance: 0.023323076923076922\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.061512930982559055, tolerance: 0.023323076923076922\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.06819857562350506, tolerance: 0.023323076923076922\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.023694546575612208, tolerance: 0.023323076923076922\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.035759956753750544, tolerance: 0.023323076923076922\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.05292354812017663, tolerance: 0.023323076923076922\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.06290743832593648, tolerance: 0.023323076923076922\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.07282818005127467, tolerance: 0.023323076923076922\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.08272331011797007, tolerance: 0.023323076923076922\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.09243666562255015, tolerance: 0.023323076923076922\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.10181610871321567, tolerance: 0.023323076923076922\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.11072338398246728, tolerance: 0.023323076923076922\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.11903742231505987, tolerance: 0.023323076923076922\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.1266564779142172, tolerance: 0.023323076923076922\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.13349932658766406, tolerance: 0.023323076923076922\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.1395055869323869, tolerance: 0.023323076923076922\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.1446352917895517, tolerance: 0.023323076923076922\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.14886783288050864, tolerance: 0.023323076923076922\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.15220040943564683, tolerance: 0.023323076923076922\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.15464613481112366, tolerance: 0.023323076923076922\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.15623190825247057, tolerance: 0.023323076923076922\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.1569961805589699, tolerance: 0.023323076923076922\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.15698671365944428, tolerance: 0.023323076923076922\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.15625840203668773, tolerance: 0.023323076923076922\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.15487122825979682, tolerance: 0.023323076923076922\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.11842260051564146, tolerance: 0.023323076923076922\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.1490636577991289, tolerance: 0.023323076923076922\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.14851480336893097, tolerance: 0.023323076923076922\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.1453725205677383, tolerance: 0.023323076923076922\n",
      "  tol, rng, random, positive)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>T_coeff</th>\n",
       "      <th>course_id</th>\n",
       "      <th>cumgame_coeff</th>\n",
       "      <th>dirvar_coeff</th>\n",
       "      <th>gustvar_coeff</th>\n",
       "      <th>intercept</th>\n",
       "      <th>mse</th>\n",
       "      <th>n_value</th>\n",
       "      <th>nomatch</th>\n",
       "      <th>player</th>\n",
       "      <th>precip_coeff</th>\n",
       "      <th>prediction_score</th>\n",
       "      <th>u_coeff</th>\n",
       "      <th>uv_var_coeff</th>\n",
       "      <th>v_coeff</th>\n",
       "      <th>wdir_coeff</th>\n",
       "      <th>wgust_coeff</th>\n",
       "      <th>wspd_coeff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Ben Horst</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Ben Horst</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Ben Horst</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Bob Montes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Bob Montes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   T_coeff  course_id  cumgame_coeff  dirvar_coeff  gustvar_coeff  intercept  \\\n",
       "0      NaN          0            NaN           NaN            NaN        NaN   \n",
       "1      NaN          1            NaN           NaN            NaN        NaN   \n",
       "2      NaN          2            NaN           NaN            NaN        NaN   \n",
       "3      NaN          0            NaN           NaN            NaN        NaN   \n",
       "4      NaN          1            NaN           NaN            NaN        NaN   \n",
       "\n",
       "   mse  n_value  nomatch      player  precip_coeff  prediction_score  u_coeff  \\\n",
       "0  NaN      NaN      1.0   Ben Horst           NaN               NaN      NaN   \n",
       "1  NaN      NaN      1.0   Ben Horst           NaN               NaN      NaN   \n",
       "2  NaN      NaN      1.0   Ben Horst           NaN               NaN      NaN   \n",
       "3  NaN      NaN      1.0  Bob Montes           NaN               NaN      NaN   \n",
       "4  NaN      NaN      1.0  Bob Montes           NaN               NaN      NaN   \n",
       "\n",
       "   uv_var_coeff  v_coeff  wdir_coeff  wgust_coeff  wspd_coeff  \n",
       "0           NaN      NaN         NaN          NaN         NaN  \n",
       "1           NaN      NaN         NaN          NaN         NaN  \n",
       "2           NaN      NaN         NaN          NaN         NaN  \n",
       "3           NaN      NaN         NaN          NaN         NaN  \n",
       "4           NaN      NaN         NaN          NaN         NaN  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Make list of player names\n",
    "player_names = all_df['Name'].unique()\n",
    "perf_dicts = []\n",
    "for player_name in player_names:\n",
    "    for course_id in range(all_df['course_id'].max() + 1):\n",
    "        perf_dict = model_player_performance(player_name, course_id)\n",
    "        perf_dicts.append(perf_dict)\n",
    "            \n",
    "perf_model_df = pd.DataFrame(perf_dicts)\n",
    "perf_model_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>T_coeff</th>\n",
       "      <th>course_id</th>\n",
       "      <th>cumgame_coeff</th>\n",
       "      <th>dirvar_coeff</th>\n",
       "      <th>gustvar_coeff</th>\n",
       "      <th>intercept</th>\n",
       "      <th>mse</th>\n",
       "      <th>n_value</th>\n",
       "      <th>nomatch</th>\n",
       "      <th>player</th>\n",
       "      <th>precip_coeff</th>\n",
       "      <th>prediction_score</th>\n",
       "      <th>u_coeff</th>\n",
       "      <th>uv_var_coeff</th>\n",
       "      <th>v_coeff</th>\n",
       "      <th>wdir_coeff</th>\n",
       "      <th>wgust_coeff</th>\n",
       "      <th>wspd_coeff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.303161</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>55.043478</td>\n",
       "      <td>9.368340</td>\n",
       "      <td>23.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bob Montes</td>\n",
       "      <td>0.152295</td>\n",
       "      <td>0.328657</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.706347</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.982209</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-2.212886</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>57.142857</td>\n",
       "      <td>6.708201</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Dennis Warsen</td>\n",
       "      <td>0.013266</td>\n",
       "      <td>0.583922</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>54.358491</td>\n",
       "      <td>14.013276</td>\n",
       "      <td>53.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Dennis Warsen</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.120216</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.797097</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-0.363872</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.100533</td>\n",
       "      <td>-0.029896</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>63.142857</td>\n",
       "      <td>6.180790</td>\n",
       "      <td>21.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Gonzalo Arestizabal</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.256484</td>\n",
       "      <td>-0.139923</td>\n",
       "      <td>-0.305617</td>\n",
       "      <td>-0.223741</td>\n",
       "      <td>0.143666</td>\n",
       "      <td>0.066997</td>\n",
       "      <td>0.102911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>-0.465969</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.814821</td>\n",
       "      <td>-0.032315</td>\n",
       "      <td>-0.236957</td>\n",
       "      <td>56.458333</td>\n",
       "      <td>8.637850</td>\n",
       "      <td>24.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Jon Braidman</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.473781</td>\n",
       "      <td>0.536920</td>\n",
       "      <td>-0.247028</td>\n",
       "      <td>-0.357186</td>\n",
       "      <td>-0.188228</td>\n",
       "      <td>1.353104</td>\n",
       "      <td>-0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     T_coeff  course_id  cumgame_coeff  dirvar_coeff  gustvar_coeff  \\\n",
       "5  -0.303161          2      -0.000000      0.000000       0.000000   \n",
       "7  -2.212886          1      -0.000000      0.000000      -0.000000   \n",
       "8  -0.000000          2      -0.000000     -0.000000       0.000000   \n",
       "11 -0.363872          2      -0.100533     -0.029896      -0.000000   \n",
       "20 -0.465969          2      -0.814821     -0.032315      -0.236957   \n",
       "\n",
       "    intercept        mse  n_value  nomatch               player  precip_coeff  \\\n",
       "5   55.043478   9.368340     23.0      NaN           Bob Montes      0.152295   \n",
       "7   57.142857   6.708201     14.0      NaN        Dennis Warsen      0.013266   \n",
       "8   54.358491  14.013276     53.0      NaN        Dennis Warsen      0.000000   \n",
       "11  63.142857   6.180790     21.0      NaN  Gonzalo Arestizabal      0.000000   \n",
       "20  56.458333   8.637850     24.0      NaN         Jon Braidman      0.000000   \n",
       "\n",
       "    prediction_score   u_coeff  uv_var_coeff   v_coeff  wdir_coeff  \\\n",
       "5           0.328657 -0.000000      0.000000 -0.706347   -0.000000   \n",
       "7           0.583922 -0.000000      0.000000  0.000000    0.000000   \n",
       "8           0.120216 -0.000000     -0.000000 -0.000000    0.000000   \n",
       "11          0.256484 -0.139923     -0.305617 -0.223741    0.143666   \n",
       "20          0.473781  0.536920     -0.247028 -0.357186   -0.188228   \n",
       "\n",
       "    wgust_coeff  wspd_coeff  \n",
       "5      0.982209    0.000000  \n",
       "7     -0.000000    0.000000  \n",
       "8      0.797097    0.000000  \n",
       "11     0.066997    0.102911  \n",
       "20     1.353104   -0.000000  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perf_model_small = perf_model_df.dropna(subset=['T_coeff'])\n",
    "print(len(perf_model_small))\n",
    "perf_model_small.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([18.,  2., 25.]),\n",
       " array([0.        , 0.66666667, 1.33333333, 2.        ]),\n",
       " <a list of 3 Patch objects>)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(perf_model_small['course_id'],bins=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 1.,  1.,  0.,  0.,  1.,  2.,  4., 32.,  2.,  2.]),\n",
       " array([-2.21288634, -1.90381296, -1.59473958, -1.2856662 , -0.97659283,\n",
       "        -0.66751945, -0.35844607, -0.04937269,  0.25970069,  0.56877406,\n",
       "         0.87784744]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(perf_model_small['T_coeff'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([2., 7., 6., 8., 7., 8., 4., 1., 1., 1.]),\n",
       " array([ 2.52839953,  4.52709019,  6.52578085,  8.52447151, 10.52316217,\n",
       "        12.52185283, 14.52054349, 16.51923415, 18.5179248 , 20.51661546,\n",
       "        22.51530612]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(perf_model_small['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1419"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perf_model_df.to_csv('../../score_model_data/score_model2_X_rh_n13.csv')\n",
    "len(perf_model_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 1.,  0.,  0.,  1.,  2., 34.,  4.,  2.,  0.,  1.]),\n",
       " array([-2.78523724, -2.31008506, -1.83493288, -1.3597807 , -0.88462852,\n",
       "        -0.40947633,  0.06567585,  0.54082803,  1.01598021,  1.49113239,\n",
       "         1.96628458]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAD4CAYAAAD1jb0+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAANOklEQVR4nO3df4jk9X3H8eerdxcTYkDFib2q9EKQVAnJWbZXwdIaNe3FlKilgfpHeqXCRVBQkBJ/QE1pBSWNFkoJXDjr/WFMRA2KmtarNVihsV3t9Ty7ploxrXp4a6xRKVhO3/1jv5du9nZvZndmdvzcPh+w7Mx3vjPf93fvePK92e93LlWFJKk9PzfpASRJK2PAJalRBlySGmXAJalRBlySGrV+NTd24okn1qZNm1Zzk5LUvCeffPK1quotXN434Ek+CDwGHNOtf3dV3ZDkduA3gJ90q/5BVe050mtt2rSJ6enp5c4uSWtakh8ttnyQI/B3gHOr6u0kG4DHk3yve+yPquruUQ0pSRpc34DX3JU+b3d3N3RfXv0jSRM20C8xk6xLsgc4AOyuqie6h25MsjfJrUmOGduUkqTDDBTwqnq3qjYDpwBbknwSuBb4JeBXgBOAryz23CTbk0wnmZ6dnR3R2JKkZZ1GWFVvAN8HtlbV/przDvDXwJYlnrOjqqaqaqrXO+yXqJKkFeob8CS9JMd1tz8EnA88m2RjtyzARcC+cQ4qSfpZg5yFshHYlWQdc8G/q6oeSPL3SXpAgD3AZWOcU5K0wCBnoewFzlxk+bljmUiSNBAvpZekRq3qpfTS+9Wmax6c2LZfvOnzE9u22uYRuCQ1yoBLUqMMuCQ1yoBLUqMMuCQ1yoBLUqMMuCQ1yoBLUqMMuCQ1yoBLUqMMuCQ1yoBLUqMMuCQ1yoBLUqMMuCQ1yoBLUqMMuCQ1yoBLUqMMuCQ1yoBLUqP6BjzJB5P8U5J/TfJMkj/pln8syRNJnkvynSQfGP+4kqRDBjkCfwc4t6o+DWwGtiY5C7gZuLWqTgP+G7h0fGNKkhbqG/Ca83Z3d0P3VcC5wN3d8l3ARWOZUJK0qIHeA0+yLske4ACwG/gP4I2qOtit8hJw8hLP3Z5kOsn07OzsKGaWJDFgwKvq3araDJwCbAFOX2y1JZ67o6qmqmqq1+utfFJJ0s9Y1lkoVfUG8H3gLOC4JOu7h04BXhntaJKkIxnkLJRekuO62x8CzgdmgEeB3+1W2wbcN64hJUmHW99/FTYCu5KsYy74d1XVA0n+Dfh2kj8D/gXYOcY5JUkL9A14Ve0Fzlxk+QvMvR8uSZoAr8SUpEYZcElqlAGXpEYZcElqlAGXpEYZcElqlAGXpEYZcElqlAGXpEYZcElqlAGXpEYZcElqlAGXpEYZcElqlAGXpEYZcElqlAGXpEYZcElqlAGXpEYZcElqlAGXpEb1DXiSU5M8mmQmyTNJruyWfzXJy0n2dF8XjH9cSdIh6wdY5yBwdVU9leQjwJNJdneP3VpVfz6+8SRJS+kb8KraD+zvbr+VZAY4edyDSZKObFnvgSfZBJwJPNEtuiLJ3iS3JTl+xLNJko5g4IAnORa4B7iqqt4EvgF8HNjM3BH615d43vYk00mmZ2dnRzCyJAkGDHiSDczF+46quhegql6tqner6j3gm8CWxZ5bVTuqaqqqpnq93qjmlqQ1b5CzUALsBGaq6pZ5yzfOW+1iYN/ox5MkLWWQs1DOBr4EPJ1kT7fsOuCSJJuBAl4EvjyWCSVJixrkLJTHgSzy0EOjH0eSNCivxJSkRhlwSWqUAZekRhlwSWqUAZekRhlwSWqUAZekRhlwSWqUAZekRhlwSWqUAZekRhlwSWqUAZekRhlwSWqUAZekRhlwSWqUAZekRhlwSWqUAZekRhlwSWqUAZekRhlwSWpU34AnOTXJo0lmkjyT5Mpu+QlJdid5rvt+/PjHlSQdMsgR+EHg6qo6HTgLuDzJGcA1wCNVdRrwSHdfkrRK+ga8qvZX1VPd7beAGeBk4EJgV7faLuCicQ0pSTrcst4DT7IJOBN4AjipqvbDXOSBjy7xnO1JppNMz87ODjetJOmnBg54kmOBe4CrqurNQZ9XVTuqaqqqpnq93kpmlCQtYqCAJ9nAXLzvqKp7u8WvJtnYPb4RODCeESVJixnkLJQAO4GZqrpl3kP3A9u629uA+0Y/niRpKesHWOds4EvA00n2dMuuA24C7kpyKfCfwBfHM6IkaTF9A15VjwNZ4uHzRjuOJGlQXokpSY0y4JLUKAMuSY0y4JLUKAMuSY0y4JLUKAMuSY0y4JLUKAMuSY0y4JLUKAMuSY0y4JLUKAMuSY0y4JLUKAMuSY0y4JLUKAMuSY0y4JLUKAMuSY0y4JLUKAMuSY3qG/AktyU5kGTfvGVfTfJykj3d1wXjHVOStNAgR+C3A1sXWX5rVW3uvh4a7ViSpH76BryqHgNeX4VZJEnLMMx74Fck2du9xXL8Uisl2Z5kOsn07OzsEJuTJM230oB/A/g4sBnYD3x9qRWrakdVTVXVVK/XW+HmJEkLrSjgVfVqVb1bVe8B3wS2jHYsSVI/Kwp4ko3z7l4M7FtqXUnSeKzvt0KSO4FzgBOTvATcAJyTZDNQwIvAl8c4oyRpEX0DXlWXLLJ45xhmkSQtg1diSlKjDLgkNcqAS1KjDLgkNcqAS1KjDLgkNcqAS1KjDLgkNcqAS1KjDLgkNcqAS1KjDLgkNcqAS1KjDLgkNcqAS1KjDLgkNcqAS1KjDLgkNcqAS1KjDLgkNcqAS1KjDLgkNapvwJPcluRAkn3zlp2QZHeS57rvx493TEnSQoMcgd8ObF2w7Brgkao6DXikuy9JWkV9A15VjwGvL1h8IbCru70LuGjEc0mS+ljpe+AnVdV+gO77R5daMcn2JNNJpmdnZ1e4OUnSQmP/JWZV7aiqqaqa6vV6496cJK0ZKw34q0k2AnTfD4xuJEnSIFYa8PuBbd3tbcB9oxlHkjSoQU4jvBP4R+ATSV5KcilwE/DZJM8Bn+3uS5JW0fp+K1TVJUs8dN6IZ5EkLYNXYkpSowy4JDXKgEtSowy4JDXKgEtSowy4JDXKgEtSowy4JDXKgEtSowy4JDXKgEtSowy4JDXKgEtSowy4JDXKgEtSowy4JDXKgEtSowy4JDXKgEtSowy4JDXKgEtSo/r+r/RHkuRF4C3gXeBgVU2NYihJUn9DBbzzmap6bQSvI0laBt9CkaRGDRvwAh5O8mSS7YutkGR7kukk07Ozs0NuTpJ0yLABP7uqfhn4HHB5kl9fuEJV7aiqqaqa6vV6Q25OknTIUAGvqle67weA7wJbRjGUJKm/FQc8yYeTfOTQbeA3gX2jGkySdGTDnIVyEvDdJIde51tV9TcjmUqS1NeKA15VLwCfHuEskqRlGMV54JKGsOmaByey3Rdv+vxEtqvR8TxwSWqUAZekRhlwSWqUAZekRhlwSWqUAZekRhlwSWqUAZekRhlwSWqUAZekRhlwSWqUAZekRvlhVnpfmdQHO61Fk/xZ+0Fao+ERuCQ1yoBLUqMMuCQ1yoBLUqMMuCQ1qpmzUPyN+erxTBAdrY62jngELkmNMuCS1KihAp5ka5IfJnk+yTWjGkqS1N+KA55kHfBXwOeAM4BLkpwxqsEkSUc2zBH4FuD5qnqhqv4X+DZw4WjGkiT1M8xZKCcD/zXv/kvAry5cKcl2YHt39+0kPwZeG2K7qy43j/TlTqSx/R+Dtf4zWPP7n5vX3v7P68hK/vx/cbGFwwQ8iyyrwxZU7QB2/PRJyXRVTQ2x3aat9f0Hfwbuv/s/qv0f5i2Ul4BT590/BXhluHEkSYMaJuD/DJyW5GNJPgD8HnD/aMaSJPWz4rdQqupgkiuAvwXWAbdV1TMDPHVH/1WOamt9/8Gfgfu/to1s/1N12NvWkqQGeCWmJDXKgEtSoyYS8CR/mmRvkj1JHk7yC5OYY1KSfC3Js93P4LtJjpv0TKspyReTPJPkvSRr5nSytf7RE0luS3Igyb5Jz7Lakpya5NEkM93f/StH8bqTOgL/WlV9qqo2Aw8AfzyhOSZlN/DJqvoU8O/AtROeZ7XtA34HeGzSg6wWP3oCgNuBrZMeYkIOAldX1enAWcDlo/jzn0jAq+rNeXc/zCIXAB3NqurhqjrY3f0Bc+fQrxlVNVNVP5z0HKtszX/0RFU9Brw+6Tkmoar2V9VT3e23gBnmrmYfysT+Q4ckNwK/D/wE+Myk5ngf+EPgO5MeQmM30EdP6OiXZBNwJvDEsK81toAn+Tvg5xd56Pqquq+qrgeuT3ItcAVww7hmmYR++9+tcz1z/7S6YzVnWw2D7P8aM9BHT+joluRY4B7gqgXvRKzI2AJeVecPuOq3gAc5ygLeb/+TbAN+GzivjsKT8Zfx579W+NETa1ySDczF+46quncUrzmps1BOm3f3C8Czk5hjUpJsBb4CfKGq/mfS82hV+NETa1iSADuBmaq6ZWSvO4mDvyT3AJ8A3gN+BFxWVS+v+iATkuR54Bjgx92iH1TVZRMcaVUluRj4S6AHvAHsqarfmuxU45fkAuAv+P+PnrhxwiOtqiR3Aucw93GqrwI3VNXOiQ61SpL8GvAPwNPMdQ/guqp6aKjXPQr/9S5Ja4JXYkpSowy4JDXKgEtSowy4JDXKgEtSowy4JDXKgEtSo/4P88xDXfL+y9QAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(perf_model_small['cumgame_coeff'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.000000    14\n",
       "0.009530     1\n",
       "0.040065     1\n",
       "0.075782     1\n",
       "0.084620     1\n",
       "Name: prediction_score, dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perf_model_small.prediction_score.value_counts().sort_index().head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['T_coeff', 'course_id', 'cumgame_coeff', 'dirvar_coeff',\n",
       "       'gustvar_coeff', 'intercept', 'mse', 'n_value', 'nomatch', 'player',\n",
       "       'precip_coeff', 'prediction_score', 'rh_coeff', 'u_coeff',\n",
       "       'uv_var_coeff', 'v_coeff', 'wdir_coeff', 'wgust_coeff', 'wspd_coeff'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perf_model_small.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([16.,  4.,  5.,  4.,  3.,  2.,  2.,  1.,  6.,  2.]),\n",
       " array([0.        , 0.07275419, 0.14550838, 0.21826257, 0.29101676,\n",
       "        0.36377094, 0.43652513, 0.50927932, 0.58203351, 0.6547877 ,\n",
       "        0.72754189]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(perf_model_small['prediction_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\ipykernel_launcher.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>T_coeff</th>\n",
       "      <th>course_id</th>\n",
       "      <th>cumgame_coeff</th>\n",
       "      <th>dirvar_coeff</th>\n",
       "      <th>gustvar_coeff</th>\n",
       "      <th>intercept</th>\n",
       "      <th>mse</th>\n",
       "      <th>n_value</th>\n",
       "      <th>nomatch</th>\n",
       "      <th>player</th>\n",
       "      <th>precip_coeff</th>\n",
       "      <th>prediction_score</th>\n",
       "      <th>u_coeff</th>\n",
       "      <th>uv_var_coeff</th>\n",
       "      <th>v_coeff</th>\n",
       "      <th>wdir_coeff</th>\n",
       "      <th>wgust_coeff</th>\n",
       "      <th>wspd_coeff</th>\n",
       "      <th>coeff_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.303161</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>55.043478</td>\n",
       "      <td>9.368340</td>\n",
       "      <td>23.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bob Montes</td>\n",
       "      <td>0.152295</td>\n",
       "      <td>0.328657</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.706347</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.982209</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-2.212886</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>57.142857</td>\n",
       "      <td>6.708201</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Dennis Warsen</td>\n",
       "      <td>0.013266</td>\n",
       "      <td>0.583922</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>54.358491</td>\n",
       "      <td>14.013276</td>\n",
       "      <td>53.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Dennis Warsen</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.120216</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.797097</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-0.363872</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.100533</td>\n",
       "      <td>-0.029896</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>63.142857</td>\n",
       "      <td>6.180790</td>\n",
       "      <td>21.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Gonzalo Arestizabal</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.256484</td>\n",
       "      <td>-0.139923</td>\n",
       "      <td>-0.305617</td>\n",
       "      <td>-0.223741</td>\n",
       "      <td>0.143666</td>\n",
       "      <td>0.066997</td>\n",
       "      <td>0.102911</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>-0.465969</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.814821</td>\n",
       "      <td>-0.032315</td>\n",
       "      <td>-0.236957</td>\n",
       "      <td>56.458333</td>\n",
       "      <td>8.637850</td>\n",
       "      <td>24.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Jon Braidman</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.473781</td>\n",
       "      <td>0.536920</td>\n",
       "      <td>-0.247028</td>\n",
       "      <td>-0.357186</td>\n",
       "      <td>-0.188228</td>\n",
       "      <td>1.353104</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     T_coeff  course_id  cumgame_coeff  dirvar_coeff  gustvar_coeff  \\\n",
       "5  -0.303161          2      -0.000000      0.000000       0.000000   \n",
       "7  -2.212886          1      -0.000000      0.000000      -0.000000   \n",
       "8  -0.000000          2      -0.000000     -0.000000       0.000000   \n",
       "11 -0.363872          2      -0.100533     -0.029896      -0.000000   \n",
       "20 -0.465969          2      -0.814821     -0.032315      -0.236957   \n",
       "\n",
       "    intercept        mse  n_value  nomatch               player  precip_coeff  \\\n",
       "5   55.043478   9.368340     23.0      NaN           Bob Montes      0.152295   \n",
       "7   57.142857   6.708201     14.0      NaN        Dennis Warsen      0.013266   \n",
       "8   54.358491  14.013276     53.0      NaN        Dennis Warsen      0.000000   \n",
       "11  63.142857   6.180790     21.0      NaN  Gonzalo Arestizabal      0.000000   \n",
       "20  56.458333   8.637850     24.0      NaN         Jon Braidman      0.000000   \n",
       "\n",
       "    prediction_score   u_coeff  uv_var_coeff   v_coeff  wdir_coeff  \\\n",
       "5           0.328657 -0.000000      0.000000 -0.706347   -0.000000   \n",
       "7           0.583922 -0.000000      0.000000  0.000000    0.000000   \n",
       "8           0.120216 -0.000000     -0.000000 -0.000000    0.000000   \n",
       "11          0.256484 -0.139923     -0.305617 -0.223741    0.143666   \n",
       "20          0.473781  0.536920     -0.247028 -0.357186   -0.188228   \n",
       "\n",
       "    wgust_coeff  wspd_coeff  coeff_count  \n",
       "5      0.982209    0.000000            4  \n",
       "7     -0.000000    0.000000            2  \n",
       "8      0.797097    0.000000            1  \n",
       "11     0.066997    0.102911            9  \n",
       "20     1.353104   -0.000000            9  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zeros = []\n",
    "coeff_count = []\n",
    "for row in perf_model_small.iterrows():\n",
    "    tmp_count = 0\n",
    "    if row[1]['cumgame_coeff'] == 0:\n",
    "        tmp_count += 1\n",
    "    if row[1]['T_coeff'] == 0:\n",
    "        tmp_count += 1\n",
    "    if row[1]['precip_coeff'] == 0:\n",
    "        tmp_count += 1\n",
    "    if row[1]['u_coeff'] == 0:\n",
    "        tmp_count += 1\n",
    "    if row[1]['v_coeff'] == 0:\n",
    "        tmp_count += 1\n",
    "    if row[1]['wdir_coeff'] == 0:\n",
    "        tmp_count += 1\n",
    "    if row[1]['wgust_coeff'] == 0:\n",
    "        tmp_count += 1\n",
    "    if row[1]['wspd_coeff'] == 0:\n",
    "        tmp_count += 1\n",
    "    if row[1]['dirvar_coeff'] == 0:\n",
    "        tmp_count += 1\n",
    "    if row[1]['gustvar_coeff'] == 0:\n",
    "        tmp_count += 1\n",
    "    if row[1]['uv_var_coeff'] == 0:\n",
    "        tmp_count += 1\n",
    "    zeros.append(tmp_count)\n",
    "    coeff_count.append(11 - tmp_count)\n",
    "perf_model_small['coeff_count'] = coeff_count\n",
    "perf_model_small.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x2d153814c18>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(x=perf_model_small.n_value, y=perf_model_small.coeff_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x2d1538d0358>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(x=perf_model_small.prediction_score, y=perf_model_small.coeff_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.496456344755513"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perf_model_small.mse.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "T_coeff             -0.076904\n",
       "course_id            1.155556\n",
       "cumgame_coeff       -0.024371\n",
       "dirvar_coeff         0.044052\n",
       "gustvar_coeff       -0.031759\n",
       "intercept           57.175515\n",
       "mse                 10.496456\n",
       "n_value             24.111111\n",
       "nomatch                   NaN\n",
       "precip_coeff         0.185389\n",
       "prediction_score     0.238531\n",
       "u_coeff             -0.062268\n",
       "uv_var_coeff        -0.088330\n",
       "v_coeff              0.042376\n",
       "wdir_coeff           0.010105\n",
       "wgust_coeff          0.175829\n",
       "wspd_coeff           0.136459\n",
       "coeff_count          4.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perf_model_small.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "T_coeff              0.444488\n",
       "course_id            0.981484\n",
       "cumgame_coeff        0.597652\n",
       "dirvar_coeff         0.398663\n",
       "gustvar_coeff        0.138713\n",
       "intercept            4.048949\n",
       "mse                  4.665364\n",
       "n_value             13.604621\n",
       "nomatch                   NaN\n",
       "precip_coeff         0.361824\n",
       "prediction_score     0.263558\n",
       "u_coeff              0.387526\n",
       "uv_var_coeff         0.277781\n",
       "v_coeff              0.646197\n",
       "wdir_coeff           0.305849\n",
       "wgust_coeff          0.408886\n",
       "wspd_coeff           0.389128\n",
       "coeff_count          3.770528\n",
       "dtype: float64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perf_model_small.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>player</th>\n",
       "      <th>course_id</th>\n",
       "      <th>mse</th>\n",
       "      <th>coeff_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>720</th>\n",
       "      <td>Niel Jones</td>\n",
       "      <td>0</td>\n",
       "      <td>2.528400</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>Chris Isom</td>\n",
       "      <td>0</td>\n",
       "      <td>4.128068</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>461</th>\n",
       "      <td>Christian Eck</td>\n",
       "      <td>2</td>\n",
       "      <td>4.847626</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>Peter Sontag</td>\n",
       "      <td>2</td>\n",
       "      <td>5.269297</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>Conner Russell</td>\n",
       "      <td>2</td>\n",
       "      <td>6.084604</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Matt Rowe</td>\n",
       "      <td>2</td>\n",
       "      <td>6.089419</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>Luiz Celeste</td>\n",
       "      <td>2</td>\n",
       "      <td>6.156030</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Gonzalo Arestizabal</td>\n",
       "      <td>2</td>\n",
       "      <td>6.180790</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>690</th>\n",
       "      <td>Matt Duncanson</td>\n",
       "      <td>0</td>\n",
       "      <td>6.514368</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>552</th>\n",
       "      <td>Alan Chambless</td>\n",
       "      <td>0</td>\n",
       "      <td>6.555788</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Dennis Warsen</td>\n",
       "      <td>1</td>\n",
       "      <td>6.708201</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>Case Conover</td>\n",
       "      <td>2</td>\n",
       "      <td>6.975240</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>Luiz Celeste</td>\n",
       "      <td>0</td>\n",
       "      <td>7.333490</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>Nick Calabrese</td>\n",
       "      <td>2</td>\n",
       "      <td>7.504800</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>Joe Wharton</td>\n",
       "      <td>2</td>\n",
       "      <td>7.765556</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Jon Braidman</td>\n",
       "      <td>2</td>\n",
       "      <td>8.637850</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>747</th>\n",
       "      <td>Sean Saxton</td>\n",
       "      <td>0</td>\n",
       "      <td>8.717551</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Toby Parks</td>\n",
       "      <td>1</td>\n",
       "      <td>8.918367</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Bob Montes</td>\n",
       "      <td>2</td>\n",
       "      <td>9.368340</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>Anni Kreml</td>\n",
       "      <td>2</td>\n",
       "      <td>9.789541</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>Hugh Harrell</td>\n",
       "      <td>0</td>\n",
       "      <td>10.134009</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>909</th>\n",
       "      <td>Harper Alexander</td>\n",
       "      <td>0</td>\n",
       "      <td>10.240000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>Jeff Fiedler</td>\n",
       "      <td>2</td>\n",
       "      <td>10.315556</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>561</th>\n",
       "      <td>Andy Rothschild</td>\n",
       "      <td>0</td>\n",
       "      <td>10.598996</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Steve Willis</td>\n",
       "      <td>2</td>\n",
       "      <td>10.640547</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>Kevin Couch</td>\n",
       "      <td>2</td>\n",
       "      <td>10.654004</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>Ari Freedman</td>\n",
       "      <td>2</td>\n",
       "      <td>10.774091</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>558</th>\n",
       "      <td>Andy Hale</td>\n",
       "      <td>0</td>\n",
       "      <td>11.040000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>John Jennings</td>\n",
       "      <td>2</td>\n",
       "      <td>11.990596</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>789</th>\n",
       "      <td>Chris Johengen</td>\n",
       "      <td>0</td>\n",
       "      <td>12.352041</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Toby Parks</td>\n",
       "      <td>2</td>\n",
       "      <td>12.588235</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>687</th>\n",
       "      <td>Matt Brenner</td>\n",
       "      <td>0</td>\n",
       "      <td>12.648889</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>Will Roller</td>\n",
       "      <td>2</td>\n",
       "      <td>12.732454</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>954</th>\n",
       "      <td>Todd Kurnat</td>\n",
       "      <td>0</td>\n",
       "      <td>12.739796</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>530</th>\n",
       "      <td>Alex Bruner</td>\n",
       "      <td>2</td>\n",
       "      <td>12.761022</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>627</th>\n",
       "      <td>Edward Bigarani</td>\n",
       "      <td>0</td>\n",
       "      <td>13.065918</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Dennis Warsen</td>\n",
       "      <td>2</td>\n",
       "      <td>14.013276</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Pete D'Agostino</td>\n",
       "      <td>2</td>\n",
       "      <td>14.083198</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>Matty Angell</td>\n",
       "      <td>2</td>\n",
       "      <td>14.976814</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>618</th>\n",
       "      <td>Derek Phelan</td>\n",
       "      <td>0</td>\n",
       "      <td>15.251174</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>Scott Riley</td>\n",
       "      <td>2</td>\n",
       "      <td>15.735853</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>717</th>\n",
       "      <td>Nellio Fontes</td>\n",
       "      <td>0</td>\n",
       "      <td>16.304709</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>Zac Pape</td>\n",
       "      <td>2</td>\n",
       "      <td>18.456747</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>792</th>\n",
       "      <td>Chris Tirrell</td>\n",
       "      <td>0</td>\n",
       "      <td>19.653979</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>744</th>\n",
       "      <td>Sean Pierson</td>\n",
       "      <td>0</td>\n",
       "      <td>22.515306</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  player  course_id        mse  coeff_count\n",
       "720           Niel Jones          0   2.528400           10\n",
       "111           Chris Isom          0   4.128068            3\n",
       "461        Christian Eck          2   4.847626            9\n",
       "86          Peter Sontag          2   5.269297            9\n",
       "71        Conner Russell          2   6.084604           10\n",
       "26             Matt Rowe          2   6.089419            5\n",
       "182         Luiz Celeste          2   6.156030            3\n",
       "11   Gonzalo Arestizabal          2   6.180790            9\n",
       "690       Matt Duncanson          0   6.514368            4\n",
       "552       Alan Chambless          0   6.555788            4\n",
       "7          Dennis Warsen          1   6.708201            2\n",
       "59          Case Conover          2   6.975240            9\n",
       "180         Luiz Celeste          0   7.333490            2\n",
       "146       Nick Calabrese          2   7.504800            1\n",
       "80           Joe Wharton          2   7.765556            0\n",
       "20          Jon Braidman          2   8.637850            9\n",
       "747          Sean Saxton          0   8.717551            8\n",
       "46            Toby Parks          1   8.918367            0\n",
       "5             Bob Montes          2   9.368340            4\n",
       "56            Anni Kreml          2   9.789541            0\n",
       "204         Hugh Harrell          0  10.134009            8\n",
       "909     Harper Alexander          0  10.240000            0\n",
       "77          Jeff Fiedler          2  10.315556            0\n",
       "561      Andy Rothschild          0  10.598996            7\n",
       "41          Steve Willis          2  10.640547            5\n",
       "65           Kevin Couch          2  10.654004            2\n",
       "83          Ari Freedman          2  10.774091            9\n",
       "558            Andy Hale          0  11.040000            0\n",
       "176        John Jennings          2  11.990596            2\n",
       "789       Chris Johengen          0  12.352041            0\n",
       "47            Toby Parks          2  12.588235            0\n",
       "687         Matt Brenner          0  12.648889            0\n",
       "53           Will Roller          2  12.732454            3\n",
       "954          Todd Kurnat          0  12.739796            0\n",
       "530          Alex Bruner          2  12.761022            4\n",
       "627      Edward Bigarani          0  13.065918           10\n",
       "8          Dennis Warsen          2  14.013276            1\n",
       "32       Pete D'Agostino          2  14.083198           11\n",
       "134         Matty Angell          2  14.976814            8\n",
       "618         Derek Phelan          0  15.251174            3\n",
       "68           Scott Riley          2  15.735853            4\n",
       "717        Nellio Fontes          0  16.304709            1\n",
       "314             Zac Pape          2  18.456747            0\n",
       "792        Chris Tirrell          0  19.653979            1\n",
       "744         Sean Pierson          0  22.515306            0"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perf_model_small[['player','course_id','mse','coeff_count']].sort_values(by='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>T_coeff</th>\n",
       "      <th>course_id</th>\n",
       "      <th>cumgame_coeff</th>\n",
       "      <th>dirvar_coeff</th>\n",
       "      <th>gustvar_coeff</th>\n",
       "      <th>intercept</th>\n",
       "      <th>mse</th>\n",
       "      <th>n_value</th>\n",
       "      <th>nomatch</th>\n",
       "      <th>player</th>\n",
       "      <th>precip_coeff</th>\n",
       "      <th>prediction_score</th>\n",
       "      <th>u_coeff</th>\n",
       "      <th>uv_var_coeff</th>\n",
       "      <th>v_coeff</th>\n",
       "      <th>wdir_coeff</th>\n",
       "      <th>wgust_coeff</th>\n",
       "      <th>wspd_coeff</th>\n",
       "      <th>coeff_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>747</th>\n",
       "      <td>0.795462</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.011504</td>\n",
       "      <td>1.218429</td>\n",
       "      <td>0.0</td>\n",
       "      <td>56.785714</td>\n",
       "      <td>8.717551</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sean Saxton</td>\n",
       "      <td>0.845591</td>\n",
       "      <td>0.619032</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.625112</td>\n",
       "      <td>2.524385</td>\n",
       "      <td>1.552971</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.343955</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      T_coeff  course_id  cumgame_coeff  dirvar_coeff  gustvar_coeff  \\\n",
       "747  0.795462          0      -0.011504      1.218429            0.0   \n",
       "\n",
       "     intercept       mse  n_value  nomatch       player  precip_coeff  \\\n",
       "747  56.785714  8.717551     14.0      NaN  Sean Saxton      0.845591   \n",
       "\n",
       "     prediction_score  u_coeff  uv_var_coeff   v_coeff  wdir_coeff  \\\n",
       "747          0.619032     -0.0     -0.625112  2.524385    1.552971   \n",
       "\n",
       "     wgust_coeff  wspd_coeff  coeff_count  \n",
       "747          0.0    1.343955            8  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perf_model_small.loc[perf_model_small['player'] == 'Sean Saxton']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
