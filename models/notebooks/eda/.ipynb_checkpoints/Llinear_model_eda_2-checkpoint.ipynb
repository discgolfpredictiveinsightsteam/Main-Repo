{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Score Model w/ Weather EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objective\n",
    "\n",
    "* Evaluation of basic linear model using weather factors and previous scores\n",
    "\n",
    "### Rationale\n",
    "\n",
    "*  Why This?  Before establishing a baseline model, the performance implications of various model choices need to be explored.\n",
    "\n",
    "*  Why Me?  Because I will be building the baseline model, I am the logical choice\n",
    "\n",
    "*  Why Now?  Data from a reproducible pipeline is now available; understanding model choices is necessary before continuing on the project critical path of model implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Requirements\n",
    "\n",
    "*  Pandas 0.24.2\n",
    "*  Scikit-learn 0.21.2\n",
    "*  Matplotlib 3.1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input / Output\n",
    "\n",
    "*  This notebook is expected to be in `models/notebooks/eda`\n",
    "\n",
    "*  The input weather data is in a file `models/wx_model_data/wx_model.csv`\n",
    "\n",
    "*  The input score data is in a file `models/score_model_data/scores.csv`\n",
    "\n",
    "*  The output models are stored in a file `models/score_model_data/linear_model_fits.csv`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import / Set-Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "import numpy as np\n",
    "from sklearn.linear_model import ElasticNetCV\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import datetime as dt\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get weather data\n",
    "wx_df = pd.read_csv('../../wx_model_data/wx_model.csv', parse_dates = ['date'])\n",
    "# Get scores data\n",
    "scores_df = pd.read_csv('../../score_model_data/scores.csv', parse_dates = ['time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>date</th>\n",
       "      <th>weighted_T</th>\n",
       "      <th>weighted_w_dir</th>\n",
       "      <th>weighted_w_spd</th>\n",
       "      <th>weighted_w_gust</th>\n",
       "      <th>weighted_rh</th>\n",
       "      <th>weighted_precip</th>\n",
       "      <th>weighted_w_u</th>\n",
       "      <th>weighted_w_v</th>\n",
       "      <th>w_gust_var</th>\n",
       "      <th>w_dir_var</th>\n",
       "      <th>w_uv_var</th>\n",
       "      <th>course_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2018-11-25</td>\n",
       "      <td>57.023188</td>\n",
       "      <td>80.344928</td>\n",
       "      <td>1.289855</td>\n",
       "      <td>6.800000</td>\n",
       "      <td>88.214493</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.807230</td>\n",
       "      <td>0.670447</td>\n",
       "      <td>0.560000</td>\n",
       "      <td>266.490351</td>\n",
       "      <td>154.904818</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2019-02-24</td>\n",
       "      <td>52.839273</td>\n",
       "      <td>179.611525</td>\n",
       "      <td>1.979019</td>\n",
       "      <td>11.066667</td>\n",
       "      <td>75.883806</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.276422</td>\n",
       "      <td>-1.255324</td>\n",
       "      <td>0.062222</td>\n",
       "      <td>1907.347412</td>\n",
       "      <td>27.922180</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2019-01-27</td>\n",
       "      <td>56.642593</td>\n",
       "      <td>66.362963</td>\n",
       "      <td>3.916667</td>\n",
       "      <td>12.466667</td>\n",
       "      <td>73.714815</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.674324</td>\n",
       "      <td>2.326601</td>\n",
       "      <td>1.582222</td>\n",
       "      <td>301.056529</td>\n",
       "      <td>227.954035</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2019-02-17</td>\n",
       "      <td>49.299471</td>\n",
       "      <td>267.369841</td>\n",
       "      <td>5.489524</td>\n",
       "      <td>14.066667</td>\n",
       "      <td>67.711164</td>\n",
       "      <td>0.000778</td>\n",
       "      <td>-4.882030</td>\n",
       "      <td>-0.070813</td>\n",
       "      <td>1.528889</td>\n",
       "      <td>14.666560</td>\n",
       "      <td>13.316158</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2019-01-06</td>\n",
       "      <td>51.505556</td>\n",
       "      <td>153.133333</td>\n",
       "      <td>4.384722</td>\n",
       "      <td>20.933333</td>\n",
       "      <td>89.798611</td>\n",
       "      <td>0.105625</td>\n",
       "      <td>0.829178</td>\n",
       "      <td>-3.227827</td>\n",
       "      <td>6.995556</td>\n",
       "      <td>214.376551</td>\n",
       "      <td>906.500313</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0       date  weighted_T  weighted_w_dir  weighted_w_spd  \\\n",
       "0           0 2018-11-25   57.023188       80.344928        1.289855   \n",
       "1           1 2019-02-24   52.839273      179.611525        1.979019   \n",
       "2           2 2019-01-27   56.642593       66.362963        3.916667   \n",
       "3           3 2019-02-17   49.299471      267.369841        5.489524   \n",
       "4           4 2019-01-06   51.505556      153.133333        4.384722   \n",
       "\n",
       "   weighted_w_gust  weighted_rh  weighted_precip  weighted_w_u  weighted_w_v  \\\n",
       "0         6.800000    88.214493         0.000000      0.807230      0.670447   \n",
       "1        11.066667    75.883806         0.000000     -0.276422     -1.255324   \n",
       "2        12.466667    73.714815         0.000000      2.674324      2.326601   \n",
       "3        14.066667    67.711164         0.000778     -4.882030     -0.070813   \n",
       "4        20.933333    89.798611         0.105625      0.829178     -3.227827   \n",
       "\n",
       "   w_gust_var    w_dir_var    w_uv_var  course_id  \n",
       "0    0.560000   266.490351  154.904818          0  \n",
       "1    0.062222  1907.347412   27.922180          0  \n",
       "2    1.582222   301.056529  227.954035          0  \n",
       "3    1.528889    14.666560   13.316158          0  \n",
       "4    6.995556   214.376551  906.500313          0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wx_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Name</th>\n",
       "      <th>Raw</th>\n",
       "      <th>Handicap</th>\n",
       "      <th>Adjusted</th>\n",
       "      <th>time</th>\n",
       "      <th>course_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Mark Shannon</td>\n",
       "      <td>61.0</td>\n",
       "      <td>-12.40</td>\n",
       "      <td>48.60</td>\n",
       "      <td>2019-01-19 08:00:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Jacob Kermish-Wells</td>\n",
       "      <td>60.0</td>\n",
       "      <td>-10.72</td>\n",
       "      <td>49.28</td>\n",
       "      <td>2019-01-19 08:00:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Luiz Celeste</td>\n",
       "      <td>55.0</td>\n",
       "      <td>-5.23</td>\n",
       "      <td>49.77</td>\n",
       "      <td>2019-01-19 08:00:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Tu Tran</td>\n",
       "      <td>59.0</td>\n",
       "      <td>-9.07</td>\n",
       "      <td>49.93</td>\n",
       "      <td>2019-01-19 08:00:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Matty Angell</td>\n",
       "      <td>53.0</td>\n",
       "      <td>-1.50</td>\n",
       "      <td>51.50</td>\n",
       "      <td>2019-01-19 08:00:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                 Name   Raw  Handicap  Adjusted  \\\n",
       "0           0         Mark Shannon  61.0    -12.40     48.60   \n",
       "1           1  Jacob Kermish-Wells  60.0    -10.72     49.28   \n",
       "2           2         Luiz Celeste  55.0     -5.23     49.77   \n",
       "3           3              Tu Tran  59.0     -9.07     49.93   \n",
       "4           4         Matty Angell  53.0     -1.50     51.50   \n",
       "\n",
       "                 time  course_id  \n",
       "0 2019-01-19 08:00:00          1  \n",
       "1 2019-01-19 08:00:00          1  \n",
       "2 2019-01-19 08:00:00          1  \n",
       "3 2019-01-19 08:00:00          1  \n",
       "4 2019-01-19 08:00:00          1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean out duplicated indexes\n",
    "wx_df = wx_df.drop(columns = 'Unnamed: 0')\n",
    "scores_df = scores_df.drop(columns = 'Unnamed: 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort prior to merge\n",
    "wx_df = wx_df.sort_values(by = ['date','course_id'])\n",
    "scores_df = scores_df.sort_values(by= ['time','course_id','Name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Raw</th>\n",
       "      <th>Handicap</th>\n",
       "      <th>Adjusted</th>\n",
       "      <th>time</th>\n",
       "      <th>course_id</th>\n",
       "      <th>date</th>\n",
       "      <th>weighted_T</th>\n",
       "      <th>weighted_w_dir</th>\n",
       "      <th>weighted_w_spd</th>\n",
       "      <th>weighted_w_gust</th>\n",
       "      <th>weighted_rh</th>\n",
       "      <th>weighted_precip</th>\n",
       "      <th>weighted_w_u</th>\n",
       "      <th>weighted_w_v</th>\n",
       "      <th>w_gust_var</th>\n",
       "      <th>w_dir_var</th>\n",
       "      <th>w_uv_var</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alex Torres</td>\n",
       "      <td>68.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2012-11-18 07:30:00</td>\n",
       "      <td>0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Andy Leaf</td>\n",
       "      <td>53.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2012-11-18 07:30:00</td>\n",
       "      <td>0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Anthony McGinnis</td>\n",
       "      <td>78.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2012-11-18 07:30:00</td>\n",
       "      <td>0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Aurelius Lewicki</td>\n",
       "      <td>57.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2012-11-18 07:30:00</td>\n",
       "      <td>0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Billy Manger</td>\n",
       "      <td>58.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2012-11-18 07:30:00</td>\n",
       "      <td>0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Name   Raw  Handicap  Adjusted                time  course_id  \\\n",
       "0       Alex Torres  68.0       NaN       NaN 2012-11-18 07:30:00          0   \n",
       "1         Andy Leaf  53.0       NaN       NaN 2012-11-18 07:30:00          0   \n",
       "2  Anthony McGinnis  78.0       NaN       NaN 2012-11-18 07:30:00          0   \n",
       "3  Aurelius Lewicki  57.0       NaN       NaN 2012-11-18 07:30:00          0   \n",
       "4      Billy Manger  58.0       NaN       NaN 2012-11-18 07:30:00          0   \n",
       "\n",
       "  date  weighted_T  weighted_w_dir  weighted_w_spd  weighted_w_gust  \\\n",
       "0  NaT         NaN             NaN             NaN              NaN   \n",
       "1  NaT         NaN             NaN             NaN              NaN   \n",
       "2  NaT         NaN             NaN             NaN              NaN   \n",
       "3  NaT         NaN             NaN             NaN              NaN   \n",
       "4  NaT         NaN             NaN             NaN              NaN   \n",
       "\n",
       "   weighted_rh  weighted_precip  weighted_w_u  weighted_w_v  w_gust_var  \\\n",
       "0          NaN              NaN           NaN           NaN         NaN   \n",
       "1          NaN              NaN           NaN           NaN         NaN   \n",
       "2          NaN              NaN           NaN           NaN         NaN   \n",
       "3          NaN              NaN           NaN           NaN         NaN   \n",
       "4          NaN              NaN           NaN           NaN         NaN   \n",
       "\n",
       "   w_dir_var  w_uv_var  \n",
       "0        NaN       NaN  \n",
       "1        NaN       NaN  \n",
       "2        NaN       NaN  \n",
       "3        NaN       NaN  \n",
       "4        NaN       NaN  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_df = pd.merge_asof(scores_df, wx_df, by = 'course_id', left_on= 'time', right_on = 'date',\n",
    "                       direction = 'backward', tolerance = pd.Timedelta('1d') )\n",
    "all_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Raw</th>\n",
       "      <th>Handicap</th>\n",
       "      <th>Adjusted</th>\n",
       "      <th>time</th>\n",
       "      <th>course_id</th>\n",
       "      <th>date</th>\n",
       "      <th>weighted_T</th>\n",
       "      <th>weighted_w_dir</th>\n",
       "      <th>weighted_w_spd</th>\n",
       "      <th>weighted_w_gust</th>\n",
       "      <th>weighted_rh</th>\n",
       "      <th>weighted_precip</th>\n",
       "      <th>weighted_w_u</th>\n",
       "      <th>weighted_w_v</th>\n",
       "      <th>w_gust_var</th>\n",
       "      <th>w_dir_var</th>\n",
       "      <th>w_uv_var</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>478</th>\n",
       "      <td>Ben Horst</td>\n",
       "      <td>65.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-01-28 09:00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>2017-01-28</td>\n",
       "      <td>53.789346</td>\n",
       "      <td>251.602328</td>\n",
       "      <td>1.089775</td>\n",
       "      <td>7.688889</td>\n",
       "      <td>64.358531</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.963792</td>\n",
       "      <td>-0.419697</td>\n",
       "      <td>0.134321</td>\n",
       "      <td>28.786247</td>\n",
       "      <td>2.475685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479</th>\n",
       "      <td>Bob Montes</td>\n",
       "      <td>54.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-01-28 09:00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>2017-01-28</td>\n",
       "      <td>53.789346</td>\n",
       "      <td>251.602328</td>\n",
       "      <td>1.089775</td>\n",
       "      <td>7.688889</td>\n",
       "      <td>64.358531</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.963792</td>\n",
       "      <td>-0.419697</td>\n",
       "      <td>0.134321</td>\n",
       "      <td>28.786247</td>\n",
       "      <td>2.475685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480</th>\n",
       "      <td>Dennis Warsen</td>\n",
       "      <td>52.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-01-28 09:00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>2017-01-28</td>\n",
       "      <td>53.789346</td>\n",
       "      <td>251.602328</td>\n",
       "      <td>1.089775</td>\n",
       "      <td>7.688889</td>\n",
       "      <td>64.358531</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.963792</td>\n",
       "      <td>-0.419697</td>\n",
       "      <td>0.134321</td>\n",
       "      <td>28.786247</td>\n",
       "      <td>2.475685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>481</th>\n",
       "      <td>Gonzalo Arestizabal</td>\n",
       "      <td>63.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-01-28 09:00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>2017-01-28</td>\n",
       "      <td>53.789346</td>\n",
       "      <td>251.602328</td>\n",
       "      <td>1.089775</td>\n",
       "      <td>7.688889</td>\n",
       "      <td>64.358531</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.963792</td>\n",
       "      <td>-0.419697</td>\n",
       "      <td>0.134321</td>\n",
       "      <td>28.786247</td>\n",
       "      <td>2.475685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>482</th>\n",
       "      <td>Greg Mann</td>\n",
       "      <td>58.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-01-28 09:00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>2017-01-28</td>\n",
       "      <td>53.789346</td>\n",
       "      <td>251.602328</td>\n",
       "      <td>1.089775</td>\n",
       "      <td>7.688889</td>\n",
       "      <td>64.358531</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.963792</td>\n",
       "      <td>-0.419697</td>\n",
       "      <td>0.134321</td>\n",
       "      <td>28.786247</td>\n",
       "      <td>2.475685</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Name   Raw  Handicap  Adjusted                time  \\\n",
       "478            Ben Horst  65.0       NaN       NaN 2017-01-28 09:00:00   \n",
       "479           Bob Montes  54.0       NaN       NaN 2017-01-28 09:00:00   \n",
       "480        Dennis Warsen  52.0       NaN       NaN 2017-01-28 09:00:00   \n",
       "481  Gonzalo Arestizabal  63.0       NaN       NaN 2017-01-28 09:00:00   \n",
       "482            Greg Mann  58.0       NaN       NaN 2017-01-28 09:00:00   \n",
       "\n",
       "     course_id       date  weighted_T  weighted_w_dir  weighted_w_spd  \\\n",
       "478          2 2017-01-28   53.789346      251.602328        1.089775   \n",
       "479          2 2017-01-28   53.789346      251.602328        1.089775   \n",
       "480          2 2017-01-28   53.789346      251.602328        1.089775   \n",
       "481          2 2017-01-28   53.789346      251.602328        1.089775   \n",
       "482          2 2017-01-28   53.789346      251.602328        1.089775   \n",
       "\n",
       "     weighted_w_gust  weighted_rh  weighted_precip  weighted_w_u  \\\n",
       "478         7.688889    64.358531              0.0     -0.963792   \n",
       "479         7.688889    64.358531              0.0     -0.963792   \n",
       "480         7.688889    64.358531              0.0     -0.963792   \n",
       "481         7.688889    64.358531              0.0     -0.963792   \n",
       "482         7.688889    64.358531              0.0     -0.963792   \n",
       "\n",
       "     weighted_w_v  w_gust_var  w_dir_var  w_uv_var  \n",
       "478     -0.419697    0.134321  28.786247  2.475685  \n",
       "479     -0.419697    0.134321  28.786247  2.475685  \n",
       "480     -0.419697    0.134321  28.786247  2.475685  \n",
       "481     -0.419697    0.134321  28.786247  2.475685  \n",
       "482     -0.419697    0.134321  28.786247  2.475685  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop any rows that do not have weather data\n",
    "all_df = all_df.dropna(subset = ['weighted_T'])\n",
    "all_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2960"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Name', 'Raw', 'Handicap', 'Adjusted', 'time', 'course_id', 'date',\n",
       "       'weighted_T', 'weighted_w_dir', 'weighted_w_spd', 'weighted_w_gust',\n",
       "       'weighted_rh', 'weighted_precip', 'weighted_w_u', 'weighted_w_v',\n",
       "       'w_gust_var', 'w_dir_var', 'w_uv_var'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def model_player_performance(player : str, course : int):\n",
    "    \"\"\"Given a player name and course id, return model parameters indicating the effects of weather on expected score.\n",
    "    The model will return a dictionary with coefficients for easy identification\"\"\"\n",
    "    \n",
    "    model_dict = {}\n",
    "    model_dict['player'] = player\n",
    "    model_dict['course_id'] = course\n",
    "    player_df = all_df[(all_df['Name'] == player) & (all_df['course_id'] == course)]\n",
    "    # Replace index with the cumulative number of games played, and make that into a column\n",
    "    player_df = player_df.reset_index()\n",
    "    player_df = player_df.drop(columns = ['index'])\n",
    "    player_df = player_df.reset_index()\n",
    "    \n",
    "    #Build weather model\n",
    "    X = player_df[['index','weighted_T', 'weighted_w_dir', 'weighted_w_spd', 'weighted_w_gust',\n",
    "       'weighted_rh', 'weighted_precip', 'weighted_w_u', 'weighted_w_v',\n",
    "       'w_gust_var', 'w_dir_var', 'w_uv_var']].values\n",
    "    y = player_df['Raw'].values\n",
    "    \n",
    "    if len(player_df) > 13:\n",
    "        scaler = StandardScaler()\n",
    "        lr = ElasticNetCV(l1_ratio = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 0.95, 0.99], cv = 3, \n",
    "                          max_iter = 5000, random_state=42)\n",
    "        pipeline = make_pipeline(scaler, lr)\n",
    "        pipeline.fit(X,y)\n",
    "        ypred = pipeline.predict(X)\n",
    "        cumgame_coeff, T_coeff, wdir_coeff, wspd_coeff, wgust_coeff, rh_coeff,\\\n",
    "        precip_coeff, u_coeff, v_coeff, gustvar_coeff, dirvar_coeff, uv_var_coeff = pipeline['elasticnetcv'].coef_\n",
    "        model_dict['prediction_score'] = pipeline.score(X,y)\n",
    "        model_dict['cumgame_coeff'] = cumgame_coeff\n",
    "        model_dict['T_coeff'] = T_coeff\n",
    "        model_dict['wdir_coeff'] = wdir_coeff\n",
    "        model_dict['wspd_coeff'] = wspd_coeff\n",
    "        model_dict['wgust_coeff'] = wgust_coeff\n",
    "        model_dict['rh_coeff'] = rh_coeff\n",
    "        model_dict['precip_coeff'] = precip_coeff\n",
    "        model_dict['u_coeff'] = u_coeff\n",
    "        model_dict['v_coeff'] = v_coeff\n",
    "        model_dict['gustvar_coeff'] = gustvar_coeff\n",
    "        model_dict['dirvar_coeff'] = dirvar_coeff\n",
    "        model_dict['uv_var_coeff'] = uv_var_coeff\n",
    "        model_dict['intercept'] = pipeline['elasticnetcv'].intercept_\n",
    "        model_dict['mse'] = mean_squared_error(y, ypred)\n",
    "        model_dict['n_value'] = len(player_df)\n",
    "    elif len(player_df) > 0:\n",
    "        model_dict['nomatch'] = 1\n",
    "    else:\n",
    "        model_dict['nomatch'] = 1\n",
    "        \n",
    "    return model_dict    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.006772843671394524, tolerance: 0.0066\n",
      "  positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.00694652185212119, tolerance: 0.0066\n",
      "  positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.011019177819424186, tolerance: 0.009222222222222224\n",
      "  positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.013644913885633159, tolerance: 0.009222222222222224\n",
      "  positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.016813739455791676, tolerance: 0.009222222222222224\n",
      "  positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.008459061297086068, tolerance: 0.0066\n",
      "  positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.009068939065225656, tolerance: 0.0066\n",
      "  positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.00929405854848464, tolerance: 0.0066\n",
      "  positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.009373429283572543, tolerance: 0.0066\n",
      "  positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.009374861755065966, tolerance: 0.0066\n",
      "  positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.009321204732326782, tolerance: 0.0066\n",
      "  positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.009222695610838327, tolerance: 0.0066\n",
      "  positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.009085800019408397, tolerance: 0.0066\n",
      "  positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.008915743988554992, tolerance: 0.0066\n",
      "  positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.008717248392385246, tolerance: 0.0066\n",
      "  positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.014137693168278176, tolerance: 0.009222222222222224\n",
      "  positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.015352898561832973, tolerance: 0.009222222222222224\n",
      "  positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.018437511678079943, tolerance: 0.009222222222222224\n",
      "  positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.019917178191544593, tolerance: 0.009222222222222224\n",
      "  positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.028179593109655343, tolerance: 0.009222222222222224\n",
      "  positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.03107104821403439, tolerance: 0.009222222222222224\n",
      "  positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.025527726316271426, tolerance: 0.009222222222222224\n",
      "  positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.02770839855160645, tolerance: 0.009222222222222224\n",
      "  positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.035104596505094676, tolerance: 0.009222222222222224\n",
      "  positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.04247715006832742, tolerance: 0.009222222222222224\n",
      "  positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.05019570473327306, tolerance: 0.009222222222222224\n",
      "  positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.05833589269029282, tolerance: 0.009222222222222224\n",
      "  positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.06687147481281475, tolerance: 0.009222222222222224\n",
      "  positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.045960597798483604, tolerance: 0.009222222222222224\n",
      "  positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.09719409714104188, tolerance: 0.009222222222222224\n",
      "  positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.0188328333513752, tolerance: 0.009222222222222224\n",
      "  positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.028763749927181337, tolerance: 0.009222222222222224\n",
      "  positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.0742593183566882, tolerance: 0.009222222222222224\n",
      "  positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.10757082854808964, tolerance: 0.009222222222222224\n",
      "  positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.1378541223335521, tolerance: 0.009222222222222224\n",
      "  positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.23520929417093228, tolerance: 0.009222222222222224\n",
      "  positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.2453500293765405, tolerance: 0.009222222222222224\n",
      "  positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.2599479011455843, tolerance: 0.009222222222222224\n",
      "  positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.27403352908009726, tolerance: 0.009222222222222224\n",
      "  positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.28639815522646384, tolerance: 0.009222222222222224\n",
      "  positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.2966134213852767, tolerance: 0.009222222222222224\n",
      "  positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.3045375108137396, tolerance: 0.009222222222222224\n",
      "  positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.31017692061952884, tolerance: 0.009222222222222224\n",
      "  positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.31362393955872925, tolerance: 0.009222222222222224\n",
      "  positive)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.049851190827780556, tolerance: 0.012854545454545457\n",
      "  positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.03409355582455298, tolerance: 0.020854545454545455\n",
      "  positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.04480848281863192, tolerance: 0.020854545454545455\n",
      "  positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.05233428837022913, tolerance: 0.020854545454545455\n",
      "  positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.059913666129115306, tolerance: 0.020854545454545455\n",
      "  positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.06748995980125194, tolerance: 0.020854545454545455\n",
      "  positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.0749141147936685, tolerance: 0.020854545454545455\n",
      "  positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.03648511594215975, tolerance: 0.020854545454545455\n",
      "  positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.08358009139802736, tolerance: 0.020854545454545455\n",
      "  positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.12288139064370185, tolerance: 0.020854545454545455\n",
      "  positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.030141483365259347, tolerance: 0.028225\n",
      "  positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.0334524498421338, tolerance: 0.028225\n",
      "  positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.03696417506815308, tolerance: 0.028225\n",
      "  positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.04035986892298382, tolerance: 0.028225\n",
      "  positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.04356229851118343, tolerance: 0.028225\n",
      "  positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.04652243568643044, tolerance: 0.028225\n",
      "  positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.04920193954966301, tolerance: 0.028225\n",
      "  positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.0507865660389335, tolerance: 0.028225\n",
      "  positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.05589758365180586, tolerance: 0.028225\n",
      "  positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.05947507607421443, tolerance: 0.028225\n",
      "  positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.06261420491087577, tolerance: 0.028225\n",
      "  positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.06537102161062869, tolerance: 0.028225\n",
      "  positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.06773275333248918, tolerance: 0.028225\n",
      "  positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.06968902860464965, tolerance: 0.028225\n",
      "  positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.07123684640414396, tolerance: 0.028225\n",
      "  positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.07238029178322058, tolerance: 0.028225\n",
      "  positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.07312972528662876, tolerance: 0.028225\n",
      "  positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.07350086887197271, tolerance: 0.028225\n",
      "  positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.07351386253203174, tolerance: 0.028225\n",
      "  positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.0731923302423576, tolerance: 0.028225\n",
      "  positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.029583816869735102, tolerance: 0.028225\n",
      "  positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.02864838929839575, tolerance: 0.028225\n",
      "  positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.028286553314699425, tolerance: 0.028225\n",
      "  positive)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.024153847559951203, tolerance: 0.023323076923076922\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.023631050532003428, tolerance: 0.023323076923076922\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.047215922086692785, tolerance: 0.023323076923076922\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.059126346559814635, tolerance: 0.023323076923076922\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.07246517297136279, tolerance: 0.023323076923076922\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.08775984803182268, tolerance: 0.023323076923076922\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.10511894293489377, tolerance: 0.023323076923076922\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.12460607379292199, tolerance: 0.023323076923076922\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.14624635273648323, tolerance: 0.023323076923076922\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.1700203400147693, tolerance: 0.023323076923076922\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.02764746191918732, tolerance: 0.023323076923076922\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.06893290748585912, tolerance: 0.023323076923076922\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.12529730345787016, tolerance: 0.023323076923076922\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.16080288686084288, tolerance: 0.023323076923076922\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.18943699365441802, tolerance: 0.023323076923076922\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.05743179553449096, tolerance: 0.023323076923076922\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.2203898244245579, tolerance: 0.023323076923076922\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.2717286535420982, tolerance: 0.023323076923076922\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.3062261270090758, tolerance: 0.023323076923076922\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.3374025682793551, tolerance: 0.023323076923076922\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.36690715890071246, tolerance: 0.023323076923076922\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.39468283205219734, tolerance: 0.023323076923076922\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.17878276102984003, tolerance: 0.023323076923076922\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.4003026941268182, tolerance: 0.023323076923076922\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.461647949871967, tolerance: 0.023323076923076922\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.48988255242376866, tolerance: 0.023323076923076922\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.5092639446420311, tolerance: 0.023323076923076922\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.5244409505795922, tolerance: 0.023323076923076922\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.5363326710609879, tolerance: 0.023323076923076922\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.5451608969432975, tolerance: 0.023323076923076922\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.3625617361295337, tolerance: 0.023323076923076922\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.33154063069662065, tolerance: 0.023323076923076922\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.4802785331680486, tolerance: 0.023323076923076922\n",
      "  tol, rng, random, positive)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>T_coeff</th>\n",
       "      <th>course_id</th>\n",
       "      <th>cumgame_coeff</th>\n",
       "      <th>dirvar_coeff</th>\n",
       "      <th>gustvar_coeff</th>\n",
       "      <th>intercept</th>\n",
       "      <th>mse</th>\n",
       "      <th>n_value</th>\n",
       "      <th>nomatch</th>\n",
       "      <th>player</th>\n",
       "      <th>precip_coeff</th>\n",
       "      <th>prediction_score</th>\n",
       "      <th>rh_coeff</th>\n",
       "      <th>u_coeff</th>\n",
       "      <th>uv_var_coeff</th>\n",
       "      <th>v_coeff</th>\n",
       "      <th>wdir_coeff</th>\n",
       "      <th>wgust_coeff</th>\n",
       "      <th>wspd_coeff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Ben Horst</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Ben Horst</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Ben Horst</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Bob Montes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Bob Montes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   T_coeff  course_id  cumgame_coeff  dirvar_coeff  gustvar_coeff  intercept  \\\n",
       "0      NaN          0            NaN           NaN            NaN        NaN   \n",
       "1      NaN          1            NaN           NaN            NaN        NaN   \n",
       "2      NaN          2            NaN           NaN            NaN        NaN   \n",
       "3      NaN          0            NaN           NaN            NaN        NaN   \n",
       "4      NaN          1            NaN           NaN            NaN        NaN   \n",
       "\n",
       "   mse  n_value  nomatch      player  precip_coeff  prediction_score  \\\n",
       "0  NaN      NaN      1.0   Ben Horst           NaN               NaN   \n",
       "1  NaN      NaN      1.0   Ben Horst           NaN               NaN   \n",
       "2  NaN      NaN      1.0   Ben Horst           NaN               NaN   \n",
       "3  NaN      NaN      1.0  Bob Montes           NaN               NaN   \n",
       "4  NaN      NaN      1.0  Bob Montes           NaN               NaN   \n",
       "\n",
       "   rh_coeff  u_coeff  uv_var_coeff  v_coeff  wdir_coeff  wgust_coeff  \\\n",
       "0       NaN      NaN           NaN      NaN         NaN          NaN   \n",
       "1       NaN      NaN           NaN      NaN         NaN          NaN   \n",
       "2       NaN      NaN           NaN      NaN         NaN          NaN   \n",
       "3       NaN      NaN           NaN      NaN         NaN          NaN   \n",
       "4       NaN      NaN           NaN      NaN         NaN          NaN   \n",
       "\n",
       "   wspd_coeff  \n",
       "0         NaN  \n",
       "1         NaN  \n",
       "2         NaN  \n",
       "3         NaN  \n",
       "4         NaN  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Make list of player names\n",
    "player_names = all_df['Name'].unique()\n",
    "perf_dicts = []\n",
    "for player_name in player_names:\n",
    "    for course_id in range(all_df['course_id'].max() + 1):\n",
    "        perf_dict = model_player_performance(player_name, course_id)\n",
    "        perf_dicts.append(perf_dict)\n",
    "            \n",
    "perf_model_df = pd.DataFrame(perf_dicts)\n",
    "perf_model_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>T_coeff</th>\n",
       "      <th>course_id</th>\n",
       "      <th>cumgame_coeff</th>\n",
       "      <th>dirvar_coeff</th>\n",
       "      <th>gustvar_coeff</th>\n",
       "      <th>intercept</th>\n",
       "      <th>mse</th>\n",
       "      <th>n_value</th>\n",
       "      <th>nomatch</th>\n",
       "      <th>player</th>\n",
       "      <th>precip_coeff</th>\n",
       "      <th>prediction_score</th>\n",
       "      <th>rh_coeff</th>\n",
       "      <th>u_coeff</th>\n",
       "      <th>uv_var_coeff</th>\n",
       "      <th>v_coeff</th>\n",
       "      <th>wdir_coeff</th>\n",
       "      <th>wgust_coeff</th>\n",
       "      <th>wspd_coeff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.128402</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.151977</td>\n",
       "      <td>55.043478</td>\n",
       "      <td>10.955951</td>\n",
       "      <td>23.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bob Montes</td>\n",
       "      <td>0.147545</td>\n",
       "      <td>0.214888</td>\n",
       "      <td>0.123820</td>\n",
       "      <td>-0.046501</td>\n",
       "      <td>0.009249</td>\n",
       "      <td>-0.252943</td>\n",
       "      <td>-0.027359</td>\n",
       "      <td>0.252485</td>\n",
       "      <td>0.143663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-2.212886</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>57.142857</td>\n",
       "      <td>6.708201</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Dennis Warsen</td>\n",
       "      <td>0.013266</td>\n",
       "      <td>0.583922</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>54.358491</td>\n",
       "      <td>14.013276</td>\n",
       "      <td>53.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Dennis Warsen</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.120216</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.797097</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-0.256193</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.062888</td>\n",
       "      <td>-0.03218</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>63.142857</td>\n",
       "      <td>6.571892</td>\n",
       "      <td>21.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Gonzalo Arestizabal</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.209437</td>\n",
       "      <td>0.055052</td>\n",
       "      <td>-0.108468</td>\n",
       "      <td>-0.233501</td>\n",
       "      <td>-0.159369</td>\n",
       "      <td>0.100453</td>\n",
       "      <td>0.051833</td>\n",
       "      <td>0.077865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>-0.655646</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.815119</td>\n",
       "      <td>-0.00000</td>\n",
       "      <td>-0.335813</td>\n",
       "      <td>56.458333</td>\n",
       "      <td>6.658610</td>\n",
       "      <td>24.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Jon Braidman</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.594357</td>\n",
       "      <td>-0.282425</td>\n",
       "      <td>1.201926</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.049038</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>2.618771</td>\n",
       "      <td>-0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     T_coeff  course_id  cumgame_coeff  dirvar_coeff  gustvar_coeff  \\\n",
       "5  -0.128402          2      -0.000000       0.00000       0.151977   \n",
       "7  -2.212886          1      -0.000000       0.00000      -0.000000   \n",
       "8  -0.000000          2      -0.000000      -0.00000       0.000000   \n",
       "11 -0.256193          2      -0.062888      -0.03218      -0.000000   \n",
       "20 -0.655646          2      -0.815119      -0.00000      -0.335813   \n",
       "\n",
       "    intercept        mse  n_value  nomatch               player  precip_coeff  \\\n",
       "5   55.043478  10.955951     23.0      NaN           Bob Montes      0.147545   \n",
       "7   57.142857   6.708201     14.0      NaN        Dennis Warsen      0.013266   \n",
       "8   54.358491  14.013276     53.0      NaN        Dennis Warsen      0.000000   \n",
       "11  63.142857   6.571892     21.0      NaN  Gonzalo Arestizabal      0.000000   \n",
       "20  56.458333   6.658610     24.0      NaN         Jon Braidman      0.000000   \n",
       "\n",
       "    prediction_score  rh_coeff   u_coeff  uv_var_coeff   v_coeff  wdir_coeff  \\\n",
       "5           0.214888  0.123820 -0.046501      0.009249 -0.252943   -0.027359   \n",
       "7           0.583922  0.000000 -0.000000      0.000000  0.000000    0.000000   \n",
       "8           0.120216 -0.000000 -0.000000     -0.000000 -0.000000    0.000000   \n",
       "11          0.209437  0.055052 -0.108468     -0.233501 -0.159369    0.100453   \n",
       "20          0.594357 -0.282425  1.201926     -0.000000 -0.049038   -0.000000   \n",
       "\n",
       "    wgust_coeff  wspd_coeff  \n",
       "5      0.252485    0.143663  \n",
       "7     -0.000000    0.000000  \n",
       "8      0.797097    0.000000  \n",
       "11     0.051833    0.077865  \n",
       "20     2.618771   -0.000000  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perf_model_small = perf_model_df.dropna(subset=['T_coeff'])\n",
    "print(len(perf_model_small))\n",
    "perf_model_small.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([18.,  2., 25.]),\n",
       " array([0.        , 0.66666667, 1.33333333, 2.        ]),\n",
       " <a list of 3 Patch objects>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(perf_model_small['course_id'],bins=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 1.,  1.,  1.,  1., 32.,  4.,  3.,  0.,  1.,  1.]),\n",
       " array([-0.93275032, -0.74460894, -0.55646755, -0.36832617, -0.18018479,\n",
       "         0.00795659,  0.19609797,  0.38423935,  0.57238073,  0.76052211,\n",
       "         0.94866349]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(perf_model_small['rh_coeff'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([2., 7., 7., 8., 9., 2., 6., 1., 1., 2.]),\n",
       " array([ 2.62005925,  4.64631863,  6.67257801,  8.69883739, 10.72509678,\n",
       "        12.75135616, 14.77761554, 16.80387492, 18.8301343 , 20.85639368,\n",
       "        22.88265306]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(perf_model_small['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>player</th>\n",
       "      <th>course_id</th>\n",
       "      <th>mse</th>\n",
       "      <th>coeff_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>720</th>\n",
       "      <td>Niel Jones</td>\n",
       "      <td>0</td>\n",
       "      <td>2.620059</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>Chris Isom</td>\n",
       "      <td>0</td>\n",
       "      <td>4.425242</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>461</th>\n",
       "      <td>Christian Eck</td>\n",
       "      <td>2</td>\n",
       "      <td>4.814559</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Matt Rowe</td>\n",
       "      <td>2</td>\n",
       "      <td>5.217655</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>Peter Sontag</td>\n",
       "      <td>2</td>\n",
       "      <td>5.454666</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>690</th>\n",
       "      <td>Matt Duncanson</td>\n",
       "      <td>0</td>\n",
       "      <td>5.926691</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>Luiz Celeste</td>\n",
       "      <td>2</td>\n",
       "      <td>6.156030</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Gonzalo Arestizabal</td>\n",
       "      <td>2</td>\n",
       "      <td>6.571892</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Jon Braidman</td>\n",
       "      <td>2</td>\n",
       "      <td>6.658610</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Dennis Warsen</td>\n",
       "      <td>1</td>\n",
       "      <td>6.708201</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>552</th>\n",
       "      <td>Alan Chambless</td>\n",
       "      <td>0</td>\n",
       "      <td>7.093333</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>Nick Calabrese</td>\n",
       "      <td>2</td>\n",
       "      <td>7.292186</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>Luiz Celeste</td>\n",
       "      <td>0</td>\n",
       "      <td>7.333490</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>Case Conover</td>\n",
       "      <td>2</td>\n",
       "      <td>7.344162</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>Joe Wharton</td>\n",
       "      <td>2</td>\n",
       "      <td>7.765556</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>Conner Russell</td>\n",
       "      <td>2</td>\n",
       "      <td>8.180908</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Toby Parks</td>\n",
       "      <td>1</td>\n",
       "      <td>8.918367</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>530</th>\n",
       "      <td>Alex Bruner</td>\n",
       "      <td>2</td>\n",
       "      <td>9.707375</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>Anni Kreml</td>\n",
       "      <td>2</td>\n",
       "      <td>9.789541</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>Hugh Harrell</td>\n",
       "      <td>0</td>\n",
       "      <td>10.134009</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>909</th>\n",
       "      <td>Harper Alexander</td>\n",
       "      <td>0</td>\n",
       "      <td>10.240000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>Jeff Fiedler</td>\n",
       "      <td>2</td>\n",
       "      <td>10.315556</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Steve Willis</td>\n",
       "      <td>2</td>\n",
       "      <td>10.558752</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>Kevin Couch</td>\n",
       "      <td>2</td>\n",
       "      <td>10.654004</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>Ari Freedman</td>\n",
       "      <td>2</td>\n",
       "      <td>10.729664</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Bob Montes</td>\n",
       "      <td>2</td>\n",
       "      <td>10.955951</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>558</th>\n",
       "      <td>Andy Hale</td>\n",
       "      <td>0</td>\n",
       "      <td>11.040000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>John Jennings</td>\n",
       "      <td>2</td>\n",
       "      <td>11.720468</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>789</th>\n",
       "      <td>Chris Johengen</td>\n",
       "      <td>0</td>\n",
       "      <td>12.352041</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Toby Parks</td>\n",
       "      <td>2</td>\n",
       "      <td>12.588235</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>687</th>\n",
       "      <td>Matt Brenner</td>\n",
       "      <td>0</td>\n",
       "      <td>12.648889</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>Will Roller</td>\n",
       "      <td>2</td>\n",
       "      <td>12.732454</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>954</th>\n",
       "      <td>Todd Kurnat</td>\n",
       "      <td>0</td>\n",
       "      <td>12.739796</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Pete D'Agostino</td>\n",
       "      <td>2</td>\n",
       "      <td>13.073967</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Dennis Warsen</td>\n",
       "      <td>2</td>\n",
       "      <td>14.013276</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>Matty Angell</td>\n",
       "      <td>2</td>\n",
       "      <td>14.929428</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>618</th>\n",
       "      <td>Derek Phelan</td>\n",
       "      <td>0</td>\n",
       "      <td>15.397924</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>561</th>\n",
       "      <td>Andy Rothschild</td>\n",
       "      <td>0</td>\n",
       "      <td>15.669978</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>Scott Riley</td>\n",
       "      <td>2</td>\n",
       "      <td>15.735853</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>627</th>\n",
       "      <td>Edward Bigarani</td>\n",
       "      <td>0</td>\n",
       "      <td>16.016493</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>717</th>\n",
       "      <td>Nellio Fontes</td>\n",
       "      <td>0</td>\n",
       "      <td>16.304709</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>Zac Pape</td>\n",
       "      <td>2</td>\n",
       "      <td>18.456747</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>792</th>\n",
       "      <td>Chris Tirrell</td>\n",
       "      <td>0</td>\n",
       "      <td>19.653979</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>744</th>\n",
       "      <td>Sean Pierson</td>\n",
       "      <td>0</td>\n",
       "      <td>22.515306</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>747</th>\n",
       "      <td>Sean Saxton</td>\n",
       "      <td>0</td>\n",
       "      <td>22.882653</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  player  course_id        mse  coeff_count\n",
       "720           Niel Jones          0   2.620059           12\n",
       "111           Chris Isom          0   4.425242            3\n",
       "461        Christian Eck          2   4.814559            8\n",
       "26             Matt Rowe          2   5.217655            5\n",
       "86          Peter Sontag          2   5.454666            9\n",
       "690       Matt Duncanson          0   5.926691            5\n",
       "182         Luiz Celeste          2   6.156030            3\n",
       "11   Gonzalo Arestizabal          2   6.571892           10\n",
       "20          Jon Braidman          2   6.658610            7\n",
       "7          Dennis Warsen          1   6.708201            2\n",
       "552       Alan Chambless          0   7.093333            1\n",
       "146       Nick Calabrese          2   7.292186            3\n",
       "180         Luiz Celeste          0   7.333490            2\n",
       "59          Case Conover          2   7.344162            4\n",
       "80           Joe Wharton          2   7.765556            0\n",
       "71        Conner Russell          2   8.180908            4\n",
       "46            Toby Parks          1   8.918367            0\n",
       "530          Alex Bruner          2   9.707375            4\n",
       "56            Anni Kreml          2   9.789541            0\n",
       "204         Hugh Harrell          0  10.134009            8\n",
       "909     Harper Alexander          0  10.240000            0\n",
       "77          Jeff Fiedler          2  10.315556            0\n",
       "41          Steve Willis          2  10.558752            5\n",
       "65           Kevin Couch          2  10.654004            2\n",
       "83          Ari Freedman          2  10.729664           10\n",
       "5             Bob Montes          2  10.955951           10\n",
       "558            Andy Hale          0  11.040000            0\n",
       "176        John Jennings          2  11.720468            3\n",
       "789       Chris Johengen          0  12.352041            0\n",
       "47            Toby Parks          2  12.588235            0\n",
       "687         Matt Brenner          0  12.648889            0\n",
       "53           Will Roller          2  12.732454            3\n",
       "954          Todd Kurnat          0  12.739796            0\n",
       "32       Pete D'Agostino          2  13.073967            9\n",
       "8          Dennis Warsen          2  14.013276            1\n",
       "134         Matty Angell          2  14.929428            9\n",
       "618         Derek Phelan          0  15.397924            0\n",
       "561      Andy Rothschild          0  15.669978            3\n",
       "68           Scott Riley          2  15.735853            4\n",
       "627      Edward Bigarani          0  16.016493            3\n",
       "717        Nellio Fontes          0  16.304709            1\n",
       "314             Zac Pape          2  18.456747            1\n",
       "792        Chris Tirrell          0  19.653979            1\n",
       "744         Sean Pierson          0  22.515306            0\n",
       "747          Sean Saxton          0  22.882653            1"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perf_model_small[['player','course_id','mse','coeff_count']].sort_values(by='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1419"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perf_model_df.to_csv('../../score_model_data/score_model2_all.csv')\n",
    "len(perf_model_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 1.,  0.,  1.,  1.,  2., 34.,  4.,  1.,  0.,  1.]),\n",
       " array([-2.23925209, -1.83119388, -1.42313566, -1.01507744, -0.60701922,\n",
       "        -0.198961  ,  0.20909722,  0.61715543,  1.02521365,  1.43327187,\n",
       "         1.84133009]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(perf_model_small['cumgame_coeff'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.000000    17\n",
       "0.040065     1\n",
       "0.084620     1\n",
       "0.092123     1\n",
       "0.120216     1\n",
       "Name: prediction_score, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perf_model_small.prediction_score.value_counts().sort_index().head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['T_coeff', 'course_id', 'cumgame_coeff', 'dirvar_coeff',\n",
       "       'gustvar_coeff', 'intercept', 'mse', 'n_value', 'nomatch', 'player',\n",
       "       'precip_coeff', 'prediction_score', 'rh_coeff', 'u_coeff',\n",
       "       'uv_var_coeff', 'v_coeff', 'wdir_coeff', 'wgust_coeff', 'wspd_coeff'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perf_model_small.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([18.,  3.,  6.,  5.,  1.,  2.,  1.,  1.,  6.,  2.]),\n",
       " array([0.        , 0.07179571, 0.14359142, 0.21538713, 0.28718284,\n",
       "        0.35897855, 0.43077426, 0.50256997, 0.57436568, 0.64616139,\n",
       "        0.7179571 ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(perf_model_small['prediction_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\andre\\Anaconda3\\envs\\discgolf\\lib\\site-packages\\ipykernel_launcher.py:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>T_coeff</th>\n",
       "      <th>course_id</th>\n",
       "      <th>cumgame_coeff</th>\n",
       "      <th>dirvar_coeff</th>\n",
       "      <th>gustvar_coeff</th>\n",
       "      <th>intercept</th>\n",
       "      <th>mse</th>\n",
       "      <th>n_value</th>\n",
       "      <th>nomatch</th>\n",
       "      <th>player</th>\n",
       "      <th>...</th>\n",
       "      <th>prediction_score</th>\n",
       "      <th>rh_coeff</th>\n",
       "      <th>u_coeff</th>\n",
       "      <th>uv_var_coeff</th>\n",
       "      <th>v_coeff</th>\n",
       "      <th>wdir_coeff</th>\n",
       "      <th>wgust_coeff</th>\n",
       "      <th>wspd_coeff</th>\n",
       "      <th>zeros</th>\n",
       "      <th>coeff_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.128402</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.151977</td>\n",
       "      <td>55.043478</td>\n",
       "      <td>10.955951</td>\n",
       "      <td>23.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bob Montes</td>\n",
       "      <td>...</td>\n",
       "      <td>0.214888</td>\n",
       "      <td>0.123820</td>\n",
       "      <td>-0.046501</td>\n",
       "      <td>0.009249</td>\n",
       "      <td>-0.252943</td>\n",
       "      <td>-0.027359</td>\n",
       "      <td>0.252485</td>\n",
       "      <td>0.143663</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-2.212886</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>57.142857</td>\n",
       "      <td>6.708201</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Dennis Warsen</td>\n",
       "      <td>...</td>\n",
       "      <td>0.583922</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>54.358491</td>\n",
       "      <td>14.013276</td>\n",
       "      <td>53.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Dennis Warsen</td>\n",
       "      <td>...</td>\n",
       "      <td>0.120216</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.797097</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-0.256193</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.062888</td>\n",
       "      <td>-0.03218</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>63.142857</td>\n",
       "      <td>6.571892</td>\n",
       "      <td>21.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Gonzalo Arestizabal</td>\n",
       "      <td>...</td>\n",
       "      <td>0.209437</td>\n",
       "      <td>0.055052</td>\n",
       "      <td>-0.108468</td>\n",
       "      <td>-0.233501</td>\n",
       "      <td>-0.159369</td>\n",
       "      <td>0.100453</td>\n",
       "      <td>0.051833</td>\n",
       "      <td>0.077865</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>-0.655646</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.815119</td>\n",
       "      <td>-0.00000</td>\n",
       "      <td>-0.335813</td>\n",
       "      <td>56.458333</td>\n",
       "      <td>6.658610</td>\n",
       "      <td>24.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Jon Braidman</td>\n",
       "      <td>...</td>\n",
       "      <td>0.594357</td>\n",
       "      <td>-0.282425</td>\n",
       "      <td>1.201926</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.049038</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>2.618771</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     T_coeff  course_id  cumgame_coeff  dirvar_coeff  gustvar_coeff  \\\n",
       "5  -0.128402          2      -0.000000       0.00000       0.151977   \n",
       "7  -2.212886          1      -0.000000       0.00000      -0.000000   \n",
       "8  -0.000000          2      -0.000000      -0.00000       0.000000   \n",
       "11 -0.256193          2      -0.062888      -0.03218      -0.000000   \n",
       "20 -0.655646          2      -0.815119      -0.00000      -0.335813   \n",
       "\n",
       "    intercept        mse  n_value  nomatch               player  ...  \\\n",
       "5   55.043478  10.955951     23.0      NaN           Bob Montes  ...   \n",
       "7   57.142857   6.708201     14.0      NaN        Dennis Warsen  ...   \n",
       "8   54.358491  14.013276     53.0      NaN        Dennis Warsen  ...   \n",
       "11  63.142857   6.571892     21.0      NaN  Gonzalo Arestizabal  ...   \n",
       "20  56.458333   6.658610     24.0      NaN         Jon Braidman  ...   \n",
       "\n",
       "    prediction_score  rh_coeff   u_coeff  uv_var_coeff   v_coeff  wdir_coeff  \\\n",
       "5           0.214888  0.123820 -0.046501      0.009249 -0.252943   -0.027359   \n",
       "7           0.583922  0.000000 -0.000000      0.000000  0.000000    0.000000   \n",
       "8           0.120216 -0.000000 -0.000000     -0.000000 -0.000000    0.000000   \n",
       "11          0.209437  0.055052 -0.108468     -0.233501 -0.159369    0.100453   \n",
       "20          0.594357 -0.282425  1.201926     -0.000000 -0.049038   -0.000000   \n",
       "\n",
       "    wgust_coeff  wspd_coeff  zeros  coeff_count  \n",
       "5      0.252485    0.143663      2           10  \n",
       "7     -0.000000    0.000000     10            2  \n",
       "8      0.797097    0.000000     11            1  \n",
       "11     0.051833    0.077865      2           10  \n",
       "20     2.618771   -0.000000      5            7  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zeros = []\n",
    "coeff_count = []\n",
    "for row in perf_model_small.iterrows():\n",
    "    tmp_count = 0\n",
    "    if row[1]['cumgame_coeff'] == 0:\n",
    "        tmp_count += 1\n",
    "    if row[1]['T_coeff'] == 0:\n",
    "        tmp_count += 1\n",
    "    if row[1]['rh_coeff'] == 0:\n",
    "        tmp_count += 1\n",
    "    if row[1]['precip_coeff'] == 0:\n",
    "        tmp_count += 1\n",
    "    if row[1]['u_coeff'] == 0:\n",
    "        tmp_count += 1\n",
    "    if row[1]['v_coeff'] == 0:\n",
    "        tmp_count += 1\n",
    "    if row[1]['wdir_coeff'] == 0:\n",
    "        tmp_count += 1\n",
    "    if row[1]['wgust_coeff'] == 0:\n",
    "        tmp_count += 1\n",
    "    if row[1]['wspd_coeff'] == 0:\n",
    "        tmp_count += 1\n",
    "    if row[1]['dirvar_coeff'] == 0:\n",
    "        tmp_count += 1\n",
    "    if row[1]['gustvar_coeff'] == 0:\n",
    "        tmp_count += 1\n",
    "    if row[1]['uv_var_coeff'] == 0:\n",
    "        tmp_count += 1\n",
    "    zeros.append(tmp_count)\n",
    "    coeff_count.append(12 - tmp_count)\n",
    "perf_model_small['coeff_count'] = coeff_count\n",
    "perf_model_small.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x258630ca940>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(x=perf_model_small.n_value, y=perf_model_small.coeff_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x258631936d8>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(x=perf_model_small.prediction_score, y=perf_model_small.coeff_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.934192324803373"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perf_model_small.mse.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "T_coeff             -0.112452\n",
       "course_id            1.155556\n",
       "cumgame_coeff       -0.015895\n",
       "dirvar_coeff        -0.018696\n",
       "gustvar_coeff       -0.041892\n",
       "intercept           57.175515\n",
       "mse                 10.934192\n",
       "n_value             24.111111\n",
       "nomatch                   NaN\n",
       "precip_coeff         0.146856\n",
       "prediction_score     0.217967\n",
       "rh_coeff             0.004197\n",
       "u_coeff             -0.031410\n",
       "uv_var_coeff        -0.061334\n",
       "v_coeff             -0.044925\n",
       "wdir_coeff          -0.020111\n",
       "wgust_coeff          0.171630\n",
       "wspd_coeff           0.078084\n",
       "zeros                8.533333\n",
       "coeff_count          3.466667\n",
       "dtype: float64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perf_model_small.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "T_coeff              0.451857\n",
       "course_id            0.975974\n",
       "cumgame_coeff        0.529776\n",
       "dirvar_coeff         0.136277\n",
       "gustvar_coeff        0.136607\n",
       "intercept            4.193727\n",
       "mse                  4.693515\n",
       "n_value             14.372041\n",
       "nomatch                   NaN\n",
       "precip_coeff         0.366913\n",
       "prediction_score     0.236346\n",
       "rh_coeff             0.262917\n",
       "u_coeff              0.346201\n",
       "uv_var_coeff         0.209035\n",
       "v_coeff              0.270754\n",
       "wdir_coeff           0.164378\n",
       "wgust_coeff          0.502180\n",
       "wspd_coeff           0.208192\n",
       "zeros                3.513610\n",
       "coeff_count          3.513610\n",
       "dtype: float64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perf_model_small.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
